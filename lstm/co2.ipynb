{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from keras>=3.5.0->tensorflow) (13.7.0)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=32, num_layers=2):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_country_data(country_data, sequence_length=5):\n",
    "    # Scale the data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(country_data.reshape(-1, 1))\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y = [], []\n",
    "    for i in range(len(scaled_data) - sequence_length):\n",
    "        X.append(scaled_data[i:(i + sequence_length)])\n",
    "        y.append(scaled_data[i + sequence_length])\n",
    "    \n",
    "    return np.array(X), np.array(y), scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, epochs=200):\n",
    "    # Create dataset and dataloader\n",
    "    X_tensor = torch.FloatTensor(X)\n",
    "    y_tensor = torch.FloatTensor(y)\n",
    "    dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "    train_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = Predictor(input_size=1)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future(model, last_sequence, scaler, n_future=5):\n",
    "    model.eval()\n",
    "    current_sequence = last_sequence.copy()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_future):\n",
    "            sequence = torch.FloatTensor(current_sequence).unsqueeze(0)\n",
    "            pred = model(sequence)\n",
    "            predictions.append(pred.numpy())\n",
    "            current_sequence = np.vstack((current_sequence[1:], pred.numpy()))\n",
    "    \n",
    "    predictions = np.array(predictions).reshape(-1, 1)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    \n",
    "    return predictions.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>1990 CO2 per capita</th>\n",
       "      <th>1991 CO2 per capita</th>\n",
       "      <th>1992 CO2 per capita</th>\n",
       "      <th>1993 CO2 per capita</th>\n",
       "      <th>1994 CO2 per capita</th>\n",
       "      <th>1995 CO2 per capita</th>\n",
       "      <th>1996 CO2 per capita</th>\n",
       "      <th>1997 CO2 per capita</th>\n",
       "      <th>1998 CO2 per capita</th>\n",
       "      <th>...</th>\n",
       "      <th>2014 CO2 per capita</th>\n",
       "      <th>2015 CO2 per capita</th>\n",
       "      <th>2016 CO2 per capita</th>\n",
       "      <th>2017 CO2 per capita</th>\n",
       "      <th>2018 CO2 per capita</th>\n",
       "      <th>2019 CO2 per capita</th>\n",
       "      <th>2020 CO2 per capita</th>\n",
       "      <th>2021 CO2 per capita</th>\n",
       "      <th>2022 CO2 per capita</th>\n",
       "      <th>2023 CO2 per capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Africa</td>\n",
       "      <td>1.024</td>\n",
       "      <td>1.042</td>\n",
       "      <td>0.984</td>\n",
       "      <td>1.016</td>\n",
       "      <td>1.108</td>\n",
       "      <td>1.154</td>\n",
       "      <td>1.162</td>\n",
       "      <td>1.162</td>\n",
       "      <td>1.157</td>\n",
       "      <td>...</td>\n",
       "      <td>1.143</td>\n",
       "      <td>1.094</td>\n",
       "      <td>1.100</td>\n",
       "      <td>1.087</td>\n",
       "      <td>1.055</td>\n",
       "      <td>1.099</td>\n",
       "      <td>0.983</td>\n",
       "      <td>1.021</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Africa (GCP)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1.684</td>\n",
       "      <td>1.307</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.547</td>\n",
       "      <td>...</td>\n",
       "      <td>2.066</td>\n",
       "      <td>1.626</td>\n",
       "      <td>1.598</td>\n",
       "      <td>1.826</td>\n",
       "      <td>1.691</td>\n",
       "      <td>1.673</td>\n",
       "      <td>1.640</td>\n",
       "      <td>1.802</td>\n",
       "      <td>1.830</td>\n",
       "      <td>1.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>3.024</td>\n",
       "      <td>3.032</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.004</td>\n",
       "      <td>3.177</td>\n",
       "      <td>3.399</td>\n",
       "      <td>3.446</td>\n",
       "      <td>2.988</td>\n",
       "      <td>3.545</td>\n",
       "      <td>...</td>\n",
       "      <td>3.859</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.880</td>\n",
       "      <td>3.962</td>\n",
       "      <td>4.063</td>\n",
       "      <td>4.155</td>\n",
       "      <td>3.819</td>\n",
       "      <td>4.012</td>\n",
       "      <td>4.058</td>\n",
       "      <td>3.859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Country  1990 CO2 per capita  1991 CO2 per capita  \\\n",
       "0   Afghanistan                0.168                0.156   \n",
       "1        Africa                1.024                1.042   \n",
       "2  Africa (GCP)                0.000                0.000   \n",
       "3       Albania                1.684                1.307   \n",
       "4       Algeria                3.024                3.032   \n",
       "\n",
       "   1992 CO2 per capita  1993 CO2 per capita  1994 CO2 per capita  \\\n",
       "0                0.112                0.100                0.089   \n",
       "1                0.984                1.016                1.108   \n",
       "2                0.000                0.000                0.000   \n",
       "3                0.767                0.713                0.588   \n",
       "4                3.000                3.004                3.177   \n",
       "\n",
       "   1995 CO2 per capita  1996 CO2 per capita  1997 CO2 per capita  \\\n",
       "0                0.083                0.077                0.071   \n",
       "1                1.154                1.162                1.162   \n",
       "2                0.000                0.000                0.000   \n",
       "3                0.641                0.622                0.478   \n",
       "4                3.399                3.446                2.988   \n",
       "\n",
       "   1998 CO2 per capita  ...  2014 CO2 per capita  2015 CO2 per capita  \\\n",
       "0                0.067  ...                0.277                0.286   \n",
       "1                1.157  ...                1.143                1.094   \n",
       "2                0.000  ...                0.000                0.000   \n",
       "3                0.547  ...                2.066                1.626   \n",
       "4                3.545  ...                3.859                4.000   \n",
       "\n",
       "   2016 CO2 per capita  2017 CO2 per capita  2018 CO2 per capita  \\\n",
       "0                0.257                0.271                0.289   \n",
       "1                1.100                1.087                1.055   \n",
       "2                0.000                0.000                0.000   \n",
       "3                1.598                1.826                1.691   \n",
       "4                3.880                3.962                4.063   \n",
       "\n",
       "   2019 CO2 per capita  2020 CO2 per capita  2021 CO2 per capita  \\\n",
       "0                0.286                0.297                0.257   \n",
       "1                1.099                0.983                1.021   \n",
       "2                0.000                0.000                0.000   \n",
       "3                1.673                1.640                1.802   \n",
       "4                4.155                3.819                4.012   \n",
       "\n",
       "   2022 CO2 per capita  2023 CO2 per capita  \n",
       "0                0.260                0.266  \n",
       "1                0.991                0.959  \n",
       "2                0.000                0.000  \n",
       "3                1.830                1.830  \n",
       "4                4.058                3.859  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/co2.csv')\n",
    "df.head()\n",
    "df.replace(\"..\", pd.NA, inplace=True)\n",
    "# Forward fill first, then backward fill to handle any remaining NAs at the start\n",
    "df.rename(columns={'country': 'Country'}, inplace=True)\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df = df.ffill().bfill()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df.columns if 'CO2' in col]\n",
    "    \n",
    "sequence_length = 5\n",
    "predictions_by_country = {}\n",
    "selected_countries = ['United States', 'China', 'Japan', 'Germany', 'United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for Afghanistan\n",
      "Epoch [50/200], Loss: 0.0355\n",
      "Epoch [100/200], Loss: 0.0030\n",
      "Epoch [150/200], Loss: 0.0020\n",
      "Epoch [200/200], Loss: 0.0015\n",
      "\n",
      "Training model for Africa\n",
      "Epoch [50/200], Loss: 0.0621\n",
      "Epoch [100/200], Loss: 0.0496\n",
      "Epoch [150/200], Loss: 0.0317\n",
      "Epoch [200/200], Loss: 0.0360\n",
      "\n",
      "Training model for Africa (GCP)\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Albania\n",
      "Epoch [50/200], Loss: 0.0179\n",
      "Epoch [100/200], Loss: 0.0132\n",
      "Epoch [150/200], Loss: 0.0077\n",
      "Epoch [200/200], Loss: 0.0080\n",
      "\n",
      "Training model for Algeria\n",
      "Epoch [50/200], Loss: 0.0332\n",
      "Epoch [100/200], Loss: 0.0260\n",
      "Epoch [150/200], Loss: 0.0209\n",
      "Epoch [200/200], Loss: 0.0188\n",
      "\n",
      "Training model for Andorra\n",
      "Epoch [50/200], Loss: 0.0393\n",
      "Epoch [100/200], Loss: 0.0260\n",
      "Epoch [150/200], Loss: 0.0145\n",
      "Epoch [200/200], Loss: 0.0128\n",
      "\n",
      "Training model for Angola\n",
      "Epoch [50/200], Loss: 0.0461\n",
      "Epoch [100/200], Loss: 0.0135\n",
      "Epoch [150/200], Loss: 0.0101\n",
      "Epoch [200/200], Loss: 0.0079\n",
      "\n",
      "Training model for Anguilla\n",
      "Epoch [50/200], Loss: 0.0186\n",
      "Epoch [100/200], Loss: 0.0114\n",
      "Epoch [150/200], Loss: 0.0071\n",
      "Epoch [200/200], Loss: 0.0058\n",
      "\n",
      "Training model for Antarctica\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Antigua and Barbuda\n",
      "Epoch [50/200], Loss: 0.0109\n",
      "Epoch [100/200], Loss: 0.0062\n",
      "Epoch [150/200], Loss: 0.0029\n",
      "Epoch [200/200], Loss: 0.0031\n",
      "\n",
      "Training model for Argentina\n",
      "Epoch [50/200], Loss: 0.0418\n",
      "Epoch [100/200], Loss: 0.0371\n",
      "Epoch [150/200], Loss: 0.0268\n",
      "Epoch [200/200], Loss: 0.0238\n",
      "\n",
      "Training model for Armenia\n",
      "Epoch [50/200], Loss: 0.0188\n",
      "Epoch [100/200], Loss: 0.0099\n",
      "Epoch [150/200], Loss: 0.0086\n",
      "Epoch [200/200], Loss: 0.0089\n",
      "\n",
      "Training model for Aruba\n",
      "Epoch [50/200], Loss: 0.0636\n",
      "Epoch [100/200], Loss: 0.0331\n",
      "Epoch [150/200], Loss: 0.0304\n",
      "Epoch [200/200], Loss: 0.0287\n",
      "\n",
      "Training model for Asia\n",
      "Epoch [50/200], Loss: 0.0067\n",
      "Epoch [100/200], Loss: 0.0033\n",
      "Epoch [150/200], Loss: 0.0020\n",
      "Epoch [200/200], Loss: 0.0020\n",
      "\n",
      "Training model for Asia (GCP)\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Asia (excl. China and India)\n",
      "Epoch [50/200], Loss: 0.0068\n",
      "Epoch [100/200], Loss: 0.0047\n",
      "Epoch [150/200], Loss: 0.0052\n",
      "Epoch [200/200], Loss: 0.0039\n",
      "\n",
      "Training model for Australia\n",
      "Epoch [50/200], Loss: 0.0364\n",
      "Epoch [100/200], Loss: 0.0205\n",
      "Epoch [150/200], Loss: 0.0081\n",
      "Epoch [200/200], Loss: 0.0050\n",
      "\n",
      "Training model for Austria\n",
      "Epoch [50/200], Loss: 0.0371\n",
      "Epoch [100/200], Loss: 0.0285\n",
      "Epoch [150/200], Loss: 0.0159\n",
      "Epoch [200/200], Loss: 0.0109\n",
      "\n",
      "Training model for Azerbaijan\n",
      "Epoch [50/200], Loss: 0.0027\n",
      "Epoch [100/200], Loss: 0.0030\n",
      "Epoch [150/200], Loss: 0.0027\n",
      "Epoch [200/200], Loss: 0.0026\n",
      "\n",
      "Training model for Bahamas\n",
      "Epoch [50/200], Loss: 0.0340\n",
      "Epoch [100/200], Loss: 0.0323\n",
      "Epoch [150/200], Loss: 0.0286\n",
      "Epoch [200/200], Loss: 0.0265\n",
      "\n",
      "Training model for Bahrain\n",
      "Epoch [50/200], Loss: 0.0219\n",
      "Epoch [100/200], Loss: 0.0182\n",
      "Epoch [150/200], Loss: 0.0164\n",
      "Epoch [200/200], Loss: 0.0139\n",
      "\n",
      "Training model for Bangladesh\n",
      "Epoch [50/200], Loss: 0.0010\n",
      "Epoch [100/200], Loss: 0.0006\n",
      "Epoch [150/200], Loss: 0.0006\n",
      "Epoch [200/200], Loss: 0.0006\n",
      "\n",
      "Training model for Barbados\n",
      "Epoch [50/200], Loss: 0.0297\n",
      "Epoch [100/200], Loss: 0.0166\n",
      "Epoch [150/200], Loss: 0.0124\n",
      "Epoch [200/200], Loss: 0.0104\n",
      "\n",
      "Training model for Belarus\n",
      "Epoch [50/200], Loss: 0.0048\n",
      "Epoch [100/200], Loss: 0.0030\n",
      "Epoch [150/200], Loss: 0.0021\n",
      "Epoch [200/200], Loss: 0.0017\n",
      "\n",
      "Training model for Belgium\n",
      "Epoch [50/200], Loss: 0.0097\n",
      "Epoch [100/200], Loss: 0.0073\n",
      "Epoch [150/200], Loss: 0.0070\n",
      "Epoch [200/200], Loss: 0.0066\n",
      "\n",
      "Training model for Belize\n",
      "Epoch [50/200], Loss: 0.0271\n",
      "Epoch [100/200], Loss: 0.0288\n",
      "Epoch [150/200], Loss: 0.0248\n",
      "Epoch [200/200], Loss: 0.0259\n",
      "\n",
      "Training model for Benin\n",
      "Epoch [50/200], Loss: 0.0130\n",
      "Epoch [100/200], Loss: 0.0101\n",
      "Epoch [150/200], Loss: 0.0056\n",
      "Epoch [200/200], Loss: 0.0036\n",
      "\n",
      "Training model for Bermuda\n",
      "Epoch [50/200], Loss: 0.0418\n",
      "Epoch [100/200], Loss: 0.0319\n",
      "Epoch [150/200], Loss: 0.0302\n",
      "Epoch [200/200], Loss: 0.0251\n",
      "\n",
      "Training model for Bhutan\n",
      "Epoch [50/200], Loss: 0.0163\n",
      "Epoch [100/200], Loss: 0.0123\n",
      "Epoch [150/200], Loss: 0.0102\n",
      "Epoch [200/200], Loss: 0.0086\n",
      "\n",
      "Training model for Bolivia\n",
      "Epoch [50/200], Loss: 0.0338\n",
      "Epoch [100/200], Loss: 0.0330\n",
      "Epoch [150/200], Loss: 0.0243\n",
      "Epoch [200/200], Loss: 0.0171\n",
      "\n",
      "Training model for Bonaire Sint Eustatius and Saba\n",
      "Epoch [50/200], Loss: 0.0454\n",
      "Epoch [100/200], Loss: 0.0317\n",
      "Epoch [150/200], Loss: 0.0298\n",
      "Epoch [200/200], Loss: 0.0302\n",
      "\n",
      "Training model for Bosnia and Herzegovina\n",
      "Epoch [50/200], Loss: 0.0182\n",
      "Epoch [100/200], Loss: 0.0107\n",
      "Epoch [150/200], Loss: 0.0056\n",
      "Epoch [200/200], Loss: 0.0052\n",
      "\n",
      "Training model for Botswana\n",
      "Epoch [50/200], Loss: 0.0377\n",
      "Epoch [100/200], Loss: 0.0383\n",
      "Epoch [150/200], Loss: 0.0359\n",
      "Epoch [200/200], Loss: 0.0351\n",
      "\n",
      "Training model for Brazil\n",
      "Epoch [50/200], Loss: 0.0167\n",
      "Epoch [100/200], Loss: 0.0162\n",
      "Epoch [150/200], Loss: 0.0083\n",
      "Epoch [200/200], Loss: 0.0056\n",
      "\n",
      "Training model for British Virgin Islands\n",
      "Epoch [50/200], Loss: 0.0375\n",
      "Epoch [100/200], Loss: 0.0143\n",
      "Epoch [150/200], Loss: 0.0137\n",
      "Epoch [200/200], Loss: 0.0151\n",
      "\n",
      "Training model for Brunei\n",
      "Epoch [50/200], Loss: 0.0427\n",
      "Epoch [100/200], Loss: 0.0289\n",
      "Epoch [150/200], Loss: 0.0260\n",
      "Epoch [200/200], Loss: 0.0254\n",
      "\n",
      "Training model for Bulgaria\n",
      "Epoch [50/200], Loss: 0.0233\n",
      "Epoch [100/200], Loss: 0.0249\n",
      "Epoch [150/200], Loss: 0.0231\n",
      "Epoch [200/200], Loss: 0.0214\n",
      "\n",
      "Training model for Burkina Faso\n",
      "Epoch [50/200], Loss: 0.0052\n",
      "Epoch [100/200], Loss: 0.0028\n",
      "Epoch [150/200], Loss: 0.0026\n",
      "Epoch [200/200], Loss: 0.0023\n",
      "\n",
      "Training model for Burundi\n",
      "Epoch [50/200], Loss: 0.0503\n",
      "Epoch [100/200], Loss: 0.0258\n",
      "Epoch [150/200], Loss: 0.0180\n",
      "Epoch [200/200], Loss: 0.0157\n",
      "\n",
      "Training model for Cambodia\n",
      "Epoch [50/200], Loss: 0.0073\n",
      "Epoch [100/200], Loss: 0.0037\n",
      "Epoch [150/200], Loss: 0.0027\n",
      "Epoch [200/200], Loss: 0.0019\n",
      "\n",
      "Training model for Cameroon\n",
      "Epoch [50/200], Loss: 0.0245\n",
      "Epoch [100/200], Loss: 0.0228\n",
      "Epoch [150/200], Loss: 0.0177\n",
      "Epoch [200/200], Loss: 0.0166\n",
      "\n",
      "Training model for Canada\n",
      "Epoch [50/200], Loss: 0.0288\n",
      "Epoch [100/200], Loss: 0.0199\n",
      "Epoch [150/200], Loss: 0.0114\n",
      "Epoch [200/200], Loss: 0.0132\n",
      "\n",
      "Training model for Cape Verde\n",
      "Epoch [50/200], Loss: 0.0144\n",
      "Epoch [100/200], Loss: 0.0110\n",
      "Epoch [150/200], Loss: 0.0074\n",
      "Epoch [200/200], Loss: 0.0068\n",
      "\n",
      "Training model for Central African Republic\n",
      "Epoch [50/200], Loss: 0.0263\n",
      "Epoch [100/200], Loss: 0.0267\n",
      "Epoch [150/200], Loss: 0.0254\n",
      "Epoch [200/200], Loss: 0.0236\n",
      "\n",
      "Training model for Central America (GCP)\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Chad\n",
      "Epoch [50/200], Loss: 0.0281\n",
      "Epoch [100/200], Loss: 0.0201\n",
      "Epoch [150/200], Loss: 0.0149\n",
      "Epoch [200/200], Loss: 0.0121\n",
      "\n",
      "Training model for Chile\n",
      "Epoch [50/200], Loss: 0.0166\n",
      "Epoch [100/200], Loss: 0.0142\n",
      "Epoch [150/200], Loss: 0.0141\n",
      "Epoch [200/200], Loss: 0.0125\n",
      "\n",
      "Training model for China\n",
      "Epoch [50/200], Loss: 0.0072\n",
      "Epoch [100/200], Loss: 0.0039\n",
      "Epoch [150/200], Loss: 0.0029\n",
      "Epoch [200/200], Loss: 0.0026\n",
      "\n",
      "Training model for Christmas Island\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Colombia\n",
      "Epoch [50/200], Loss: 0.0411\n",
      "Epoch [100/200], Loss: 0.0218\n",
      "Epoch [150/200], Loss: 0.0179\n",
      "Epoch [200/200], Loss: 0.0243\n",
      "\n",
      "Training model for Comoros\n",
      "Epoch [50/200], Loss: 0.0113\n",
      "Epoch [100/200], Loss: 0.0109\n",
      "Epoch [150/200], Loss: 0.0106\n",
      "Epoch [200/200], Loss: 0.0086\n",
      "\n",
      "Training model for Congo\n",
      "Epoch [50/200], Loss: 0.0188\n",
      "Epoch [100/200], Loss: 0.0133\n",
      "Epoch [150/200], Loss: 0.0116\n",
      "Epoch [200/200], Loss: 0.0101\n",
      "\n",
      "Training model for Cook Islands\n",
      "Epoch [50/200], Loss: 0.0154\n",
      "Epoch [100/200], Loss: 0.0119\n",
      "Epoch [150/200], Loss: 0.0100\n",
      "Epoch [200/200], Loss: 0.0091\n",
      "\n",
      "Training model for Costa Rica\n",
      "Epoch [50/200], Loss: 0.0123\n",
      "Epoch [100/200], Loss: 0.0116\n",
      "Epoch [150/200], Loss: 0.0118\n",
      "Epoch [200/200], Loss: 0.0104\n",
      "\n",
      "Training model for Cote d'Ivoire\n",
      "Epoch [50/200], Loss: 0.0659\n",
      "Epoch [100/200], Loss: 0.0607\n",
      "Epoch [150/200], Loss: 0.0440\n",
      "Epoch [200/200], Loss: 0.0409\n",
      "\n",
      "Training model for Croatia\n",
      "Epoch [50/200], Loss: 0.0239\n",
      "Epoch [100/200], Loss: 0.0090\n",
      "Epoch [150/200], Loss: 0.0067\n",
      "Epoch [200/200], Loss: 0.0053\n",
      "\n",
      "Training model for Cuba\n",
      "Epoch [50/200], Loss: 0.0265\n",
      "Epoch [100/200], Loss: 0.0225\n",
      "Epoch [150/200], Loss: 0.0194\n",
      "Epoch [200/200], Loss: 0.0144\n",
      "\n",
      "Training model for Curacao\n",
      "Epoch [50/200], Loss: 0.0672\n",
      "Epoch [100/200], Loss: 0.0519\n",
      "Epoch [150/200], Loss: 0.0359\n",
      "Epoch [200/200], Loss: 0.0323\n",
      "\n",
      "Training model for Cyprus\n",
      "Epoch [50/200], Loss: 0.0433\n",
      "Epoch [100/200], Loss: 0.0138\n",
      "Epoch [150/200], Loss: 0.0066\n",
      "Epoch [200/200], Loss: 0.0055\n",
      "\n",
      "Training model for Czechia\n",
      "Epoch [50/200], Loss: 0.0058\n",
      "Epoch [100/200], Loss: 0.0046\n",
      "Epoch [150/200], Loss: 0.0044\n",
      "Epoch [200/200], Loss: 0.0036\n",
      "\n",
      "Training model for Democratic Republic of Congo\n",
      "Epoch [50/200], Loss: 0.0127\n",
      "Epoch [100/200], Loss: 0.0102\n",
      "Epoch [150/200], Loss: 0.0060\n",
      "Epoch [200/200], Loss: 0.0051\n",
      "\n",
      "Training model for Denmark\n",
      "Epoch [50/200], Loss: 0.0085\n",
      "Epoch [100/200], Loss: 0.0083\n",
      "Epoch [150/200], Loss: 0.0077\n",
      "Epoch [200/200], Loss: 0.0084\n",
      "\n",
      "Training model for Djibouti\n",
      "Epoch [50/200], Loss: 0.0538\n",
      "Epoch [100/200], Loss: 0.0502\n",
      "Epoch [150/200], Loss: 0.0485\n",
      "Epoch [200/200], Loss: 0.0555\n",
      "\n",
      "Training model for Dominica\n",
      "Epoch [50/200], Loss: 0.0130\n",
      "Epoch [100/200], Loss: 0.0058\n",
      "Epoch [150/200], Loss: 0.0052\n",
      "Epoch [200/200], Loss: 0.0042\n",
      "\n",
      "Training model for Dominican Republic\n",
      "Epoch [50/200], Loss: 0.0142\n",
      "Epoch [100/200], Loss: 0.0114\n",
      "Epoch [150/200], Loss: 0.0090\n",
      "Epoch [200/200], Loss: 0.0096\n",
      "\n",
      "Training model for East Timor\n",
      "Epoch [50/200], Loss: 0.0291\n",
      "Epoch [100/200], Loss: 0.0255\n",
      "Epoch [150/200], Loss: 0.0222\n",
      "Epoch [200/200], Loss: 0.0215\n",
      "\n",
      "Training model for Ecuador\n",
      "Epoch [50/200], Loss: 0.0202\n",
      "Epoch [100/200], Loss: 0.0187\n",
      "Epoch [150/200], Loss: 0.0157\n",
      "Epoch [200/200], Loss: 0.0141\n",
      "\n",
      "Training model for Egypt\n",
      "Epoch [50/200], Loss: 0.0124\n",
      "Epoch [100/200], Loss: 0.0091\n",
      "Epoch [150/200], Loss: 0.0080\n",
      "Epoch [200/200], Loss: 0.0081\n",
      "\n",
      "Training model for El Salvador\n",
      "Epoch [50/200], Loss: 0.0096\n",
      "Epoch [100/200], Loss: 0.0075\n",
      "Epoch [150/200], Loss: 0.0072\n",
      "Epoch [200/200], Loss: 0.0072\n",
      "\n",
      "Training model for Equatorial Guinea\n",
      "Epoch [50/200], Loss: 0.0175\n",
      "Epoch [100/200], Loss: 0.0171\n",
      "Epoch [150/200], Loss: 0.0159\n",
      "Epoch [200/200], Loss: 0.0145\n",
      "\n",
      "Training model for Eritrea\n",
      "Epoch [50/200], Loss: 0.0256\n",
      "Epoch [100/200], Loss: 0.0105\n",
      "Epoch [150/200], Loss: 0.0041\n",
      "Epoch [200/200], Loss: 0.0038\n",
      "\n",
      "Training model for Estonia\n",
      "Epoch [50/200], Loss: 0.0161\n",
      "Epoch [100/200], Loss: 0.0111\n",
      "Epoch [150/200], Loss: 0.0093\n",
      "Epoch [200/200], Loss: 0.0083\n",
      "\n",
      "Training model for Eswatini\n",
      "Epoch [50/200], Loss: 0.0499\n",
      "Epoch [100/200], Loss: 0.0483\n",
      "Epoch [150/200], Loss: 0.0480\n",
      "Epoch [200/200], Loss: 0.0443\n",
      "\n",
      "Training model for Ethiopia\n",
      "Epoch [50/200], Loss: 0.0146\n",
      "Epoch [100/200], Loss: 0.0102\n",
      "Epoch [150/200], Loss: 0.0048\n",
      "Epoch [200/200], Loss: 0.0037\n",
      "\n",
      "Training model for Europe\n",
      "Epoch [50/200], Loss: 0.0088\n",
      "Epoch [100/200], Loss: 0.0049\n",
      "Epoch [150/200], Loss: 0.0038\n",
      "Epoch [200/200], Loss: 0.0033\n",
      "\n",
      "Training model for Europe (GCP)\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Europe (excl. EU-27)\n",
      "Epoch [50/200], Loss: 0.0031\n",
      "Epoch [100/200], Loss: 0.0023\n",
      "Epoch [150/200], Loss: 0.0016\n",
      "Epoch [200/200], Loss: 0.0015\n",
      "\n",
      "Training model for Europe (excl. EU-28)\n",
      "Epoch [50/200], Loss: 0.0041\n",
      "Epoch [100/200], Loss: 0.0030\n",
      "Epoch [150/200], Loss: 0.0019\n",
      "Epoch [200/200], Loss: 0.0018\n",
      "\n",
      "Training model for European Union (27)\n",
      "Epoch [50/200], Loss: 0.0068\n",
      "Epoch [100/200], Loss: 0.0065\n",
      "Epoch [150/200], Loss: 0.0066\n",
      "Epoch [200/200], Loss: 0.0056\n",
      "\n",
      "Training model for European Union (28)\n",
      "Epoch [50/200], Loss: 0.0062\n",
      "Epoch [100/200], Loss: 0.0055\n",
      "Epoch [150/200], Loss: 0.0059\n",
      "Epoch [200/200], Loss: 0.0053\n",
      "\n",
      "Training model for Faroe Islands\n",
      "Epoch [50/200], Loss: 0.0453\n",
      "Epoch [100/200], Loss: 0.0201\n",
      "Epoch [150/200], Loss: 0.0169\n",
      "Epoch [200/200], Loss: 0.0172\n",
      "\n",
      "Training model for Fiji\n",
      "Epoch [50/200], Loss: 0.0630\n",
      "Epoch [100/200], Loss: 0.0434\n",
      "Epoch [150/200], Loss: 0.0423\n",
      "Epoch [200/200], Loss: 0.0394\n",
      "\n",
      "Training model for Finland\n",
      "Epoch [50/200], Loss: 0.0192\n",
      "Epoch [100/200], Loss: 0.0168\n",
      "Epoch [150/200], Loss: 0.0136\n",
      "Epoch [200/200], Loss: 0.0157\n",
      "\n",
      "Training model for France\n",
      "Epoch [50/200], Loss: 0.0058\n",
      "Epoch [100/200], Loss: 0.0056\n",
      "Epoch [150/200], Loss: 0.0063\n",
      "Epoch [200/200], Loss: 0.0049\n",
      "\n",
      "Training model for French Polynesia\n",
      "Epoch [50/200], Loss: 0.0256\n",
      "Epoch [100/200], Loss: 0.0192\n",
      "Epoch [150/200], Loss: 0.0110\n",
      "Epoch [200/200], Loss: 0.0094\n",
      "\n",
      "Training model for Gabon\n",
      "Epoch [50/200], Loss: 0.0198\n",
      "Epoch [100/200], Loss: 0.0142\n",
      "Epoch [150/200], Loss: 0.0120\n",
      "Epoch [200/200], Loss: 0.0088\n",
      "\n",
      "Training model for Gambia\n",
      "Epoch [50/200], Loss: 0.0144\n",
      "Epoch [100/200], Loss: 0.0103\n",
      "Epoch [150/200], Loss: 0.0111\n",
      "Epoch [200/200], Loss: 0.0091\n",
      "\n",
      "Training model for Georgia\n",
      "Epoch [50/200], Loss: 0.0317\n",
      "Epoch [100/200], Loss: 0.0063\n",
      "Epoch [150/200], Loss: 0.0060\n",
      "Epoch [200/200], Loss: 0.0044\n",
      "\n",
      "Training model for Germany\n",
      "Epoch [50/200], Loss: 0.0049\n",
      "Epoch [100/200], Loss: 0.0022\n",
      "Epoch [150/200], Loss: 0.0024\n",
      "Epoch [200/200], Loss: 0.0021\n",
      "\n",
      "Training model for Ghana\n",
      "Epoch [50/200], Loss: 0.0145\n",
      "Epoch [100/200], Loss: 0.0117\n",
      "Epoch [150/200], Loss: 0.0134\n",
      "Epoch [200/200], Loss: 0.0128\n",
      "\n",
      "Training model for Greece\n",
      "Epoch [50/200], Loss: 0.0254\n",
      "Epoch [100/200], Loss: 0.0150\n",
      "Epoch [150/200], Loss: 0.0052\n",
      "Epoch [200/200], Loss: 0.0047\n",
      "\n",
      "Training model for Greenland\n",
      "Epoch [50/200], Loss: 0.0439\n",
      "Epoch [100/200], Loss: 0.0417\n",
      "Epoch [150/200], Loss: 0.0346\n",
      "Epoch [200/200], Loss: 0.0323\n",
      "\n",
      "Training model for Grenada\n",
      "Epoch [50/200], Loss: 0.0049\n",
      "Epoch [100/200], Loss: 0.0048\n",
      "Epoch [150/200], Loss: 0.0059\n",
      "Epoch [200/200], Loss: 0.0058\n",
      "\n",
      "Training model for Guatemala\n",
      "Epoch [50/200], Loss: 0.0195\n",
      "Epoch [100/200], Loss: 0.0136\n",
      "Epoch [150/200], Loss: 0.0112\n",
      "Epoch [200/200], Loss: 0.0106\n",
      "\n",
      "Training model for Guinea\n",
      "Epoch [50/200], Loss: 0.0209\n",
      "Epoch [100/200], Loss: 0.0200\n",
      "Epoch [150/200], Loss: 0.0123\n",
      "Epoch [200/200], Loss: 0.0111\n",
      "\n",
      "Training model for Guinea-Bissau\n",
      "Epoch [50/200], Loss: 0.0465\n",
      "Epoch [100/200], Loss: 0.0279\n",
      "Epoch [150/200], Loss: 0.0232\n",
      "Epoch [200/200], Loss: 0.0200\n",
      "\n",
      "Training model for Guyana\n",
      "Epoch [50/200], Loss: 0.0087\n",
      "Epoch [100/200], Loss: 0.0075\n",
      "Epoch [150/200], Loss: 0.0073\n",
      "Epoch [200/200], Loss: 0.0045\n",
      "\n",
      "Training model for Haiti\n",
      "Epoch [50/200], Loss: 0.0043\n",
      "Epoch [100/200], Loss: 0.0044\n",
      "Epoch [150/200], Loss: 0.0041\n",
      "Epoch [200/200], Loss: 0.0038\n",
      "\n",
      "Training model for High-income countries\n",
      "Epoch [50/200], Loss: 0.0168\n",
      "Epoch [100/200], Loss: 0.0129\n",
      "Epoch [150/200], Loss: 0.0136\n",
      "Epoch [200/200], Loss: 0.0092\n",
      "\n",
      "Training model for Honduras\n",
      "Epoch [50/200], Loss: 0.0078\n",
      "Epoch [100/200], Loss: 0.0065\n",
      "Epoch [150/200], Loss: 0.0065\n",
      "Epoch [200/200], Loss: 0.0057\n",
      "\n",
      "Training model for Hong Kong\n",
      "Epoch [50/200], Loss: 0.0719\n",
      "Epoch [100/200], Loss: 0.0477\n",
      "Epoch [150/200], Loss: 0.0312\n",
      "Epoch [200/200], Loss: 0.0262\n",
      "\n",
      "Training model for Hungary\n",
      "Epoch [50/200], Loss: 0.0124\n",
      "Epoch [100/200], Loss: 0.0099\n",
      "Epoch [150/200], Loss: 0.0067\n",
      "Epoch [200/200], Loss: 0.0050\n",
      "\n",
      "Training model for Iceland\n",
      "Epoch [50/200], Loss: 0.0196\n",
      "Epoch [100/200], Loss: 0.0191\n",
      "Epoch [150/200], Loss: 0.0117\n",
      "Epoch [200/200], Loss: 0.0086\n",
      "\n",
      "Training model for India\n",
      "Epoch [50/200], Loss: 0.0032\n",
      "Epoch [100/200], Loss: 0.0016\n",
      "Epoch [150/200], Loss: 0.0017\n",
      "Epoch [200/200], Loss: 0.0016\n",
      "\n",
      "Training model for Indonesia\n",
      "Epoch [50/200], Loss: 0.0045\n",
      "Epoch [100/200], Loss: 0.0041\n",
      "Epoch [150/200], Loss: 0.0039\n",
      "Epoch [200/200], Loss: 0.0046\n",
      "\n",
      "Training model for International aviation\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for International shipping\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for International transport\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Iran\n",
      "Epoch [50/200], Loss: 0.0023\n",
      "Epoch [100/200], Loss: 0.0021\n",
      "Epoch [150/200], Loss: 0.0023\n",
      "Epoch [200/200], Loss: 0.0020\n",
      "\n",
      "Training model for Iraq\n",
      "Epoch [50/200], Loss: 0.0299\n",
      "Epoch [100/200], Loss: 0.0290\n",
      "Epoch [150/200], Loss: 0.0367\n",
      "Epoch [200/200], Loss: 0.0248\n",
      "\n",
      "Training model for Ireland\n",
      "Epoch [50/200], Loss: 0.0262\n",
      "Epoch [100/200], Loss: 0.0149\n",
      "Epoch [150/200], Loss: 0.0077\n",
      "Epoch [200/200], Loss: 0.0052\n",
      "\n",
      "Training model for Israel\n",
      "Epoch [50/200], Loss: 0.0403\n",
      "Epoch [100/200], Loss: 0.0227\n",
      "Epoch [150/200], Loss: 0.0192\n",
      "Epoch [200/200], Loss: 0.0164\n",
      "\n",
      "Training model for Italy\n",
      "Epoch [50/200], Loss: 0.0219\n",
      "Epoch [100/200], Loss: 0.0206\n",
      "Epoch [150/200], Loss: 0.0133\n",
      "Epoch [200/200], Loss: 0.0068\n",
      "\n",
      "Training model for Jamaica\n",
      "Epoch [50/200], Loss: 0.0450\n",
      "Epoch [100/200], Loss: 0.0319\n",
      "Epoch [150/200], Loss: 0.0269\n",
      "Epoch [200/200], Loss: 0.0222\n",
      "\n",
      "Training model for Japan\n",
      "Epoch [50/200], Loss: 0.0399\n",
      "Epoch [100/200], Loss: 0.0286\n",
      "Epoch [150/200], Loss: 0.0158\n",
      "Epoch [200/200], Loss: 0.0139\n",
      "\n",
      "Training model for Jordan\n",
      "Epoch [50/200], Loss: 0.0274\n",
      "Epoch [100/200], Loss: 0.0139\n",
      "Epoch [150/200], Loss: 0.0108\n",
      "Epoch [200/200], Loss: 0.0085\n",
      "\n",
      "Training model for Kazakhstan\n",
      "Epoch [50/200], Loss: 0.0338\n",
      "Epoch [100/200], Loss: 0.0093\n",
      "Epoch [150/200], Loss: 0.0079\n",
      "Epoch [200/200], Loss: 0.0061\n",
      "\n",
      "Training model for Kenya\n",
      "Epoch [50/200], Loss: 0.0463\n",
      "Epoch [100/200], Loss: 0.0286\n",
      "Epoch [150/200], Loss: 0.0175\n",
      "Epoch [200/200], Loss: 0.0165\n",
      "\n",
      "Training model for Kiribati\n",
      "Epoch [50/200], Loss: 0.0167\n",
      "Epoch [100/200], Loss: 0.0154\n",
      "Epoch [150/200], Loss: 0.0148\n",
      "Epoch [200/200], Loss: 0.0152\n",
      "\n",
      "Training model for Kosovo\n",
      "Epoch [50/200], Loss: 0.0584\n",
      "Epoch [100/200], Loss: 0.0340\n",
      "Epoch [150/200], Loss: 0.0215\n",
      "Epoch [200/200], Loss: 0.0193\n",
      "\n",
      "Training model for Kuwait\n",
      "Epoch [50/200], Loss: 0.0001\n",
      "Epoch [100/200], Loss: 0.0001\n",
      "Epoch [150/200], Loss: 0.0001\n",
      "Epoch [200/200], Loss: 0.0001\n",
      "\n",
      "Training model for Kuwaiti Oil Fires\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Kuwaiti Oil Fires (GCP)\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Kyrgyzstan\n",
      "Epoch [50/200], Loss: 0.0052\n",
      "Epoch [100/200], Loss: 0.0027\n",
      "Epoch [150/200], Loss: 0.0029\n",
      "Epoch [200/200], Loss: 0.0026\n",
      "\n",
      "Training model for Laos\n",
      "Epoch [50/200], Loss: 0.0263\n",
      "Epoch [100/200], Loss: 0.0078\n",
      "Epoch [150/200], Loss: 0.0064\n",
      "Epoch [200/200], Loss: 0.0040\n",
      "\n",
      "Training model for Latvia\n",
      "Epoch [50/200], Loss: 0.0030\n",
      "Epoch [100/200], Loss: 0.0030\n",
      "Epoch [150/200], Loss: 0.0027\n",
      "Epoch [200/200], Loss: 0.0023\n",
      "\n",
      "Training model for Least developed countries (Jones et al.)\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Lebanon\n",
      "Epoch [50/200], Loss: 0.0297\n",
      "Epoch [100/200], Loss: 0.0268\n",
      "Epoch [150/200], Loss: 0.0266\n",
      "Epoch [200/200], Loss: 0.0176\n",
      "\n",
      "Training model for Lesotho\n",
      "Epoch [50/200], Loss: 0.0447\n",
      "Epoch [100/200], Loss: 0.0264\n",
      "Epoch [150/200], Loss: 0.0209\n",
      "Epoch [200/200], Loss: 0.0221\n",
      "\n",
      "Training model for Liberia\n",
      "Epoch [50/200], Loss: 0.0752\n",
      "Epoch [100/200], Loss: 0.0400\n",
      "Epoch [150/200], Loss: 0.0369\n",
      "Epoch [200/200], Loss: 0.0352\n",
      "\n",
      "Training model for Libya\n",
      "Epoch [50/200], Loss: 0.0392\n",
      "Epoch [100/200], Loss: 0.0382\n",
      "Epoch [150/200], Loss: 0.0404\n",
      "Epoch [200/200], Loss: 0.0366\n",
      "\n",
      "Training model for Liechtenstein\n",
      "Epoch [50/200], Loss: 0.0084\n",
      "Epoch [100/200], Loss: 0.0080\n",
      "Epoch [150/200], Loss: 0.0080\n",
      "Epoch [200/200], Loss: 0.0080\n",
      "\n",
      "Training model for Lithuania\n",
      "Epoch [50/200], Loss: 0.0034\n",
      "Epoch [100/200], Loss: 0.0031\n",
      "Epoch [150/200], Loss: 0.0020\n",
      "Epoch [200/200], Loss: 0.0017\n",
      "\n",
      "Training model for Low-income countries\n",
      "Epoch [50/200], Loss: 0.0094\n",
      "Epoch [100/200], Loss: 0.0079\n",
      "Epoch [150/200], Loss: 0.0055\n",
      "Epoch [200/200], Loss: 0.0041\n",
      "\n",
      "Training model for Lower-middle-income countries\n",
      "Epoch [50/200], Loss: 0.0025\n",
      "Epoch [100/200], Loss: 0.0009\n",
      "Epoch [150/200], Loss: 0.0009\n",
      "Epoch [200/200], Loss: 0.0009\n",
      "\n",
      "Training model for Luxembourg\n",
      "Epoch [50/200], Loss: 0.0209\n",
      "Epoch [100/200], Loss: 0.0121\n",
      "Epoch [150/200], Loss: 0.0035\n",
      "Epoch [200/200], Loss: 0.0028\n",
      "\n",
      "Training model for Macao\n",
      "Epoch [50/200], Loss: 0.0622\n",
      "Epoch [100/200], Loss: 0.0558\n",
      "Epoch [150/200], Loss: 0.0552\n",
      "Epoch [200/200], Loss: 0.0525\n",
      "\n",
      "Training model for Madagascar\n",
      "Epoch [50/200], Loss: 0.0329\n",
      "Epoch [100/200], Loss: 0.0295\n",
      "Epoch [150/200], Loss: 0.0236\n",
      "Epoch [200/200], Loss: 0.0209\n",
      "\n",
      "Training model for Malawi\n",
      "Epoch [50/200], Loss: 0.0575\n",
      "Epoch [100/200], Loss: 0.0326\n",
      "Epoch [150/200], Loss: 0.0403\n",
      "Epoch [200/200], Loss: 0.0414\n",
      "\n",
      "Training model for Malaysia\n",
      "Epoch [50/200], Loss: 0.0058\n",
      "Epoch [100/200], Loss: 0.0054\n",
      "Epoch [150/200], Loss: 0.0054\n",
      "Epoch [200/200], Loss: 0.0056\n",
      "\n",
      "Training model for Maldives\n",
      "Epoch [50/200], Loss: 0.0035\n",
      "Epoch [100/200], Loss: 0.0028\n",
      "Epoch [150/200], Loss: 0.0031\n",
      "Epoch [200/200], Loss: 0.0029\n",
      "\n",
      "Training model for Mali\n",
      "Epoch [50/200], Loss: 0.0040\n",
      "Epoch [100/200], Loss: 0.0033\n",
      "Epoch [150/200], Loss: 0.0019\n",
      "Epoch [200/200], Loss: 0.0013\n",
      "\n",
      "Training model for Malta\n",
      "Epoch [50/200], Loss: 0.0190\n",
      "Epoch [100/200], Loss: 0.0156\n",
      "Epoch [150/200], Loss: 0.0118\n",
      "Epoch [200/200], Loss: 0.0105\n",
      "\n",
      "Training model for Marshall Islands\n",
      "Epoch [50/200], Loss: 0.0017\n",
      "Epoch [100/200], Loss: 0.0008\n",
      "Epoch [150/200], Loss: 0.0009\n",
      "Epoch [200/200], Loss: 0.0007\n",
      "\n",
      "Training model for Mauritania\n",
      "Epoch [50/200], Loss: 0.0176\n",
      "Epoch [100/200], Loss: 0.0151\n",
      "Epoch [150/200], Loss: 0.0127\n",
      "Epoch [200/200], Loss: 0.0100\n",
      "\n",
      "Training model for Mauritius\n",
      "Epoch [50/200], Loss: 0.0069\n",
      "Epoch [100/200], Loss: 0.0042\n",
      "Epoch [150/200], Loss: 0.0048\n",
      "Epoch [200/200], Loss: 0.0041\n",
      "\n",
      "Training model for Mexico\n",
      "Epoch [50/200], Loss: 0.0386\n",
      "Epoch [100/200], Loss: 0.0255\n",
      "Epoch [150/200], Loss: 0.0175\n",
      "Epoch [200/200], Loss: 0.0178\n",
      "\n",
      "Training model for Micronesia (country)\n",
      "Epoch [50/200], Loss: 0.0129\n",
      "Epoch [100/200], Loss: 0.0121\n",
      "Epoch [150/200], Loss: 0.0102\n",
      "Epoch [200/200], Loss: 0.0040\n",
      "\n",
      "Training model for Middle East (GCP)\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Moldova\n",
      "Epoch [50/200], Loss: 0.0018\n",
      "Epoch [100/200], Loss: 0.0017\n",
      "Epoch [150/200], Loss: 0.0015\n",
      "Epoch [200/200], Loss: 0.0012\n",
      "\n",
      "Training model for Monaco\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Mongolia\n",
      "Epoch [50/200], Loss: 0.0407\n",
      "Epoch [100/200], Loss: 0.0309\n",
      "Epoch [150/200], Loss: 0.0191\n",
      "Epoch [200/200], Loss: 0.0049\n",
      "\n",
      "Training model for Montenegro\n",
      "Epoch [50/200], Loss: 0.0304\n",
      "Epoch [100/200], Loss: 0.0269\n",
      "Epoch [150/200], Loss: 0.0261\n",
      "Epoch [200/200], Loss: 0.0277\n",
      "\n",
      "Training model for Montserrat\n",
      "Epoch [50/200], Loss: 0.0419\n",
      "Epoch [100/200], Loss: 0.0396\n",
      "Epoch [150/200], Loss: 0.0339\n",
      "Epoch [200/200], Loss: 0.0352\n",
      "\n",
      "Training model for Morocco\n",
      "Epoch [50/200], Loss: 0.0062\n",
      "Epoch [100/200], Loss: 0.0044\n",
      "Epoch [150/200], Loss: 0.0041\n",
      "Epoch [200/200], Loss: 0.0039\n",
      "\n",
      "Training model for Mozambique\n",
      "Epoch [50/200], Loss: 0.0434\n",
      "Epoch [100/200], Loss: 0.0224\n",
      "Epoch [150/200], Loss: 0.0129\n",
      "Epoch [200/200], Loss: 0.0124\n",
      "\n",
      "Training model for Myanmar\n",
      "Epoch [50/200], Loss: 0.0179\n",
      "Epoch [100/200], Loss: 0.0133\n",
      "Epoch [150/200], Loss: 0.0045\n",
      "Epoch [200/200], Loss: 0.0047\n",
      "\n",
      "Training model for Namibia\n",
      "Epoch [50/200], Loss: 0.0099\n",
      "Epoch [100/200], Loss: 0.0054\n",
      "Epoch [150/200], Loss: 0.0052\n",
      "Epoch [200/200], Loss: 0.0057\n",
      "\n",
      "Training model for Nauru\n",
      "Epoch [50/200], Loss: 0.0028\n",
      "Epoch [100/200], Loss: 0.0027\n",
      "Epoch [150/200], Loss: 0.0025\n",
      "Epoch [200/200], Loss: 0.0021\n",
      "\n",
      "Training model for Nepal\n",
      "Epoch [50/200], Loss: 0.0087\n",
      "Epoch [100/200], Loss: 0.0063\n",
      "Epoch [150/200], Loss: 0.0045\n",
      "Epoch [200/200], Loss: 0.0039\n",
      "\n",
      "Training model for Netherlands\n",
      "Epoch [50/200], Loss: 0.0081\n",
      "Epoch [100/200], Loss: 0.0073\n",
      "Epoch [150/200], Loss: 0.0054\n",
      "Epoch [200/200], Loss: 0.0046\n",
      "\n",
      "Training model for New Caledonia\n",
      "Epoch [50/200], Loss: 0.0218\n",
      "Epoch [100/200], Loss: 0.0132\n",
      "Epoch [150/200], Loss: 0.0093\n",
      "Epoch [200/200], Loss: 0.0061\n",
      "\n",
      "Training model for New Zealand\n",
      "Epoch [50/200], Loss: 0.0271\n",
      "Epoch [100/200], Loss: 0.0222\n",
      "Epoch [150/200], Loss: 0.0146\n",
      "Epoch [200/200], Loss: 0.0077\n",
      "\n",
      "Training model for Nicaragua\n",
      "Epoch [50/200], Loss: 0.0115\n",
      "Epoch [100/200], Loss: 0.0112\n",
      "Epoch [150/200], Loss: 0.0087\n",
      "Epoch [200/200], Loss: 0.0079\n",
      "\n",
      "Training model for Niger\n",
      "Epoch [50/200], Loss: 0.0411\n",
      "Epoch [100/200], Loss: 0.0251\n",
      "Epoch [150/200], Loss: 0.0136\n",
      "Epoch [200/200], Loss: 0.0146\n",
      "\n",
      "Training model for Nigeria\n",
      "Epoch [50/200], Loss: 0.0369\n",
      "Epoch [100/200], Loss: 0.0280\n",
      "Epoch [150/200], Loss: 0.0133\n",
      "Epoch [200/200], Loss: 0.0130\n",
      "\n",
      "Training model for Niue\n",
      "Epoch [50/200], Loss: 0.0477\n",
      "Epoch [100/200], Loss: 0.0503\n",
      "Epoch [150/200], Loss: 0.0427\n",
      "Epoch [200/200], Loss: 0.0416\n",
      "\n",
      "Training model for Non-OECD (GCP)\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for North America\n",
      "Epoch [50/200], Loss: 0.0115\n",
      "Epoch [100/200], Loss: 0.0098\n",
      "Epoch [150/200], Loss: 0.0088\n",
      "Epoch [200/200], Loss: 0.0059\n",
      "\n",
      "Training model for North America (GCP)\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for North America (excl. USA)\n",
      "Epoch [50/200], Loss: 0.0274\n",
      "Epoch [100/200], Loss: 0.0238\n",
      "Epoch [150/200], Loss: 0.0136\n",
      "Epoch [200/200], Loss: 0.0121\n",
      "\n",
      "Training model for North Korea\n",
      "Epoch [50/200], Loss: 0.0112\n",
      "Epoch [100/200], Loss: 0.0089\n",
      "Epoch [150/200], Loss: 0.0063\n",
      "Epoch [200/200], Loss: 0.0055\n",
      "\n",
      "Training model for North Macedonia\n",
      "Epoch [50/200], Loss: 0.0270\n",
      "Epoch [100/200], Loss: 0.0228\n",
      "Epoch [150/200], Loss: 0.0169\n",
      "Epoch [200/200], Loss: 0.0168\n",
      "\n",
      "Training model for Norway\n",
      "Epoch [50/200], Loss: 0.0316\n",
      "Epoch [100/200], Loss: 0.0187\n",
      "Epoch [150/200], Loss: 0.0066\n",
      "Epoch [200/200], Loss: 0.0050\n",
      "\n",
      "Training model for OECD (GCP)\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for OECD (Jones et al.)\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Oceania\n",
      "Epoch [50/200], Loss: 0.0270\n",
      "Epoch [100/200], Loss: 0.0176\n",
      "Epoch [150/200], Loss: 0.0036\n",
      "Epoch [200/200], Loss: 0.0024\n",
      "\n",
      "Training model for Oceania (GCP)\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Oman\n",
      "Epoch [50/200], Loss: 0.0160\n",
      "Epoch [100/200], Loss: 0.0110\n",
      "Epoch [150/200], Loss: 0.0090\n",
      "Epoch [200/200], Loss: 0.0084\n",
      "\n",
      "Training model for Pakistan\n",
      "Epoch [50/200], Loss: 0.0271\n",
      "Epoch [100/200], Loss: 0.0215\n",
      "Epoch [150/200], Loss: 0.0166\n",
      "Epoch [200/200], Loss: 0.0132\n",
      "\n",
      "Training model for Palau\n",
      "Epoch [50/200], Loss: 0.0195\n",
      "Epoch [100/200], Loss: 0.0175\n",
      "Epoch [150/200], Loss: 0.0168\n",
      "Epoch [200/200], Loss: 0.0144\n",
      "\n",
      "Training model for Palestine\n",
      "Epoch [50/200], Loss: 0.0472\n",
      "Epoch [100/200], Loss: 0.0380\n",
      "Epoch [150/200], Loss: 0.0333\n",
      "Epoch [200/200], Loss: 0.0258\n",
      "\n",
      "Training model for Panama\n",
      "Epoch [50/200], Loss: 0.0243\n",
      "Epoch [100/200], Loss: 0.0215\n",
      "Epoch [150/200], Loss: 0.0250\n",
      "Epoch [200/200], Loss: 0.0232\n",
      "\n",
      "Training model for Papua New Guinea\n",
      "Epoch [50/200], Loss: 0.0424\n",
      "Epoch [100/200], Loss: 0.0308\n",
      "Epoch [150/200], Loss: 0.0269\n",
      "Epoch [200/200], Loss: 0.0239\n",
      "\n",
      "Training model for Paraguay\n",
      "Epoch [50/200], Loss: 0.0222\n",
      "Epoch [100/200], Loss: 0.0164\n",
      "Epoch [150/200], Loss: 0.0114\n",
      "Epoch [200/200], Loss: 0.0074\n",
      "\n",
      "Training model for Peru\n",
      "Epoch [50/200], Loss: 0.0238\n",
      "Epoch [100/200], Loss: 0.0213\n",
      "Epoch [150/200], Loss: 0.0172\n",
      "Epoch [200/200], Loss: 0.0149\n",
      "\n",
      "Training model for Philippines\n",
      "Epoch [50/200], Loss: 0.0185\n",
      "Epoch [100/200], Loss: 0.0142\n",
      "Epoch [150/200], Loss: 0.0095\n",
      "Epoch [200/200], Loss: 0.0072\n",
      "\n",
      "Training model for Poland\n",
      "Epoch [50/200], Loss: 0.0267\n",
      "Epoch [100/200], Loss: 0.0250\n",
      "Epoch [150/200], Loss: 0.0218\n",
      "Epoch [200/200], Loss: 0.0183\n",
      "\n",
      "Training model for Portugal\n",
      "Epoch [50/200], Loss: 0.0413\n",
      "Epoch [100/200], Loss: 0.0205\n",
      "Epoch [150/200], Loss: 0.0138\n",
      "Epoch [200/200], Loss: 0.0123\n",
      "\n",
      "Training model for Qatar\n",
      "Epoch [50/200], Loss: 0.0171\n",
      "Epoch [100/200], Loss: 0.0124\n",
      "Epoch [150/200], Loss: 0.0115\n",
      "Epoch [200/200], Loss: 0.0090\n",
      "\n",
      "Training model for Romania\n",
      "Epoch [50/200], Loss: 0.0087\n",
      "Epoch [100/200], Loss: 0.0088\n",
      "Epoch [150/200], Loss: 0.0080\n",
      "Epoch [200/200], Loss: 0.0064\n",
      "\n",
      "Training model for Russia\n",
      "Epoch [50/200], Loss: 0.0074\n",
      "Epoch [100/200], Loss: 0.0032\n",
      "Epoch [150/200], Loss: 0.0027\n",
      "Epoch [200/200], Loss: 0.0025\n",
      "\n",
      "Training model for Rwanda\n",
      "Epoch [50/200], Loss: 0.0182\n",
      "Epoch [100/200], Loss: 0.0144\n",
      "Epoch [150/200], Loss: 0.0102\n",
      "Epoch [200/200], Loss: 0.0091\n",
      "\n",
      "Training model for Ryukyu Islands\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Ryukyu Islands (GCP)\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Saint Helena\n",
      "Epoch [50/200], Loss: 0.0136\n",
      "Epoch [100/200], Loss: 0.0163\n",
      "Epoch [150/200], Loss: 0.0107\n",
      "Epoch [200/200], Loss: 0.0107\n",
      "\n",
      "Training model for Saint Kitts and Nevis\n",
      "Epoch [50/200], Loss: 0.0055\n",
      "Epoch [100/200], Loss: 0.0046\n",
      "Epoch [150/200], Loss: 0.0035\n",
      "Epoch [200/200], Loss: 0.0035\n",
      "\n",
      "Training model for Saint Lucia\n",
      "Epoch [50/200], Loss: 0.0034\n",
      "Epoch [100/200], Loss: 0.0030\n",
      "Epoch [150/200], Loss: 0.0029\n",
      "Epoch [200/200], Loss: 0.0030\n",
      "\n",
      "Training model for Saint Pierre and Miquelon\n",
      "Epoch [50/200], Loss: 0.0116\n",
      "Epoch [100/200], Loss: 0.0071\n",
      "Epoch [150/200], Loss: 0.0044\n",
      "Epoch [200/200], Loss: 0.0031\n",
      "\n",
      "Training model for Saint Vincent and the Grenadines\n",
      "Epoch [50/200], Loss: 0.0078\n",
      "Epoch [100/200], Loss: 0.0075\n",
      "Epoch [150/200], Loss: 0.0053\n",
      "Epoch [200/200], Loss: 0.0048\n",
      "\n",
      "Training model for Samoa\n",
      "Epoch [50/200], Loss: 0.0060\n",
      "Epoch [100/200], Loss: 0.0064\n",
      "Epoch [150/200], Loss: 0.0065\n",
      "Epoch [200/200], Loss: 0.0059\n",
      "\n",
      "Training model for San Marino\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Sao Tome and Principe\n",
      "Epoch [50/200], Loss: 0.0139\n",
      "Epoch [100/200], Loss: 0.0109\n",
      "Epoch [150/200], Loss: 0.0097\n",
      "Epoch [200/200], Loss: 0.0071\n",
      "\n",
      "Training model for Saudi Arabia\n",
      "Epoch [50/200], Loss: 0.0350\n",
      "Epoch [100/200], Loss: 0.0246\n",
      "Epoch [150/200], Loss: 0.0114\n",
      "Epoch [200/200], Loss: 0.0095\n",
      "\n",
      "Training model for Senegal\n",
      "Epoch [50/200], Loss: 0.0254\n",
      "Epoch [100/200], Loss: 0.0205\n",
      "Epoch [150/200], Loss: 0.0180\n",
      "Epoch [200/200], Loss: 0.0139\n",
      "\n",
      "Training model for Serbia\n",
      "Epoch [50/200], Loss: 0.0381\n",
      "Epoch [100/200], Loss: 0.0324\n",
      "Epoch [150/200], Loss: 0.0328\n",
      "Epoch [200/200], Loss: 0.0323\n",
      "\n",
      "Training model for Seychelles\n",
      "Epoch [50/200], Loss: 0.0106\n",
      "Epoch [100/200], Loss: 0.0102\n",
      "Epoch [150/200], Loss: 0.0094\n",
      "Epoch [200/200], Loss: 0.0094\n",
      "\n",
      "Training model for Sierra Leone\n",
      "Epoch [50/200], Loss: 0.0412\n",
      "Epoch [100/200], Loss: 0.0263\n",
      "Epoch [150/200], Loss: 0.0161\n",
      "Epoch [200/200], Loss: 0.0153\n",
      "\n",
      "Training model for Singapore\n",
      "Epoch [50/200], Loss: 0.0056\n",
      "Epoch [100/200], Loss: 0.0043\n",
      "Epoch [150/200], Loss: 0.0031\n",
      "Epoch [200/200], Loss: 0.0027\n",
      "\n",
      "Training model for Sint Maarten (Dutch part)\n",
      "Epoch [50/200], Loss: 0.0428\n",
      "Epoch [100/200], Loss: 0.0370\n",
      "Epoch [150/200], Loss: 0.0371\n",
      "Epoch [200/200], Loss: 0.0379\n",
      "\n",
      "Training model for Slovakia\n",
      "Epoch [50/200], Loss: 0.0036\n",
      "Epoch [100/200], Loss: 0.0031\n",
      "Epoch [150/200], Loss: 0.0026\n",
      "Epoch [200/200], Loss: 0.0025\n",
      "\n",
      "Training model for Slovenia\n",
      "Epoch [50/200], Loss: 0.0317\n",
      "Epoch [100/200], Loss: 0.0220\n",
      "Epoch [150/200], Loss: 0.0135\n",
      "Epoch [200/200], Loss: 0.0115\n",
      "\n",
      "Training model for Solomon Islands\n",
      "Epoch [50/200], Loss: 0.0524\n",
      "Epoch [100/200], Loss: 0.0083\n",
      "Epoch [150/200], Loss: 0.0076\n",
      "Epoch [200/200], Loss: 0.0068\n",
      "\n",
      "Training model for Somalia\n",
      "Epoch [50/200], Loss: 0.0028\n",
      "Epoch [100/200], Loss: 0.0017\n",
      "Epoch [150/200], Loss: 0.0014\n",
      "Epoch [200/200], Loss: 0.0012\n",
      "\n",
      "Training model for South Africa\n",
      "Epoch [50/200], Loss: 0.0382\n",
      "Epoch [100/200], Loss: 0.0307\n",
      "Epoch [150/200], Loss: 0.0195\n",
      "Epoch [200/200], Loss: 0.0167\n",
      "\n",
      "Training model for South America\n",
      "Epoch [50/200], Loss: 0.0245\n",
      "Epoch [100/200], Loss: 0.0083\n",
      "Epoch [150/200], Loss: 0.0081\n",
      "Epoch [200/200], Loss: 0.0070\n",
      "\n",
      "Training model for South America (GCP)\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for South Korea\n",
      "Epoch [50/200], Loss: 0.0082\n",
      "Epoch [100/200], Loss: 0.0083\n",
      "Epoch [150/200], Loss: 0.0069\n",
      "Epoch [200/200], Loss: 0.0074\n",
      "\n",
      "Training model for South Sudan\n",
      "Epoch [50/200], Loss: 0.0174\n",
      "Epoch [100/200], Loss: 0.0142\n",
      "Epoch [150/200], Loss: 0.0138\n",
      "Epoch [200/200], Loss: 0.0108\n",
      "\n",
      "Training model for Spain\n",
      "Epoch [50/200], Loss: 0.0346\n",
      "Epoch [100/200], Loss: 0.0138\n",
      "Epoch [150/200], Loss: 0.0086\n",
      "Epoch [200/200], Loss: 0.0080\n",
      "\n",
      "Training model for Sri Lanka\n",
      "Epoch [50/200], Loss: 0.0106\n",
      "Epoch [100/200], Loss: 0.0082\n",
      "Epoch [150/200], Loss: 0.0082\n",
      "Epoch [200/200], Loss: 0.0085\n",
      "\n",
      "Training model for Sudan\n",
      "Epoch [50/200], Loss: 0.0211\n",
      "Epoch [100/200], Loss: 0.0133\n",
      "Epoch [150/200], Loss: 0.0099\n",
      "Epoch [200/200], Loss: 0.0089\n",
      "\n",
      "Training model for Suriname\n",
      "Epoch [50/200], Loss: 0.0591\n",
      "Epoch [100/200], Loss: 0.0405\n",
      "Epoch [150/200], Loss: 0.0424\n",
      "Epoch [200/200], Loss: 0.0339\n",
      "\n",
      "Training model for Sweden\n",
      "Epoch [50/200], Loss: 0.0049\n",
      "Epoch [100/200], Loss: 0.0048\n",
      "Epoch [150/200], Loss: 0.0042\n",
      "Epoch [200/200], Loss: 0.0047\n",
      "\n",
      "Training model for Switzerland\n",
      "Epoch [50/200], Loss: 0.0041\n",
      "Epoch [100/200], Loss: 0.0035\n",
      "Epoch [150/200], Loss: 0.0033\n",
      "Epoch [200/200], Loss: 0.0029\n",
      "\n",
      "Training model for Syria\n",
      "Epoch [50/200], Loss: 0.0386\n",
      "Epoch [100/200], Loss: 0.0216\n",
      "Epoch [150/200], Loss: 0.0197\n",
      "Epoch [200/200], Loss: 0.0161\n",
      "\n",
      "Training model for Taiwan\n",
      "Epoch [50/200], Loss: 0.0048\n",
      "Epoch [100/200], Loss: 0.0045\n",
      "Epoch [150/200], Loss: 0.0028\n",
      "Epoch [200/200], Loss: 0.0025\n",
      "\n",
      "Training model for Tajikistan\n",
      "Epoch [50/200], Loss: 0.0091\n",
      "Epoch [100/200], Loss: 0.0016\n",
      "Epoch [150/200], Loss: 0.0016\n",
      "Epoch [200/200], Loss: 0.0012\n",
      "\n",
      "Training model for Tanzania\n",
      "Epoch [50/200], Loss: 0.0090\n",
      "Epoch [100/200], Loss: 0.0058\n",
      "Epoch [150/200], Loss: 0.0053\n",
      "Epoch [200/200], Loss: 0.0064\n",
      "\n",
      "Training model for Thailand\n",
      "Epoch [50/200], Loss: 0.0069\n",
      "Epoch [100/200], Loss: 0.0064\n",
      "Epoch [150/200], Loss: 0.0063\n",
      "Epoch [200/200], Loss: 0.0067\n",
      "\n",
      "Training model for Togo\n",
      "Epoch [50/200], Loss: 0.0638\n",
      "Epoch [100/200], Loss: 0.0560\n",
      "Epoch [150/200], Loss: 0.0438\n",
      "Epoch [200/200], Loss: 0.0287\n",
      "\n",
      "Training model for Tonga\n",
      "Epoch [50/200], Loss: 0.0129\n",
      "Epoch [100/200], Loss: 0.0118\n",
      "Epoch [150/200], Loss: 0.0119\n",
      "Epoch [200/200], Loss: 0.0103\n",
      "\n",
      "Training model for Trinidad and Tobago\n",
      "Epoch [50/200], Loss: 0.0245\n",
      "Epoch [100/200], Loss: 0.0165\n",
      "Epoch [150/200], Loss: 0.0049\n",
      "Epoch [200/200], Loss: 0.0045\n",
      "\n",
      "Training model for Tunisia\n",
      "Epoch [50/200], Loss: 0.0110\n",
      "Epoch [100/200], Loss: 0.0063\n",
      "Epoch [150/200], Loss: 0.0055\n",
      "Epoch [200/200], Loss: 0.0052\n",
      "\n",
      "Training model for Turkey\n",
      "Epoch [50/200], Loss: 0.0083\n",
      "Epoch [100/200], Loss: 0.0065\n",
      "Epoch [150/200], Loss: 0.0059\n",
      "Epoch [200/200], Loss: 0.0063\n",
      "\n",
      "Training model for Turkmenistan\n",
      "Epoch [50/200], Loss: 0.0335\n",
      "Epoch [100/200], Loss: 0.0313\n",
      "Epoch [150/200], Loss: 0.0268\n",
      "Epoch [200/200], Loss: 0.0264\n",
      "\n",
      "Training model for Turks and Caicos Islands\n",
      "Epoch [50/200], Loss: 0.0220\n",
      "Epoch [100/200], Loss: 0.0127\n",
      "Epoch [150/200], Loss: 0.0073\n",
      "Epoch [200/200], Loss: 0.0070\n",
      "\n",
      "Training model for Tuvalu\n",
      "Epoch [50/200], Loss: 0.0435\n",
      "Epoch [100/200], Loss: 0.0433\n",
      "Epoch [150/200], Loss: 0.0395\n",
      "Epoch [200/200], Loss: 0.0354\n",
      "\n",
      "Training model for Uganda\n",
      "Epoch [50/200], Loss: 0.0126\n",
      "Epoch [100/200], Loss: 0.0083\n",
      "Epoch [150/200], Loss: 0.0063\n",
      "Epoch [200/200], Loss: 0.0058\n",
      "\n",
      "Training model for Ukraine\n",
      "Epoch [50/200], Loss: 0.0053\n",
      "Epoch [100/200], Loss: 0.0037\n",
      "Epoch [150/200], Loss: 0.0023\n",
      "Epoch [200/200], Loss: 0.0021\n",
      "\n",
      "Training model for United Arab Emirates\n",
      "Epoch [50/200], Loss: 0.0467\n",
      "Epoch [100/200], Loss: 0.0395\n",
      "Epoch [150/200], Loss: 0.0344\n",
      "Epoch [200/200], Loss: 0.0326\n",
      "\n",
      "Training model for United Kingdom\n",
      "Epoch [50/200], Loss: 0.0025\n",
      "Epoch [100/200], Loss: 0.0023\n",
      "Epoch [150/200], Loss: 0.0023\n",
      "Epoch [200/200], Loss: 0.0025\n",
      "\n",
      "Training model for United States\n",
      "Epoch [50/200], Loss: 0.0110\n",
      "Epoch [100/200], Loss: 0.0099\n",
      "Epoch [150/200], Loss: 0.0081\n",
      "Epoch [200/200], Loss: 0.0069\n",
      "\n",
      "Training model for Upper-middle-income countries\n",
      "Epoch [50/200], Loss: 0.0113\n",
      "Epoch [100/200], Loss: 0.0040\n",
      "Epoch [150/200], Loss: 0.0027\n",
      "Epoch [200/200], Loss: 0.0028\n",
      "\n",
      "Training model for Uruguay\n",
      "Epoch [50/200], Loss: 0.0431\n",
      "Epoch [100/200], Loss: 0.0391\n",
      "Epoch [150/200], Loss: 0.0331\n",
      "Epoch [200/200], Loss: 0.0259\n",
      "\n",
      "Training model for Uzbekistan\n",
      "Epoch [50/200], Loss: 0.0185\n",
      "Epoch [100/200], Loss: 0.0196\n",
      "Epoch [150/200], Loss: 0.0191\n",
      "Epoch [200/200], Loss: 0.0180\n",
      "\n",
      "Training model for Vanuatu\n",
      "Epoch [50/200], Loss: 0.0268\n",
      "Epoch [100/200], Loss: 0.0270\n",
      "Epoch [150/200], Loss: 0.0263\n",
      "Epoch [200/200], Loss: 0.0235\n",
      "\n",
      "Training model for Vatican\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Venezuela\n",
      "Epoch [50/200], Loss: 0.0392\n",
      "Epoch [100/200], Loss: 0.0261\n",
      "Epoch [150/200], Loss: 0.0197\n",
      "Epoch [200/200], Loss: 0.0151\n",
      "\n",
      "Training model for Vietnam\n",
      "Epoch [50/200], Loss: 0.0063\n",
      "Epoch [100/200], Loss: 0.0045\n",
      "Epoch [150/200], Loss: 0.0039\n",
      "Epoch [200/200], Loss: 0.0041\n",
      "\n",
      "Training model for Wallis and Futuna\n",
      "Epoch [50/200], Loss: 0.0177\n",
      "Epoch [100/200], Loss: 0.0174\n",
      "Epoch [150/200], Loss: 0.0183\n",
      "Epoch [200/200], Loss: 0.0157\n",
      "\n",
      "Training model for World\n",
      "Epoch [50/200], Loss: 0.0305\n",
      "Epoch [100/200], Loss: 0.0270\n",
      "Epoch [150/200], Loss: 0.0176\n",
      "Epoch [200/200], Loss: 0.0115\n",
      "\n",
      "Training model for Yemen\n",
      "Epoch [50/200], Loss: 0.0488\n",
      "Epoch [100/200], Loss: 0.0360\n",
      "Epoch [150/200], Loss: 0.0198\n",
      "Epoch [200/200], Loss: 0.0129\n",
      "\n",
      "Training model for Zambia\n",
      "Epoch [50/200], Loss: 0.0364\n",
      "Epoch [100/200], Loss: 0.0171\n",
      "Epoch [150/200], Loss: 0.0098\n",
      "Epoch [200/200], Loss: 0.0105\n",
      "\n",
      "Training model for Zimbabwe\n",
      "Epoch [50/200], Loss: 0.0075\n",
      "Epoch [100/200], Loss: 0.0072\n",
      "Epoch [150/200], Loss: 0.0078\n",
      "Epoch [200/200], Loss: 0.0072\n"
     ]
    }
   ],
   "source": [
    "for country in df['Country']:\n",
    "        print(f\"\\nTraining model for {country}\")\n",
    "        \n",
    "        # Get country data\n",
    "        country_data = df[df['Country'] == country][cols].values.flatten()\n",
    "\n",
    "        country_data = country_data.astype(float)\n",
    "        \n",
    "        # Prepare data\n",
    "        X, y, scaler = prepare_country_data(country_data, sequence_length)\n",
    "        \n",
    "        if len(X) > 0:  # Check if we have enough data\n",
    "            # Train model\n",
    "            model = train_model(X, y)\n",
    "            \n",
    "            # Make predictions\n",
    "            last_sequence = scaler.transform(country_data[-sequence_length:].reshape(-1, 1))\n",
    "            predictions = predict_future(model, last_sequence, scaler)\n",
    "            predictions_by_country[country] = predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Internet (2024-2028):\n",
      "\n",
      "United States:\n",
      "2024: $14.28\n",
      "2025: $14.19\n",
      "2026: $14.13\n",
      "2027: $14.05\n",
      "2028: $13.99\n",
      "\n",
      "China:\n",
      "2024: $7.88\n",
      "2025: $7.91\n",
      "2026: $7.92\n",
      "2027: $7.90\n",
      "2028: $7.89\n",
      "\n",
      "Japan:\n",
      "2024: $7.72\n",
      "2025: $7.43\n",
      "2026: $7.10\n",
      "2027: $6.78\n",
      "2028: $6.49\n",
      "\n",
      "Germany:\n",
      "2024: $6.38\n",
      "2025: $5.96\n",
      "2026: $5.71\n",
      "2027: $5.22\n",
      "2028: $4.73\n",
      "\n",
      "United Kingdom:\n",
      "2024: $4.39\n",
      "2025: $4.28\n",
      "2026: $4.22\n",
      "2027: $4.13\n",
      "2028: $4.08\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for country in selected_countries:\n",
    "    if country in predictions_by_country:\n",
    "        plt.plot(range(2024, 2029), predictions_by_country[country], label=country)\n",
    "plt.title('Internet Predictions (2024-2028)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Internet')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "    \n",
    "    # Print predictions for selected countries\n",
    "print(\"\\nPredicted Internet (2024-2028):\")\n",
    "for country in selected_countries:\n",
    "    if country in predictions_by_country:\n",
    "        print(f\"\\n{country}:\")\n",
    "        for year, pred in zip(range(2024, 2029), predictions_by_country[country]):\n",
    "            print(f\"{year}: ${pred:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions exported to lstm_datasets/co2_prediction.csv\n"
     ]
    }
   ],
   "source": [
    "# Export predictions to CSV\n",
    "predictions_df = pd.DataFrame()\n",
    "predictions_df['Country'] = list(predictions_by_country.keys())\n",
    "\n",
    "for year in range(2024, 2029):\n",
    "    year_predictions = []\n",
    "    for country in predictions_df['Country']:\n",
    "        if country in predictions_by_country:\n",
    "            year_predictions.append(predictions_by_country[country][year-2024])\n",
    "        else:\n",
    "            year_predictions.append(None)\n",
    "    predictions_df[f'{year} CO2'] = year_predictions\n",
    "\n",
    "predictions_df.to_csv('../lstm_datasets/co2_prediction.csv', index=False)\n",
    "print(\"\\nPredictions exported to lstm_datasets/co2_prediction.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
