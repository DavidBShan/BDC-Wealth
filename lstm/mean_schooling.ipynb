{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from keras>=3.5.0->tensorflow) (13.7.0)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=32, num_layers=2):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_country_data(country_data, sequence_length=5):\n",
    "    # Scale the data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(country_data.reshape(-1, 1))\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y = [], []\n",
    "    for i in range(len(scaled_data) - sequence_length):\n",
    "        X.append(scaled_data[i:(i + sequence_length)])\n",
    "        y.append(scaled_data[i + sequence_length])\n",
    "    \n",
    "    return np.array(X), np.array(y), scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, epochs=200):\n",
    "    # Create dataset and dataloader\n",
    "    X_tensor = torch.FloatTensor(X)\n",
    "    y_tensor = torch.FloatTensor(y)\n",
    "    dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "    train_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = Predictor(input_size=1)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future(model, last_sequence, scaler, n_future=5):\n",
    "    model.eval()\n",
    "    current_sequence = last_sequence.copy()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_future):\n",
    "            sequence = torch.FloatTensor(current_sequence).unsqueeze(0)\n",
    "            pred = model(sequence)\n",
    "            predictions.append(pred.numpy())\n",
    "            current_sequence = np.vstack((current_sequence[1:], pred.numpy()))\n",
    "    \n",
    "    predictions = np.array(predictions).reshape(-1, 1)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    \n",
    "    return predictions.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Mean Years of Schooling (1990)</th>\n",
       "      <th>Mean Years of Schooling (1991)</th>\n",
       "      <th>Mean Years of Schooling (1992)</th>\n",
       "      <th>Mean Years of Schooling (1993)</th>\n",
       "      <th>Mean Years of Schooling (1994)</th>\n",
       "      <th>Mean Years of Schooling (1995)</th>\n",
       "      <th>Mean Years of Schooling (1996)</th>\n",
       "      <th>Mean Years of Schooling (1997)</th>\n",
       "      <th>Mean Years of Schooling (1998)</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean Years of Schooling (2012)</th>\n",
       "      <th>Mean Years of Schooling (2013)</th>\n",
       "      <th>Mean Years of Schooling (2014)</th>\n",
       "      <th>Mean Years of Schooling (2015)</th>\n",
       "      <th>Mean Years of Schooling (2016)</th>\n",
       "      <th>Mean Years of Schooling (2017)</th>\n",
       "      <th>Mean Years of Schooling (2018)</th>\n",
       "      <th>Mean Years of Schooling (2019)</th>\n",
       "      <th>Mean Years of Schooling (2020)</th>\n",
       "      <th>Mean Years of Schooling (2021)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0.971125</td>\n",
       "      <td>1.019356</td>\n",
       "      <td>1.067586</td>\n",
       "      <td>1.115817</td>\n",
       "      <td>1.164047</td>\n",
       "      <td>1.212277</td>\n",
       "      <td>1.251383</td>\n",
       "      <td>1.290489</td>\n",
       "      <td>1.329594</td>\n",
       "      <td>...</td>\n",
       "      <td>2.209473</td>\n",
       "      <td>2.261614</td>\n",
       "      <td>2.313755</td>\n",
       "      <td>2.365896</td>\n",
       "      <td>2.463660</td>\n",
       "      <td>2.561425</td>\n",
       "      <td>2.659189</td>\n",
       "      <td>2.756953</td>\n",
       "      <td>2.854718</td>\n",
       "      <td>2.985070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Angola</td>\n",
       "      <td>0.971125</td>\n",
       "      <td>1.019356</td>\n",
       "      <td>1.067586</td>\n",
       "      <td>1.115817</td>\n",
       "      <td>1.164047</td>\n",
       "      <td>1.212277</td>\n",
       "      <td>1.251383</td>\n",
       "      <td>1.290489</td>\n",
       "      <td>1.329594</td>\n",
       "      <td>...</td>\n",
       "      <td>3.909642</td>\n",
       "      <td>3.950166</td>\n",
       "      <td>3.990690</td>\n",
       "      <td>4.704040</td>\n",
       "      <td>5.417391</td>\n",
       "      <td>5.417391</td>\n",
       "      <td>5.417391</td>\n",
       "      <td>5.417391</td>\n",
       "      <td>5.417391</td>\n",
       "      <td>5.417391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>7.354632</td>\n",
       "      <td>7.352754</td>\n",
       "      <td>7.350875</td>\n",
       "      <td>7.348996</td>\n",
       "      <td>7.347118</td>\n",
       "      <td>7.345239</td>\n",
       "      <td>7.627026</td>\n",
       "      <td>7.908813</td>\n",
       "      <td>8.190599</td>\n",
       "      <td>...</td>\n",
       "      <td>10.025110</td>\n",
       "      <td>10.196281</td>\n",
       "      <td>10.370374</td>\n",
       "      <td>10.547439</td>\n",
       "      <td>10.727528</td>\n",
       "      <td>10.910692</td>\n",
       "      <td>11.096983</td>\n",
       "      <td>11.286455</td>\n",
       "      <td>11.286455</td>\n",
       "      <td>11.286455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>7.354632</td>\n",
       "      <td>7.352754</td>\n",
       "      <td>7.350875</td>\n",
       "      <td>7.348996</td>\n",
       "      <td>7.347118</td>\n",
       "      <td>7.345239</td>\n",
       "      <td>7.627026</td>\n",
       "      <td>7.908813</td>\n",
       "      <td>8.190599</td>\n",
       "      <td>...</td>\n",
       "      <td>10.587085</td>\n",
       "      <td>10.616062</td>\n",
       "      <td>10.645040</td>\n",
       "      <td>10.573280</td>\n",
       "      <td>10.556100</td>\n",
       "      <td>10.555773</td>\n",
       "      <td>10.555446</td>\n",
       "      <td>10.555120</td>\n",
       "      <td>10.555120</td>\n",
       "      <td>10.555120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>5.759906</td>\n",
       "      <td>6.058644</td>\n",
       "      <td>6.357381</td>\n",
       "      <td>6.656119</td>\n",
       "      <td>6.954857</td>\n",
       "      <td>7.253594</td>\n",
       "      <td>7.499132</td>\n",
       "      <td>7.744670</td>\n",
       "      <td>7.990207</td>\n",
       "      <td>...</td>\n",
       "      <td>10.169965</td>\n",
       "      <td>10.338129</td>\n",
       "      <td>10.506293</td>\n",
       "      <td>10.674456</td>\n",
       "      <td>10.842620</td>\n",
       "      <td>12.055400</td>\n",
       "      <td>12.484000</td>\n",
       "      <td>12.694030</td>\n",
       "      <td>12.694030</td>\n",
       "      <td>12.694030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Country  Mean Years of Schooling (1990)  \\\n",
       "0           Afghanistan                        0.971125   \n",
       "1                Angola                        0.971125   \n",
       "2               Albania                        7.354632   \n",
       "3               Andorra                        7.354632   \n",
       "4  United Arab Emirates                        5.759906   \n",
       "\n",
       "   Mean Years of Schooling (1991)  Mean Years of Schooling (1992)  \\\n",
       "0                        1.019356                        1.067586   \n",
       "1                        1.019356                        1.067586   \n",
       "2                        7.352754                        7.350875   \n",
       "3                        7.352754                        7.350875   \n",
       "4                        6.058644                        6.357381   \n",
       "\n",
       "   Mean Years of Schooling (1993)  Mean Years of Schooling (1994)  \\\n",
       "0                        1.115817                        1.164047   \n",
       "1                        1.115817                        1.164047   \n",
       "2                        7.348996                        7.347118   \n",
       "3                        7.348996                        7.347118   \n",
       "4                        6.656119                        6.954857   \n",
       "\n",
       "   Mean Years of Schooling (1995)  Mean Years of Schooling (1996)  \\\n",
       "0                        1.212277                        1.251383   \n",
       "1                        1.212277                        1.251383   \n",
       "2                        7.345239                        7.627026   \n",
       "3                        7.345239                        7.627026   \n",
       "4                        7.253594                        7.499132   \n",
       "\n",
       "   Mean Years of Schooling (1997)  Mean Years of Schooling (1998)  ...  \\\n",
       "0                        1.290489                        1.329594  ...   \n",
       "1                        1.290489                        1.329594  ...   \n",
       "2                        7.908813                        8.190599  ...   \n",
       "3                        7.908813                        8.190599  ...   \n",
       "4                        7.744670                        7.990207  ...   \n",
       "\n",
       "   Mean Years of Schooling (2012)  Mean Years of Schooling (2013)  \\\n",
       "0                        2.209473                        2.261614   \n",
       "1                        3.909642                        3.950166   \n",
       "2                       10.025110                       10.196281   \n",
       "3                       10.587085                       10.616062   \n",
       "4                       10.169965                       10.338129   \n",
       "\n",
       "   Mean Years of Schooling (2014)  Mean Years of Schooling (2015)  \\\n",
       "0                        2.313755                        2.365896   \n",
       "1                        3.990690                        4.704040   \n",
       "2                       10.370374                       10.547439   \n",
       "3                       10.645040                       10.573280   \n",
       "4                       10.506293                       10.674456   \n",
       "\n",
       "   Mean Years of Schooling (2016)  Mean Years of Schooling (2017)  \\\n",
       "0                        2.463660                        2.561425   \n",
       "1                        5.417391                        5.417391   \n",
       "2                       10.727528                       10.910692   \n",
       "3                       10.556100                       10.555773   \n",
       "4                       10.842620                       12.055400   \n",
       "\n",
       "   Mean Years of Schooling (2018)  Mean Years of Schooling (2019)  \\\n",
       "0                        2.659189                        2.756953   \n",
       "1                        5.417391                        5.417391   \n",
       "2                       11.096983                       11.286455   \n",
       "3                       10.555446                       10.555120   \n",
       "4                       12.484000                       12.694030   \n",
       "\n",
       "   Mean Years of Schooling (2020)  Mean Years of Schooling (2021)  \n",
       "0                        2.854718                        2.985070  \n",
       "1                        5.417391                        5.417391  \n",
       "2                       11.286455                       11.286455  \n",
       "3                       10.555120                       10.555120  \n",
       "4                       12.694030                       12.694030  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/mean_schooling.csv')\n",
    "df.head()\n",
    "df.replace(\"..\", pd.NA, inplace=True)\n",
    "# Forward fill first, then backward fill to handle any remaining NAs at the start\n",
    "df.rename(columns={'entity': 'Country'}, inplace=True)\n",
    "df = df.ffill().bfill()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df.columns if 'Mean' in col]\n",
    "    \n",
    "sequence_length = 5\n",
    "predictions_by_country = {}\n",
    "selected_countries = ['United States', 'China', 'Japan', 'Germany', 'United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for Afghanistan\n",
      "Epoch [50/200], Loss: 0.0013\n",
      "Epoch [100/200], Loss: 0.0005\n",
      "Epoch [150/200], Loss: 0.0005\n",
      "Epoch [200/200], Loss: 0.0006\n",
      "\n",
      "Training model for Angola\n",
      "Epoch [50/200], Loss: 0.0179\n",
      "Epoch [100/200], Loss: 0.0166\n",
      "Epoch [150/200], Loss: 0.0139\n",
      "Epoch [200/200], Loss: 0.0110\n",
      "\n",
      "Training model for Albania\n",
      "Epoch [50/200], Loss: 0.0047\n",
      "Epoch [100/200], Loss: 0.0029\n",
      "Epoch [150/200], Loss: 0.0027\n",
      "Epoch [200/200], Loss: 0.0025\n",
      "\n",
      "Training model for Andorra\n",
      "Epoch [50/200], Loss: 0.0203\n",
      "Epoch [100/200], Loss: 0.0099\n",
      "Epoch [150/200], Loss: 0.0035\n",
      "Epoch [200/200], Loss: 0.0032\n",
      "\n",
      "Training model for United Arab Emirates\n",
      "Epoch [50/200], Loss: 0.0022\n",
      "Epoch [100/200], Loss: 0.0022\n",
      "Epoch [150/200], Loss: 0.0016\n",
      "Epoch [200/200], Loss: 0.0016\n",
      "\n",
      "Training model for Argentina\n",
      "Epoch [50/200], Loss: 0.0078\n",
      "Epoch [100/200], Loss: 0.0050\n",
      "Epoch [150/200], Loss: 0.0030\n",
      "Epoch [200/200], Loss: 0.0037\n",
      "\n",
      "Training model for Armenia\n",
      "Epoch [50/200], Loss: 0.0047\n",
      "Epoch [100/200], Loss: 0.0029\n",
      "Epoch [150/200], Loss: 0.0026\n",
      "Epoch [200/200], Loss: 0.0024\n",
      "\n",
      "Training model for Antigua and Barbuda\n",
      "Epoch [50/200], Loss: 0.0283\n",
      "Epoch [100/200], Loss: 0.0305\n",
      "Epoch [150/200], Loss: 0.0298\n",
      "Epoch [200/200], Loss: 0.0302\n",
      "\n",
      "Training model for Australia\n",
      "Epoch [50/200], Loss: 0.0080\n",
      "Epoch [100/200], Loss: 0.0071\n",
      "Epoch [150/200], Loss: 0.0043\n",
      "Epoch [200/200], Loss: 0.0044\n",
      "\n",
      "Training model for Austria\n",
      "Epoch [50/200], Loss: 0.0020\n",
      "Epoch [100/200], Loss: 0.0015\n",
      "Epoch [150/200], Loss: 0.0017\n",
      "Epoch [200/200], Loss: 0.0013\n",
      "\n",
      "Training model for Azerbaijan\n",
      "Epoch [50/200], Loss: 0.0434\n",
      "Epoch [100/200], Loss: 0.0345\n",
      "Epoch [150/200], Loss: 0.0280\n",
      "Epoch [200/200], Loss: 0.0263\n",
      "\n",
      "Training model for Burundi\n",
      "Epoch [50/200], Loss: 0.0190\n",
      "Epoch [100/200], Loss: 0.0118\n",
      "Epoch [150/200], Loss: 0.0066\n",
      "Epoch [200/200], Loss: 0.0046\n",
      "\n",
      "Training model for Belgium\n",
      "Epoch [50/200], Loss: 0.0009\n",
      "Epoch [100/200], Loss: 0.0015\n",
      "Epoch [150/200], Loss: 0.0013\n",
      "Epoch [200/200], Loss: 0.0008\n",
      "\n",
      "Training model for Benin\n",
      "Epoch [50/200], Loss: 0.0007\n",
      "Epoch [100/200], Loss: 0.0006\n",
      "Epoch [150/200], Loss: 0.0006\n",
      "Epoch [200/200], Loss: 0.0005\n",
      "\n",
      "Training model for Burkina Faso\n",
      "Epoch [50/200], Loss: 0.0494\n",
      "Epoch [100/200], Loss: 0.0332\n",
      "Epoch [150/200], Loss: 0.0317\n",
      "Epoch [200/200], Loss: 0.0177\n",
      "\n",
      "Training model for Bangladesh\n",
      "Epoch [50/200], Loss: 0.0021\n",
      "Epoch [100/200], Loss: 0.0021\n",
      "Epoch [150/200], Loss: 0.0016\n",
      "Epoch [200/200], Loss: 0.0023\n",
      "\n",
      "Training model for Bulgaria\n",
      "Epoch [50/200], Loss: 0.0013\n",
      "Epoch [100/200], Loss: 0.0009\n",
      "Epoch [150/200], Loss: 0.0012\n",
      "Epoch [200/200], Loss: 0.0008\n",
      "\n",
      "Training model for Bahrain\n",
      "Epoch [50/200], Loss: 0.0055\n",
      "Epoch [100/200], Loss: 0.0042\n",
      "Epoch [150/200], Loss: 0.0039\n",
      "Epoch [200/200], Loss: 0.0049\n",
      "\n",
      "Training model for Bahamas\n",
      "Epoch [50/200], Loss: 0.0009\n",
      "Epoch [100/200], Loss: 0.0001\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0002\n",
      "\n",
      "Training model for Bosnia and Herzegovina\n",
      "Epoch [50/200], Loss: 0.0774\n",
      "Epoch [100/200], Loss: 0.0361\n",
      "Epoch [150/200], Loss: 0.0310\n",
      "Epoch [200/200], Loss: 0.0285\n",
      "\n",
      "Training model for Belarus\n",
      "Epoch [50/200], Loss: 0.0049\n",
      "Epoch [100/200], Loss: 0.0031\n",
      "Epoch [150/200], Loss: 0.0037\n",
      "Epoch [200/200], Loss: 0.0035\n",
      "\n",
      "Training model for Belize\n",
      "Epoch [50/200], Loss: 0.0129\n",
      "Epoch [100/200], Loss: 0.0084\n",
      "Epoch [150/200], Loss: 0.0033\n",
      "Epoch [200/200], Loss: 0.0008\n",
      "\n",
      "Training model for Bolivia\n",
      "Epoch [50/200], Loss: 0.0057\n",
      "Epoch [100/200], Loss: 0.0046\n",
      "Epoch [150/200], Loss: 0.0043\n",
      "Epoch [200/200], Loss: 0.0045\n",
      "\n",
      "Training model for Brazil\n",
      "Epoch [50/200], Loss: 0.0007\n",
      "Epoch [100/200], Loss: 0.0003\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0003\n",
      "\n",
      "Training model for Barbados\n",
      "Epoch [50/200], Loss: 0.0048\n",
      "Epoch [100/200], Loss: 0.0040\n",
      "Epoch [150/200], Loss: 0.0034\n",
      "Epoch [200/200], Loss: 0.0033\n",
      "\n",
      "Training model for Brunei\n",
      "Epoch [50/200], Loss: 0.0006\n",
      "Epoch [100/200], Loss: 0.0004\n",
      "Epoch [150/200], Loss: 0.0004\n",
      "Epoch [200/200], Loss: 0.0005\n",
      "\n",
      "Training model for Bhutan\n",
      "Epoch [50/200], Loss: 0.0673\n",
      "Epoch [100/200], Loss: 0.0393\n",
      "Epoch [150/200], Loss: 0.0321\n",
      "Epoch [200/200], Loss: 0.0298\n",
      "\n",
      "Training model for Botswana\n",
      "Epoch [50/200], Loss: 0.0010\n",
      "Epoch [100/200], Loss: 0.0006\n",
      "Epoch [150/200], Loss: 0.0006\n",
      "Epoch [200/200], Loss: 0.0008\n",
      "\n",
      "Training model for Central African Republic\n",
      "Epoch [50/200], Loss: 0.0025\n",
      "Epoch [100/200], Loss: 0.0009\n",
      "Epoch [150/200], Loss: 0.0009\n",
      "Epoch [200/200], Loss: 0.0009\n",
      "\n",
      "Training model for Canada\n",
      "Epoch [50/200], Loss: 0.0012\n",
      "Epoch [100/200], Loss: 0.0003\n",
      "Epoch [150/200], Loss: 0.0001\n",
      "Epoch [200/200], Loss: 0.0001\n",
      "\n",
      "Training model for Switzerland\n",
      "Epoch [50/200], Loss: 0.0185\n",
      "Epoch [100/200], Loss: 0.0022\n",
      "Epoch [150/200], Loss: 0.0016\n",
      "Epoch [200/200], Loss: 0.0014\n",
      "\n",
      "Training model for Chile\n",
      "Epoch [50/200], Loss: 0.0076\n",
      "Epoch [100/200], Loss: 0.0062\n",
      "Epoch [150/200], Loss: 0.0056\n",
      "Epoch [200/200], Loss: 0.0066\n",
      "\n",
      "Training model for China\n",
      "Epoch [50/200], Loss: 0.0004\n",
      "Epoch [100/200], Loss: 0.0005\n",
      "Epoch [150/200], Loss: 0.0004\n",
      "Epoch [200/200], Loss: 0.0004\n",
      "\n",
      "Training model for Ivory Coast\n",
      "Epoch [50/200], Loss: 0.0363\n",
      "Epoch [100/200], Loss: 0.0027\n",
      "Epoch [150/200], Loss: 0.0012\n",
      "Epoch [200/200], Loss: 0.0008\n",
      "\n",
      "Training model for Cameroon\n",
      "Epoch [50/200], Loss: 0.0017\n",
      "Epoch [100/200], Loss: 0.0006\n",
      "Epoch [150/200], Loss: 0.0006\n",
      "Epoch [200/200], Loss: 0.0004\n",
      "\n",
      "Training model for The Democratic Republic of the Congo\n",
      "Epoch [50/200], Loss: 0.0035\n",
      "Epoch [100/200], Loss: 0.0016\n",
      "Epoch [150/200], Loss: 0.0014\n",
      "Epoch [200/200], Loss: 0.0012\n",
      "\n",
      "Training model for Congo\n",
      "Epoch [50/200], Loss: 0.0017\n",
      "Epoch [100/200], Loss: 0.0022\n",
      "Epoch [150/200], Loss: 0.0017\n",
      "Epoch [200/200], Loss: 0.0022\n",
      "\n",
      "Training model for Colombia\n",
      "Epoch [50/200], Loss: 0.0024\n",
      "Epoch [100/200], Loss: 0.0017\n",
      "Epoch [150/200], Loss: 0.0019\n",
      "Epoch [200/200], Loss: 0.0033\n",
      "\n",
      "Training model for Comoros\n",
      "Epoch [50/200], Loss: 0.0692\n",
      "Epoch [100/200], Loss: 0.0428\n",
      "Epoch [150/200], Loss: 0.0293\n",
      "Epoch [200/200], Loss: 0.0634\n",
      "\n",
      "Training model for Cabo Verde\n",
      "Epoch [50/200], Loss: 0.0679\n",
      "Epoch [100/200], Loss: 0.0752\n",
      "Epoch [150/200], Loss: 0.0286\n",
      "Epoch [200/200], Loss: 0.0308\n",
      "\n",
      "Training model for Costa Rica\n",
      "Epoch [50/200], Loss: 0.0025\n",
      "Epoch [100/200], Loss: 0.0024\n",
      "Epoch [150/200], Loss: 0.0019\n",
      "Epoch [200/200], Loss: 0.0018\n",
      "\n",
      "Training model for Cuba\n",
      "Epoch [50/200], Loss: 0.0007\n",
      "Epoch [100/200], Loss: 0.0002\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0002\n",
      "\n",
      "Training model for Cyprus\n",
      "Epoch [50/200], Loss: 0.0015\n",
      "Epoch [100/200], Loss: 0.0005\n",
      "Epoch [150/200], Loss: 0.0003\n",
      "Epoch [200/200], Loss: 0.0002\n",
      "\n",
      "Training model for Czechia\n",
      "Epoch [50/200], Loss: 0.0013\n",
      "Epoch [100/200], Loss: 0.0003\n",
      "Epoch [150/200], Loss: 0.0001\n",
      "Epoch [200/200], Loss: 0.0001\n",
      "\n",
      "Training model for Germany\n",
      "Epoch [50/200], Loss: 0.0038\n",
      "Epoch [100/200], Loss: 0.0017\n",
      "Epoch [150/200], Loss: 0.0012\n",
      "Epoch [200/200], Loss: 0.0012\n",
      "\n",
      "Training model for Djibouti\n",
      "Epoch [50/200], Loss: 0.0012\n",
      "Epoch [100/200], Loss: 0.0006\n",
      "Epoch [150/200], Loss: 0.0001\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Dominica\n",
      "Epoch [50/200], Loss: 0.0507\n",
      "Epoch [100/200], Loss: 0.0073\n",
      "Epoch [150/200], Loss: 0.0035\n",
      "Epoch [200/200], Loss: 0.0012\n",
      "\n",
      "Training model for Denmark\n",
      "Epoch [50/200], Loss: 0.0196\n",
      "Epoch [100/200], Loss: 0.0139\n",
      "Epoch [150/200], Loss: 0.0105\n",
      "Epoch [200/200], Loss: 0.0107\n",
      "\n",
      "Training model for Dominican Republic\n",
      "Epoch [50/200], Loss: 0.0068\n",
      "Epoch [100/200], Loss: 0.0062\n",
      "Epoch [150/200], Loss: 0.0104\n",
      "Epoch [200/200], Loss: 0.0049\n",
      "\n",
      "Training model for Algeria\n",
      "Epoch [50/200], Loss: 0.0003\n",
      "Epoch [100/200], Loss: 0.0002\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0002\n",
      "\n",
      "Training model for Ecuador\n",
      "Epoch [50/200], Loss: 0.0032\n",
      "Epoch [100/200], Loss: 0.0028\n",
      "Epoch [150/200], Loss: 0.0025\n",
      "Epoch [200/200], Loss: 0.0026\n",
      "\n",
      "Training model for Egypt\n",
      "Epoch [50/200], Loss: 0.0041\n",
      "Epoch [100/200], Loss: 0.0038\n",
      "Epoch [150/200], Loss: 0.0031\n",
      "Epoch [200/200], Loss: 0.0032\n",
      "\n",
      "Training model for Eritrea\n",
      "Epoch [50/200], Loss: 0.0645\n",
      "Epoch [100/200], Loss: 0.0416\n",
      "Epoch [150/200], Loss: 0.0339\n",
      "Epoch [200/200], Loss: 0.0235\n",
      "\n",
      "Training model for Spain\n",
      "Epoch [50/200], Loss: 0.0009\n",
      "Epoch [100/200], Loss: 0.0008\n",
      "Epoch [150/200], Loss: 0.0005\n",
      "Epoch [200/200], Loss: 0.0006\n",
      "\n",
      "Training model for Estonia\n",
      "Epoch [50/200], Loss: 0.0022\n",
      "Epoch [100/200], Loss: 0.0011\n",
      "Epoch [150/200], Loss: 0.0005\n",
      "Epoch [200/200], Loss: 0.0002\n",
      "\n",
      "Training model for Ethiopia\n",
      "Epoch [50/200], Loss: 0.0638\n",
      "Epoch [100/200], Loss: 0.0638\n",
      "Epoch [150/200], Loss: 0.0290\n",
      "Epoch [200/200], Loss: 0.0294\n",
      "\n",
      "Training model for Finland\n",
      "Epoch [50/200], Loss: 0.0011\n",
      "Epoch [100/200], Loss: 0.0008\n",
      "Epoch [150/200], Loss: 0.0008\n",
      "Epoch [200/200], Loss: 0.0006\n",
      "\n",
      "Training model for Fiji\n",
      "Epoch [50/200], Loss: 0.0005\n",
      "Epoch [100/200], Loss: 0.0002\n",
      "Epoch [150/200], Loss: 0.0001\n",
      "Epoch [200/200], Loss: 0.0002\n",
      "\n",
      "Training model for France\n",
      "Epoch [50/200], Loss: 0.0009\n",
      "Epoch [100/200], Loss: 0.0006\n",
      "Epoch [150/200], Loss: 0.0004\n",
      "Epoch [200/200], Loss: 0.0004\n",
      "\n",
      "Training model for Micronesia\n",
      "Epoch [50/200], Loss: 0.0506\n",
      "Epoch [100/200], Loss: 0.0300\n",
      "Epoch [150/200], Loss: 0.0254\n",
      "Epoch [200/200], Loss: 0.0204\n",
      "\n",
      "Training model for Gabon\n",
      "Epoch [50/200], Loss: 0.0017\n",
      "Epoch [100/200], Loss: 0.0008\n",
      "Epoch [150/200], Loss: 0.0007\n",
      "Epoch [200/200], Loss: 0.0008\n",
      "\n",
      "Training model for United Kingdom\n",
      "Epoch [50/200], Loss: 0.0085\n",
      "Epoch [100/200], Loss: 0.0036\n",
      "Epoch [150/200], Loss: 0.0017\n",
      "Epoch [200/200], Loss: 0.0017\n",
      "\n",
      "Training model for Georgia\n",
      "Epoch [50/200], Loss: 0.0091\n",
      "Epoch [100/200], Loss: 0.0081\n",
      "Epoch [150/200], Loss: 0.0068\n",
      "Epoch [200/200], Loss: 0.0049\n",
      "\n",
      "Training model for Ghana\n",
      "Epoch [50/200], Loss: 0.0009\n",
      "Epoch [100/200], Loss: 0.0005\n",
      "Epoch [150/200], Loss: 0.0006\n",
      "Epoch [200/200], Loss: 0.0005\n",
      "\n",
      "Training model for Guinea\n",
      "Epoch [50/200], Loss: 0.0025\n",
      "Epoch [100/200], Loss: 0.0020\n",
      "Epoch [150/200], Loss: 0.0016\n",
      "Epoch [200/200], Loss: 0.0015\n",
      "\n",
      "Training model for Gambia\n",
      "Epoch [50/200], Loss: 0.0007\n",
      "Epoch [100/200], Loss: 0.0001\n",
      "Epoch [150/200], Loss: 0.0001\n",
      "Epoch [200/200], Loss: 0.0001\n",
      "\n",
      "Training model for Guinea-Bissau\n",
      "Epoch [50/200], Loss: 0.0047\n",
      "Epoch [100/200], Loss: 0.0039\n",
      "Epoch [150/200], Loss: 0.0028\n",
      "Epoch [200/200], Loss: 0.0028\n",
      "\n",
      "Training model for Equatorial Guinea\n",
      "Epoch [50/200], Loss: 0.0337\n",
      "Epoch [100/200], Loss: 0.0399\n",
      "Epoch [150/200], Loss: 0.0197\n",
      "Epoch [200/200], Loss: 0.0209\n",
      "\n",
      "Training model for Greece\n",
      "Epoch [50/200], Loss: 0.0027\n",
      "Epoch [100/200], Loss: 0.0028\n",
      "Epoch [150/200], Loss: 0.0034\n",
      "Epoch [200/200], Loss: 0.0027\n",
      "\n",
      "Training model for Grenada\n",
      "Epoch [50/200], Loss: 0.0632\n",
      "Epoch [100/200], Loss: 0.0411\n",
      "Epoch [150/200], Loss: 0.0328\n",
      "Epoch [200/200], Loss: 0.0305\n",
      "\n",
      "Training model for Guatemala\n",
      "Epoch [50/200], Loss: 0.0283\n",
      "Epoch [100/200], Loss: 0.0122\n",
      "Epoch [150/200], Loss: 0.0100\n",
      "Epoch [200/200], Loss: 0.0057\n",
      "\n",
      "Training model for Guyana\n",
      "Epoch [50/200], Loss: 0.0054\n",
      "Epoch [100/200], Loss: 0.0013\n",
      "Epoch [150/200], Loss: 0.0012\n",
      "Epoch [200/200], Loss: 0.0012\n",
      "\n",
      "Training model for Hong Kong\n",
      "Epoch [50/200], Loss: 0.0008\n",
      "Epoch [100/200], Loss: 0.0004\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0002\n",
      "\n",
      "Training model for Honduras\n",
      "Epoch [50/200], Loss: 0.0022\n",
      "Epoch [100/200], Loss: 0.0037\n",
      "Epoch [150/200], Loss: 0.0020\n",
      "Epoch [200/200], Loss: 0.0018\n",
      "\n",
      "Training model for Croatia\n",
      "Epoch [50/200], Loss: 0.0007\n",
      "Epoch [100/200], Loss: 0.0005\n",
      "Epoch [150/200], Loss: 0.0007\n",
      "Epoch [200/200], Loss: 0.0004\n",
      "\n",
      "Training model for Haiti\n",
      "Epoch [50/200], Loss: 0.0011\n",
      "Epoch [100/200], Loss: 0.0002\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0003\n",
      "\n",
      "Training model for Hungary\n",
      "Epoch [50/200], Loss: 0.0067\n",
      "Epoch [100/200], Loss: 0.0024\n",
      "Epoch [150/200], Loss: 0.0021\n",
      "Epoch [200/200], Loss: 0.0017\n",
      "\n",
      "Training model for Indonesia\n",
      "Epoch [50/200], Loss: 0.0025\n",
      "Epoch [100/200], Loss: 0.0022\n",
      "Epoch [150/200], Loss: 0.0020\n",
      "Epoch [200/200], Loss: 0.0022\n",
      "\n",
      "Training model for India\n",
      "Epoch [50/200], Loss: 0.0023\n",
      "Epoch [100/200], Loss: 0.0015\n",
      "Epoch [150/200], Loss: 0.0017\n",
      "Epoch [200/200], Loss: 0.0011\n",
      "\n",
      "Training model for Ireland\n",
      "Epoch [50/200], Loss: 0.0047\n",
      "Epoch [100/200], Loss: 0.0027\n",
      "Epoch [150/200], Loss: 0.0013\n",
      "Epoch [200/200], Loss: 0.0011\n",
      "\n",
      "Training model for Iran\n",
      "Epoch [50/200], Loss: 0.0018\n",
      "Epoch [100/200], Loss: 0.0013\n",
      "Epoch [150/200], Loss: 0.0017\n",
      "Epoch [200/200], Loss: 0.0011\n",
      "\n",
      "Training model for Iraq\n",
      "Epoch [50/200], Loss: 0.0018\n",
      "Epoch [100/200], Loss: 0.0007\n",
      "Epoch [150/200], Loss: 0.0008\n",
      "Epoch [200/200], Loss: 0.0008\n",
      "\n",
      "Training model for Iceland\n",
      "Epoch [50/200], Loss: 0.0053\n",
      "Epoch [100/200], Loss: 0.0023\n",
      "Epoch [150/200], Loss: 0.0017\n",
      "Epoch [200/200], Loss: 0.0010\n",
      "\n",
      "Training model for Israel\n",
      "Epoch [50/200], Loss: 0.0112\n",
      "Epoch [100/200], Loss: 0.0095\n",
      "Epoch [150/200], Loss: 0.0053\n",
      "Epoch [200/200], Loss: 0.0061\n",
      "\n",
      "Training model for Italy\n",
      "Epoch [50/200], Loss: 0.0004\n",
      "Epoch [100/200], Loss: 0.0001\n",
      "Epoch [150/200], Loss: 0.0001\n",
      "Epoch [200/200], Loss: 0.0001\n",
      "\n",
      "Training model for Jamaica\n",
      "Epoch [50/200], Loss: 0.0005\n",
      "Epoch [100/200], Loss: 0.0001\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0001\n",
      "\n",
      "Training model for Jordan\n",
      "Epoch [50/200], Loss: 0.0020\n",
      "Epoch [100/200], Loss: 0.0013\n",
      "Epoch [150/200], Loss: 0.0009\n",
      "Epoch [200/200], Loss: 0.0011\n",
      "\n",
      "Training model for Japan\n",
      "Epoch [50/200], Loss: 0.0059\n",
      "Epoch [100/200], Loss: 0.0034\n",
      "Epoch [150/200], Loss: 0.0037\n",
      "Epoch [200/200], Loss: 0.0032\n",
      "\n",
      "Training model for Kazakhstan\n",
      "Epoch [50/200], Loss: 0.0032\n",
      "Epoch [100/200], Loss: 0.0021\n",
      "Epoch [150/200], Loss: 0.0025\n",
      "Epoch [200/200], Loss: 0.0022\n",
      "\n",
      "Training model for Kenya\n",
      "Epoch [50/200], Loss: 0.0009\n",
      "Epoch [100/200], Loss: 0.0006\n",
      "Epoch [150/200], Loss: 0.0005\n",
      "Epoch [200/200], Loss: 0.0005\n",
      "\n",
      "Training model for Kyrgyzstan\n",
      "Epoch [50/200], Loss: 0.0012\n",
      "Epoch [100/200], Loss: 0.0009\n",
      "Epoch [150/200], Loss: 0.0009\n",
      "Epoch [200/200], Loss: 0.0010\n",
      "\n",
      "Training model for Cambodia\n",
      "Epoch [50/200], Loss: 0.0019\n",
      "Epoch [100/200], Loss: 0.0006\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0003\n",
      "\n",
      "Training model for Kiribati\n",
      "Epoch [50/200], Loss: 0.0287\n",
      "Epoch [100/200], Loss: 0.0214\n",
      "Epoch [150/200], Loss: 0.0146\n",
      "Epoch [200/200], Loss: 0.0127\n",
      "\n",
      "Training model for Saint Kitts and Nevis\n",
      "Epoch [50/200], Loss: 0.0247\n",
      "Epoch [100/200], Loss: 0.0245\n",
      "Epoch [150/200], Loss: 0.0134\n",
      "Epoch [200/200], Loss: 0.0128\n",
      "\n",
      "Training model for South Korea\n",
      "Epoch [50/200], Loss: 0.0040\n",
      "Epoch [100/200], Loss: 0.0038\n",
      "Epoch [150/200], Loss: 0.0038\n",
      "Epoch [200/200], Loss: 0.0058\n",
      "\n",
      "Training model for Kuwait\n",
      "Epoch [50/200], Loss: 0.0265\n",
      "Epoch [100/200], Loss: 0.0120\n",
      "Epoch [150/200], Loss: 0.0150\n",
      "Epoch [200/200], Loss: 0.0099\n",
      "\n",
      "Training model for Lao\n",
      "Epoch [50/200], Loss: 0.0006\n",
      "Epoch [100/200], Loss: 0.0002\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0002\n",
      "\n",
      "Training model for Lebanon\n",
      "Epoch [50/200], Loss: 0.0324\n",
      "Epoch [100/200], Loss: 0.0195\n",
      "Epoch [150/200], Loss: 0.0098\n",
      "Epoch [200/200], Loss: 0.0082\n",
      "\n",
      "Training model for Liberia\n",
      "Epoch [50/200], Loss: 0.0007\n",
      "Epoch [100/200], Loss: 0.0003\n",
      "Epoch [150/200], Loss: 0.0005\n",
      "Epoch [200/200], Loss: 0.0003\n",
      "\n",
      "Training model for Libya\n",
      "Epoch [50/200], Loss: 0.0025\n",
      "Epoch [100/200], Loss: 0.0012\n",
      "Epoch [150/200], Loss: 0.0005\n",
      "Epoch [200/200], Loss: 0.0004\n",
      "\n",
      "Training model for Saint Lucia\n",
      "Epoch [50/200], Loss: 0.0017\n",
      "Epoch [100/200], Loss: 0.0010\n",
      "Epoch [150/200], Loss: 0.0006\n",
      "Epoch [200/200], Loss: 0.0003\n",
      "\n",
      "Training model for Liechtenstein\n",
      "Epoch [50/200], Loss: 0.0009\n",
      "Epoch [100/200], Loss: 0.0001\n",
      "Epoch [150/200], Loss: 0.0001\n",
      "Epoch [200/200], Loss: 0.0001\n",
      "\n",
      "Training model for Sri Lanka\n",
      "Epoch [50/200], Loss: 0.0037\n",
      "Epoch [100/200], Loss: 0.0029\n",
      "Epoch [150/200], Loss: 0.0029\n",
      "Epoch [200/200], Loss: 0.0028\n",
      "\n",
      "Training model for Lesotho\n",
      "Epoch [50/200], Loss: 0.0250\n",
      "Epoch [100/200], Loss: 0.0127\n",
      "Epoch [150/200], Loss: 0.0030\n",
      "Epoch [200/200], Loss: 0.0025\n",
      "\n",
      "Training model for Lithuania\n",
      "Epoch [50/200], Loss: 0.0010\n",
      "Epoch [100/200], Loss: 0.0007\n",
      "Epoch [150/200], Loss: 0.0005\n",
      "Epoch [200/200], Loss: 0.0004\n",
      "\n",
      "Training model for Luxembourg\n",
      "Epoch [50/200], Loss: 0.0090\n",
      "Epoch [100/200], Loss: 0.0036\n",
      "Epoch [150/200], Loss: 0.0033\n",
      "Epoch [200/200], Loss: 0.0042\n",
      "\n",
      "Training model for Latvia\n",
      "Epoch [50/200], Loss: 0.0004\n",
      "Epoch [100/200], Loss: 0.0003\n",
      "Epoch [150/200], Loss: 0.0004\n",
      "Epoch [200/200], Loss: 0.0005\n",
      "\n",
      "Training model for Morocco\n",
      "Epoch [50/200], Loss: 0.0017\n",
      "Epoch [100/200], Loss: 0.0011\n",
      "Epoch [150/200], Loss: 0.0007\n",
      "Epoch [200/200], Loss: 0.0009\n",
      "\n",
      "Training model for Monaco\n",
      "Epoch [50/200], Loss: 0.0014\n",
      "Epoch [100/200], Loss: 0.0009\n",
      "Epoch [150/200], Loss: 0.0009\n",
      "Epoch [200/200], Loss: 0.0013\n",
      "\n",
      "Training model for Moldova\n",
      "Epoch [50/200], Loss: 0.0024\n",
      "Epoch [100/200], Loss: 0.0010\n",
      "Epoch [150/200], Loss: 0.0008\n",
      "Epoch [200/200], Loss: 0.0007\n",
      "\n",
      "Training model for Madagascar\n",
      "Epoch [50/200], Loss: 0.0456\n",
      "Epoch [100/200], Loss: 0.0400\n",
      "Epoch [150/200], Loss: 0.0291\n",
      "Epoch [200/200], Loss: 0.0254\n",
      "\n",
      "Training model for Maldives\n",
      "Epoch [50/200], Loss: 0.0140\n",
      "Epoch [100/200], Loss: 0.0113\n",
      "Epoch [150/200], Loss: 0.0049\n",
      "Epoch [200/200], Loss: 0.0008\n",
      "\n",
      "Training model for Mexico\n",
      "Epoch [50/200], Loss: 0.0039\n",
      "Epoch [100/200], Loss: 0.0022\n",
      "Epoch [150/200], Loss: 0.0018\n",
      "Epoch [200/200], Loss: 0.0016\n",
      "\n",
      "Training model for Marshall Islands\n",
      "Epoch [50/200], Loss: 0.0243\n",
      "Epoch [100/200], Loss: 0.0130\n",
      "Epoch [150/200], Loss: 0.0120\n",
      "Epoch [200/200], Loss: 0.0082\n",
      "\n",
      "Training model for North Macedonia\n",
      "Epoch [50/200], Loss: 0.0007\n",
      "Epoch [100/200], Loss: 0.0004\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0001\n",
      "\n",
      "Training model for Mali\n",
      "Epoch [50/200], Loss: 0.0015\n",
      "Epoch [100/200], Loss: 0.0004\n",
      "Epoch [150/200], Loss: 0.0004\n",
      "Epoch [200/200], Loss: 0.0004\n",
      "\n",
      "Training model for Malta\n",
      "Epoch [50/200], Loss: 0.0052\n",
      "Epoch [100/200], Loss: 0.0035\n",
      "Epoch [150/200], Loss: 0.0033\n",
      "Epoch [200/200], Loss: 0.0021\n",
      "\n",
      "Training model for Myanmar\n",
      "Epoch [50/200], Loss: 0.0024\n",
      "Epoch [100/200], Loss: 0.0005\n",
      "Epoch [150/200], Loss: 0.0006\n",
      "Epoch [200/200], Loss: 0.0004\n",
      "\n",
      "Training model for Montenegro\n",
      "Epoch [50/200], Loss: 0.0326\n",
      "Epoch [100/200], Loss: 0.0247\n",
      "Epoch [150/200], Loss: 0.0167\n",
      "Epoch [200/200], Loss: 0.0128\n",
      "\n",
      "Training model for Mongolia\n",
      "Epoch [50/200], Loss: 0.0157\n",
      "Epoch [100/200], Loss: 0.0126\n",
      "Epoch [150/200], Loss: 0.0098\n",
      "Epoch [200/200], Loss: 0.0052\n",
      "\n",
      "Training model for Mozambique\n",
      "Epoch [50/200], Loss: 0.0045\n",
      "Epoch [100/200], Loss: 0.0033\n",
      "Epoch [150/200], Loss: 0.0023\n",
      "Epoch [200/200], Loss: 0.0024\n",
      "\n",
      "Training model for Mauritania\n",
      "Epoch [50/200], Loss: 0.0007\n",
      "Epoch [100/200], Loss: 0.0002\n",
      "Epoch [150/200], Loss: 0.0001\n",
      "Epoch [200/200], Loss: 0.0001\n",
      "\n",
      "Training model for Mauritius\n",
      "Epoch [50/200], Loss: 0.0028\n",
      "Epoch [100/200], Loss: 0.0009\n",
      "Epoch [150/200], Loss: 0.0010\n",
      "Epoch [200/200], Loss: 0.0007\n",
      "\n",
      "Training model for Malawi\n",
      "Epoch [50/200], Loss: 0.0036\n",
      "Epoch [100/200], Loss: 0.0025\n",
      "Epoch [150/200], Loss: 0.0016\n",
      "Epoch [200/200], Loss: 0.0019\n",
      "\n",
      "Training model for Malaysia\n",
      "Epoch [50/200], Loss: 0.0120\n",
      "Epoch [100/200], Loss: 0.0106\n",
      "Epoch [150/200], Loss: 0.0093\n",
      "Epoch [200/200], Loss: 0.0068\n",
      "\n",
      "Training model for Namibia\n",
      "Epoch [50/200], Loss: 0.0015\n",
      "Epoch [100/200], Loss: 0.0015\n",
      "Epoch [150/200], Loss: 0.0016\n",
      "Epoch [200/200], Loss: 0.0020\n",
      "\n",
      "Training model for Niger\n",
      "Epoch [50/200], Loss: 0.0007\n",
      "Epoch [100/200], Loss: 0.0006\n",
      "Epoch [150/200], Loss: 0.0006\n",
      "Epoch [200/200], Loss: 0.0005\n",
      "\n",
      "Training model for Nigeria\n",
      "Epoch [50/200], Loss: 0.0235\n",
      "Epoch [100/200], Loss: 0.0230\n",
      "Epoch [150/200], Loss: 0.0145\n",
      "Epoch [200/200], Loss: 0.0103\n",
      "\n",
      "Training model for Nicaragua\n",
      "Epoch [50/200], Loss: 0.0013\n",
      "Epoch [100/200], Loss: 0.0004\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0002\n",
      "\n",
      "Training model for Netherlands\n",
      "Epoch [50/200], Loss: 0.0021\n",
      "Epoch [100/200], Loss: 0.0024\n",
      "Epoch [150/200], Loss: 0.0016\n",
      "Epoch [200/200], Loss: 0.0013\n",
      "\n",
      "Training model for Norway\n",
      "Epoch [50/200], Loss: 0.0012\n",
      "Epoch [100/200], Loss: 0.0003\n",
      "Epoch [150/200], Loss: 0.0003\n",
      "Epoch [200/200], Loss: 0.0005\n",
      "\n",
      "Training model for Nepal\n",
      "Epoch [50/200], Loss: 0.0019\n",
      "Epoch [100/200], Loss: 0.0012\n",
      "Epoch [150/200], Loss: 0.0016\n",
      "Epoch [200/200], Loss: 0.0006\n",
      "\n",
      "Training model for Nauru\n",
      "Epoch [50/200], Loss: 0.0032\n",
      "Epoch [100/200], Loss: 0.0016\n",
      "Epoch [150/200], Loss: 0.0014\n",
      "Epoch [200/200], Loss: 0.0009\n",
      "\n",
      "Training model for New Zealand\n",
      "Epoch [50/200], Loss: 0.0036\n",
      "Epoch [100/200], Loss: 0.0029\n",
      "Epoch [150/200], Loss: 0.0025\n",
      "Epoch [200/200], Loss: 0.0021\n",
      "\n",
      "Training model for Oman\n",
      "Epoch [50/200], Loss: 0.0716\n",
      "Epoch [100/200], Loss: 0.0439\n",
      "Epoch [150/200], Loss: 0.0301\n",
      "Epoch [200/200], Loss: 0.0248\n",
      "\n",
      "Training model for Pakistan\n",
      "Epoch [50/200], Loss: 0.0115\n",
      "Epoch [100/200], Loss: 0.0054\n",
      "Epoch [150/200], Loss: 0.0052\n",
      "Epoch [200/200], Loss: 0.0044\n",
      "\n",
      "Training model for Panama\n",
      "Epoch [50/200], Loss: 0.0019\n",
      "Epoch [100/200], Loss: 0.0005\n",
      "Epoch [150/200], Loss: 0.0004\n",
      "Epoch [200/200], Loss: 0.0004\n",
      "\n",
      "Training model for Peru\n",
      "Epoch [50/200], Loss: 0.0222\n",
      "Epoch [100/200], Loss: 0.0164\n",
      "Epoch [150/200], Loss: 0.0136\n",
      "Epoch [200/200], Loss: 0.0114\n",
      "\n",
      "Training model for Philippines\n",
      "Epoch [50/200], Loss: 0.0215\n",
      "Epoch [100/200], Loss: 0.0111\n",
      "Epoch [150/200], Loss: 0.0056\n",
      "Epoch [200/200], Loss: 0.0068\n",
      "\n",
      "Training model for Palau\n",
      "Epoch [50/200], Loss: 0.0086\n",
      "Epoch [100/200], Loss: 0.0082\n",
      "Epoch [150/200], Loss: 0.0056\n",
      "Epoch [200/200], Loss: 0.0056\n",
      "\n",
      "Training model for Papua New Guinea\n",
      "Epoch [50/200], Loss: 0.0022\n",
      "Epoch [100/200], Loss: 0.0010\n",
      "Epoch [150/200], Loss: 0.0008\n",
      "Epoch [200/200], Loss: 0.0005\n",
      "\n",
      "Training model for Poland\n",
      "Epoch [50/200], Loss: 0.0009\n",
      "Epoch [100/200], Loss: 0.0004\n",
      "Epoch [150/200], Loss: 0.0003\n",
      "Epoch [200/200], Loss: 0.0003\n",
      "\n",
      "Training model for North Korea\n",
      "Epoch [50/200], Loss: 0.0010\n",
      "Epoch [100/200], Loss: 0.0004\n",
      "Epoch [150/200], Loss: 0.0003\n",
      "Epoch [200/200], Loss: 0.0003\n",
      "\n",
      "Training model for Portugal\n",
      "Epoch [50/200], Loss: 0.0009\n",
      "Epoch [100/200], Loss: 0.0005\n",
      "Epoch [150/200], Loss: 0.0005\n",
      "Epoch [200/200], Loss: 0.0005\n",
      "\n",
      "Training model for Paraguay\n",
      "Epoch [50/200], Loss: 0.0065\n",
      "Epoch [100/200], Loss: 0.0066\n",
      "Epoch [150/200], Loss: 0.0056\n",
      "Epoch [200/200], Loss: 0.0050\n",
      "\n",
      "Training model for Palestine, State of\n",
      "Epoch [50/200], Loss: 0.0024\n",
      "Epoch [100/200], Loss: 0.0010\n",
      "Epoch [150/200], Loss: 0.0010\n",
      "Epoch [200/200], Loss: 0.0009\n",
      "\n",
      "Training model for Qatar\n",
      "Epoch [50/200], Loss: 0.0116\n",
      "Epoch [100/200], Loss: 0.0102\n",
      "Epoch [150/200], Loss: 0.0095\n",
      "Epoch [200/200], Loss: 0.0077\n",
      "\n",
      "Training model for Romania\n",
      "Epoch [50/200], Loss: 0.0026\n",
      "Epoch [100/200], Loss: 0.0009\n",
      "Epoch [150/200], Loss: 0.0008\n",
      "Epoch [200/200], Loss: 0.0011\n",
      "\n",
      "Training model for Russian Federation\n",
      "Epoch [50/200], Loss: 0.0024\n",
      "Epoch [100/200], Loss: 0.0021\n",
      "Epoch [150/200], Loss: 0.0021\n",
      "Epoch [200/200], Loss: 0.0020\n",
      "\n",
      "Training model for Rwanda\n",
      "Epoch [50/200], Loss: 0.0034\n",
      "Epoch [100/200], Loss: 0.0004\n",
      "Epoch [150/200], Loss: 0.0004\n",
      "Epoch [200/200], Loss: 0.0004\n",
      "\n",
      "Training model for Saudi Arabia\n",
      "Epoch [50/200], Loss: 0.0021\n",
      "Epoch [100/200], Loss: 0.0008\n",
      "Epoch [150/200], Loss: 0.0007\n",
      "Epoch [200/200], Loss: 0.0008\n",
      "\n",
      "Training model for Sudan\n",
      "Epoch [50/200], Loss: 0.0013\n",
      "Epoch [100/200], Loss: 0.0007\n",
      "Epoch [150/200], Loss: 0.0007\n",
      "Epoch [200/200], Loss: 0.0006\n",
      "\n",
      "Training model for Senegal\n",
      "Epoch [50/200], Loss: 0.0257\n",
      "Epoch [100/200], Loss: 0.0067\n",
      "Epoch [150/200], Loss: 0.0023\n",
      "Epoch [200/200], Loss: 0.0017\n",
      "\n",
      "Training model for Singapore\n",
      "Epoch [50/200], Loss: 0.0010\n",
      "Epoch [100/200], Loss: 0.0006\n",
      "Epoch [150/200], Loss: 0.0005\n",
      "Epoch [200/200], Loss: 0.0004\n",
      "\n",
      "Training model for Solomon Islands\n",
      "Epoch [50/200], Loss: 0.0600\n",
      "Epoch [100/200], Loss: 0.0294\n",
      "Epoch [150/200], Loss: 0.0198\n",
      "Epoch [200/200], Loss: 0.0274\n",
      "\n",
      "Training model for Sierra Leone\n",
      "Epoch [50/200], Loss: 0.0006\n",
      "Epoch [100/200], Loss: 0.0003\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0002\n",
      "\n",
      "Training model for El Salvador\n",
      "Epoch [50/200], Loss: 0.0011\n",
      "Epoch [100/200], Loss: 0.0011\n",
      "Epoch [150/200], Loss: 0.0008\n",
      "Epoch [200/200], Loss: 0.0007\n",
      "\n",
      "Training model for San Marino\n",
      "Epoch [50/200], Loss: 0.0149\n",
      "Epoch [100/200], Loss: 0.0197\n",
      "Epoch [150/200], Loss: 0.0130\n",
      "Epoch [200/200], Loss: 0.0213\n",
      "\n",
      "Training model for Somalia\n",
      "Epoch [50/200], Loss: 0.0172\n",
      "Epoch [100/200], Loss: 0.0114\n",
      "Epoch [150/200], Loss: 0.0125\n",
      "Epoch [200/200], Loss: 0.0129\n",
      "\n",
      "Training model for Serbia\n",
      "Epoch [50/200], Loss: 0.0086\n",
      "Epoch [100/200], Loss: 0.0031\n",
      "Epoch [150/200], Loss: 0.0018\n",
      "Epoch [200/200], Loss: 0.0020\n",
      "\n",
      "Training model for South Sudan\n",
      "Epoch [50/200], Loss: 0.0507\n",
      "Epoch [100/200], Loss: 0.0198\n",
      "Epoch [150/200], Loss: 0.0075\n",
      "Epoch [200/200], Loss: 0.0033\n",
      "\n",
      "Training model for Sao Tome and Principe\n",
      "Epoch [50/200], Loss: 0.0021\n",
      "Epoch [100/200], Loss: 0.0011\n",
      "Epoch [150/200], Loss: 0.0015\n",
      "Epoch [200/200], Loss: 0.0011\n",
      "\n",
      "Training model for Suriname\n",
      "Epoch [50/200], Loss: 0.0178\n",
      "Epoch [100/200], Loss: 0.0113\n",
      "Epoch [150/200], Loss: 0.0097\n",
      "Epoch [200/200], Loss: 0.0088\n",
      "\n",
      "Training model for Slovakia\n",
      "Epoch [50/200], Loss: 0.0012\n",
      "Epoch [100/200], Loss: 0.0005\n",
      "Epoch [150/200], Loss: 0.0003\n",
      "Epoch [200/200], Loss: 0.0002\n",
      "\n",
      "Training model for Slovenia\n",
      "Epoch [50/200], Loss: 0.0015\n",
      "Epoch [100/200], Loss: 0.0010\n",
      "Epoch [150/200], Loss: 0.0008\n",
      "Epoch [200/200], Loss: 0.0009\n",
      "\n",
      "Training model for Sweden\n",
      "Epoch [50/200], Loss: 0.0025\n",
      "Epoch [100/200], Loss: 0.0025\n",
      "Epoch [150/200], Loss: 0.0025\n",
      "Epoch [200/200], Loss: 0.0020\n",
      "\n",
      "Training model for Eswatini\n",
      "Epoch [50/200], Loss: 0.0245\n",
      "Epoch [100/200], Loss: 0.0138\n",
      "Epoch [150/200], Loss: 0.0011\n",
      "Epoch [200/200], Loss: 0.0014\n",
      "\n",
      "Training model for Seychelles\n",
      "Epoch [50/200], Loss: 0.0597\n",
      "Epoch [100/200], Loss: 0.0436\n",
      "Epoch [150/200], Loss: 0.0299\n",
      "Epoch [200/200], Loss: 0.0282\n",
      "\n",
      "Training model for Syrian Arab Republic\n",
      "Epoch [50/200], Loss: 0.0318\n",
      "Epoch [100/200], Loss: 0.0076\n",
      "Epoch [150/200], Loss: 0.0056\n",
      "Epoch [200/200], Loss: 0.0056\n",
      "\n",
      "Training model for Chad\n",
      "Epoch [50/200], Loss: 0.0651\n",
      "Epoch [100/200], Loss: 0.0307\n",
      "Epoch [150/200], Loss: 0.0261\n",
      "Epoch [200/200], Loss: 0.0271\n",
      "\n",
      "Training model for Togo\n",
      "Epoch [50/200], Loss: 0.0094\n",
      "Epoch [100/200], Loss: 0.0093\n",
      "Epoch [150/200], Loss: 0.0087\n",
      "Epoch [200/200], Loss: 0.0063\n",
      "\n",
      "Training model for Thailand\n",
      "Epoch [50/200], Loss: 0.0041\n",
      "Epoch [100/200], Loss: 0.0031\n",
      "Epoch [150/200], Loss: 0.0028\n",
      "Epoch [200/200], Loss: 0.0027\n",
      "\n",
      "Training model for Tajikistan\n",
      "Epoch [50/200], Loss: 0.0037\n",
      "Epoch [100/200], Loss: 0.0005\n",
      "Epoch [150/200], Loss: 0.0004\n",
      "Epoch [200/200], Loss: 0.0004\n",
      "\n",
      "Training model for Turkmenistan\n",
      "Epoch [50/200], Loss: 0.0044\n",
      "Epoch [100/200], Loss: 0.0048\n",
      "Epoch [150/200], Loss: 0.0046\n",
      "Epoch [200/200], Loss: 0.0040\n",
      "\n",
      "Training model for Timor-Leste\n",
      "Epoch [50/200], Loss: 0.0533\n",
      "Epoch [100/200], Loss: 0.0329\n",
      "Epoch [150/200], Loss: 0.0252\n",
      "Epoch [200/200], Loss: 0.0510\n",
      "\n",
      "Training model for Tonga\n",
      "Epoch [50/200], Loss: 0.0067\n",
      "Epoch [100/200], Loss: 0.0065\n",
      "Epoch [150/200], Loss: 0.0053\n",
      "Epoch [200/200], Loss: 0.0044\n",
      "\n",
      "Training model for Trinidad and Tobago\n",
      "Epoch [50/200], Loss: 0.0004\n",
      "Epoch [100/200], Loss: 0.0002\n",
      "Epoch [150/200], Loss: 0.0001\n",
      "Epoch [200/200], Loss: 0.0001\n",
      "\n",
      "Training model for Tunisia\n",
      "Epoch [50/200], Loss: 0.0015\n",
      "Epoch [100/200], Loss: 0.0003\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0002\n",
      "\n",
      "Training model for Turkey\n",
      "Epoch [50/200], Loss: 0.0022\n",
      "Epoch [100/200], Loss: 0.0013\n",
      "Epoch [150/200], Loss: 0.0012\n",
      "Epoch [200/200], Loss: 0.0012\n",
      "\n",
      "Training model for Tuvalu\n",
      "Epoch [50/200], Loss: 0.0007\n",
      "Epoch [100/200], Loss: 0.0001\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Tanzania\n",
      "Epoch [50/200], Loss: 0.0010\n",
      "Epoch [100/200], Loss: 0.0002\n",
      "Epoch [150/200], Loss: 0.0003\n",
      "Epoch [200/200], Loss: 0.0003\n",
      "\n",
      "Training model for Uganda\n",
      "Epoch [50/200], Loss: 0.0100\n",
      "Epoch [100/200], Loss: 0.0044\n",
      "Epoch [150/200], Loss: 0.0041\n",
      "Epoch [200/200], Loss: 0.0035\n",
      "\n",
      "Training model for Ukraine\n",
      "Epoch [50/200], Loss: 0.0047\n",
      "Epoch [100/200], Loss: 0.0030\n",
      "Epoch [150/200], Loss: 0.0028\n",
      "Epoch [200/200], Loss: 0.0025\n",
      "\n",
      "Training model for Uruguay\n",
      "Epoch [50/200], Loss: 0.0317\n",
      "Epoch [100/200], Loss: 0.0182\n",
      "Epoch [150/200], Loss: 0.0104\n",
      "Epoch [200/200], Loss: 0.0055\n",
      "\n",
      "Training model for United States\n",
      "Epoch [50/200], Loss: 0.0144\n",
      "Epoch [100/200], Loss: 0.0105\n",
      "Epoch [150/200], Loss: 0.0042\n",
      "Epoch [200/200], Loss: 0.0021\n",
      "\n",
      "Training model for Uzbekistan\n",
      "Epoch [50/200], Loss: 0.0649\n",
      "Epoch [100/200], Loss: 0.0660\n",
      "Epoch [150/200], Loss: 0.0244\n",
      "Epoch [200/200], Loss: 0.0564\n",
      "\n",
      "Training model for Saint Vincent and the Grenadines\n",
      "Epoch [50/200], Loss: 0.0858\n",
      "Epoch [100/200], Loss: 0.0794\n",
      "Epoch [150/200], Loss: 0.0278\n",
      "Epoch [200/200], Loss: 0.0267\n",
      "\n",
      "Training model for Venezuela\n",
      "Epoch [50/200], Loss: 0.0021\n",
      "Epoch [100/200], Loss: 0.0009\n",
      "Epoch [150/200], Loss: 0.0007\n",
      "Epoch [200/200], Loss: 0.0007\n",
      "\n",
      "Training model for Viet Nam\n",
      "Epoch [50/200], Loss: 0.0032\n",
      "Epoch [100/200], Loss: 0.0003\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0001\n",
      "\n",
      "Training model for Vanuatu\n",
      "Epoch [50/200], Loss: 0.0027\n",
      "Epoch [100/200], Loss: 0.0020\n",
      "Epoch [150/200], Loss: 0.0012\n",
      "Epoch [200/200], Loss: 0.0011\n",
      "\n",
      "Training model for Samoa\n",
      "Epoch [50/200], Loss: 0.0054\n",
      "Epoch [100/200], Loss: 0.0041\n",
      "Epoch [150/200], Loss: 0.0035\n",
      "Epoch [200/200], Loss: 0.0031\n",
      "\n",
      "Training model for Yemen\n",
      "Epoch [50/200], Loss: 0.0035\n",
      "Epoch [100/200], Loss: 0.0006\n",
      "Epoch [150/200], Loss: 0.0005\n",
      "Epoch [200/200], Loss: 0.0005\n",
      "\n",
      "Training model for South Africa\n",
      "Epoch [50/200], Loss: 0.0081\n",
      "Epoch [100/200], Loss: 0.0078\n",
      "Epoch [150/200], Loss: 0.0073\n",
      "Epoch [200/200], Loss: 0.0082\n",
      "\n",
      "Training model for Zambia\n",
      "Epoch [50/200], Loss: 0.0027\n",
      "Epoch [100/200], Loss: 0.0023\n",
      "Epoch [150/200], Loss: 0.0026\n",
      "Epoch [200/200], Loss: 0.0027\n",
      "\n",
      "Training model for Zimbabwe\n",
      "Epoch [50/200], Loss: 0.0006\n",
      "Epoch [100/200], Loss: 0.0004\n",
      "Epoch [150/200], Loss: 0.0004\n",
      "Epoch [200/200], Loss: 0.0003\n"
     ]
    }
   ],
   "source": [
    "for country in df['Country']:\n",
    "        print(f\"\\nTraining model for {country}\")\n",
    "        \n",
    "        # Get country data\n",
    "        country_data = df[df['Country'] == country][cols].values.flatten()\n",
    "\n",
    "        country_data = country_data.astype(float)\n",
    "        \n",
    "        # Prepare data\n",
    "        X, y, scaler = prepare_country_data(country_data, sequence_length)\n",
    "        \n",
    "        if len(X) > 0:  # Check if we have enough data\n",
    "            # Train model\n",
    "            model = train_model(X, y)\n",
    "            \n",
    "            # Make predictions\n",
    "            last_sequence = scaler.transform(country_data[-sequence_length:].reshape(-1, 1))\n",
    "            predictions = predict_future(model, last_sequence, scaler)\n",
    "            predictions_by_country[country] = predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Internet (2024-2028):\n",
      "\n",
      "United States:\n",
      "2024: $13.72\n",
      "2025: $13.71\n",
      "2026: $13.69\n",
      "2027: $13.66\n",
      "2028: $13.63\n",
      "\n",
      "China:\n",
      "2024: $7.76\n",
      "2025: $7.82\n",
      "2026: $7.88\n",
      "2027: $7.92\n",
      "2028: $7.98\n",
      "\n",
      "Japan:\n",
      "2024: $13.47\n",
      "2025: $13.48\n",
      "2026: $13.49\n",
      "2027: $13.49\n",
      "2028: $13.51\n",
      "\n",
      "Germany:\n",
      "2024: $14.05\n",
      "2025: $14.04\n",
      "2026: $14.04\n",
      "2027: $14.04\n",
      "2028: $14.04\n",
      "\n",
      "United Kingdom:\n",
      "2024: $13.28\n",
      "2025: $13.29\n",
      "2026: $13.30\n",
      "2027: $13.30\n",
      "2028: $13.29\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for country in selected_countries:\n",
    "    if country in predictions_by_country:\n",
    "        plt.plot(range(2024, 2029), predictions_by_country[country], label=country)\n",
    "plt.title('Internet Predictions (2024-2028)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Internet')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "    \n",
    "    # Print predictions for selected countries\n",
    "print(\"\\nPredicted Internet (2024-2028):\")\n",
    "for country in selected_countries:\n",
    "    if country in predictions_by_country:\n",
    "        print(f\"\\n{country}:\")\n",
    "        for year, pred in zip(range(2024, 2029), predictions_by_country[country]):\n",
    "            print(f\"{year}: ${pred:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions exported to lstm_datasets/mean_schooling_prediction.csv\n"
     ]
    }
   ],
   "source": [
    "# Export predictions to CSV\n",
    "predictions_df = pd.DataFrame()\n",
    "predictions_df['Country'] = list(predictions_by_country.keys())\n",
    "\n",
    "for year in range(2024, 2029):\n",
    "    year_predictions = []\n",
    "    for country in predictions_df['Country']:\n",
    "        if country in predictions_by_country:\n",
    "            year_predictions.append(predictions_by_country[country][year-2024])\n",
    "        else:\n",
    "            year_predictions.append(None)\n",
    "    predictions_df[f'{year} Mean Schooling'] = year_predictions\n",
    "\n",
    "predictions_df.to_csv('../lstm_datasets/mean_schooling_prediction.csv', index=False)\n",
    "print(\"\\nPredictions exported to lstm_datasets/mean_schooling_prediction.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
