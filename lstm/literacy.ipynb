{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from keras>=3.5.0->tensorflow) (13.7.0)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=32, num_layers=2):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_country_data(country_data, sequence_length=5):\n",
    "    # Scale the data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(country_data.reshape(-1, 1))\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y = [], []\n",
    "    for i in range(len(scaled_data) - sequence_length):\n",
    "        X.append(scaled_data[i:(i + sequence_length)])\n",
    "        y.append(scaled_data[i + sequence_length])\n",
    "    \n",
    "    return np.array(X), np.array(y), scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, epochs=200):\n",
    "    # Create dataset and dataloader\n",
    "    X_tensor = torch.FloatTensor(X)\n",
    "    y_tensor = torch.FloatTensor(y)\n",
    "    dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "    train_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = Predictor(input_size=1)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future(model, last_sequence, scaler, n_future=5):\n",
    "    model.eval()\n",
    "    current_sequence = last_sequence.copy()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_future):\n",
    "            sequence = torch.FloatTensor(current_sequence).unsqueeze(0)\n",
    "            pred = model(sequence)\n",
    "            predictions.append(pred.numpy())\n",
    "            current_sequence = np.vstack((current_sequence[1:], pred.numpy()))\n",
    "    \n",
    "    predictions = np.array(predictions).reshape(-1, 1)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    \n",
    "    return predictions.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Code</th>\n",
       "      <th>Literacy rate 1990</th>\n",
       "      <th>Literacy rate 1991</th>\n",
       "      <th>Literacy rate 1992</th>\n",
       "      <th>Literacy rate 1993</th>\n",
       "      <th>Literacy rate 1994</th>\n",
       "      <th>Literacy rate 1995</th>\n",
       "      <th>Literacy rate 1996</th>\n",
       "      <th>Literacy rate 1997</th>\n",
       "      <th>...</th>\n",
       "      <th>Literacy rate 2014</th>\n",
       "      <th>Literacy rate 2015</th>\n",
       "      <th>Literacy rate 2016</th>\n",
       "      <th>Literacy rate 2017</th>\n",
       "      <th>Literacy rate 2018</th>\n",
       "      <th>Literacy rate 2019</th>\n",
       "      <th>Literacy rate 2020</th>\n",
       "      <th>Literacy rate 2021</th>\n",
       "      <th>Literacy rate 2022</th>\n",
       "      <th>Literacy rate 2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>33.75384</td>\n",
       "      <td>33.75384</td>\n",
       "      <td>33.75384</td>\n",
       "      <td>33.75384</td>\n",
       "      <td>33.75384</td>\n",
       "      <td>33.75384</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>37.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.55390</td>\n",
       "      <td>97.55390</td>\n",
       "      <td>98.81623</td>\n",
       "      <td>98.81623</td>\n",
       "      <td>98.81623</td>\n",
       "      <td>98.81623</td>\n",
       "      <td>98.81623</td>\n",
       "      <td>98.50000</td>\n",
       "      <td>98.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZA</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>79.60840</td>\n",
       "      <td>79.60840</td>\n",
       "      <td>79.60840</td>\n",
       "      <td>81.40784</td>\n",
       "      <td>81.40784</td>\n",
       "      <td>81.40784</td>\n",
       "      <td>81.40784</td>\n",
       "      <td>81.40784</td>\n",
       "      <td>81.40784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>AND</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>AGO</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.23586</td>\n",
       "      <td>66.23586</td>\n",
       "      <td>66.23586</td>\n",
       "      <td>66.23586</td>\n",
       "      <td>66.23586</td>\n",
       "      <td>66.23586</td>\n",
       "      <td>66.23586</td>\n",
       "      <td>72.40000</td>\n",
       "      <td>72.40000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country Code  Literacy rate 1990  Literacy rate 1991  \\\n",
       "0  Afghanistan  AFG                31.0                31.0   \n",
       "1      Albania  ALB                99.0                99.0   \n",
       "2      Algeria  DZA                70.0                70.0   \n",
       "3      Andorra  AND               100.0               100.0   \n",
       "4       Angola  AGO                67.0                67.0   \n",
       "\n",
       "   Literacy rate 1992  Literacy rate 1993  Literacy rate 1994  \\\n",
       "0                31.0                31.0                31.0   \n",
       "1                99.0                99.0                99.0   \n",
       "2                70.0                70.0                70.0   \n",
       "3               100.0               100.0               100.0   \n",
       "4                67.0                67.0                67.0   \n",
       "\n",
       "   Literacy rate 1995  Literacy rate 1996  Literacy rate 1997  ...  \\\n",
       "0                31.0                31.0                31.0  ...   \n",
       "1                99.0                99.0                99.0  ...   \n",
       "2                70.0                70.0                70.0  ...   \n",
       "3               100.0               100.0               100.0  ...   \n",
       "4                67.0                67.0                67.0  ...   \n",
       "\n",
       "   Literacy rate 2014  Literacy rate 2015  Literacy rate 2016  \\\n",
       "0                31.0            33.75384            33.75384   \n",
       "1                97.0            97.55390            97.55390   \n",
       "2                75.0            79.60840            79.60840   \n",
       "3               100.0           100.00000           100.00000   \n",
       "4                66.0            66.23586            66.23586   \n",
       "\n",
       "   Literacy rate 2017  Literacy rate 2018  Literacy rate 2019  \\\n",
       "0            33.75384            33.75384            33.75384   \n",
       "1            98.81623            98.81623            98.81623   \n",
       "2            79.60840            81.40784            81.40784   \n",
       "3           100.00000           100.00000           100.00000   \n",
       "4            66.23586            66.23586            66.23586   \n",
       "\n",
       "   Literacy rate 2020  Literacy rate 2021  Literacy rate 2022  \\\n",
       "0            33.75384            37.00000            37.00000   \n",
       "1            98.81623            98.81623            98.50000   \n",
       "2            81.40784            81.40784            81.40784   \n",
       "3           100.00000           100.00000           100.00000   \n",
       "4            66.23586            66.23586            72.40000   \n",
       "\n",
       "   Literacy rate 2023  \n",
       "0            37.00000  \n",
       "1            98.50000  \n",
       "2            81.40784  \n",
       "3           100.00000  \n",
       "4            72.40000  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/literacy.csv')\n",
    "df.head()\n",
    "df.replace(\"..\", pd.NA, inplace=True)\n",
    "# Forward fill first, then backward fill to handle any remaining NAs at the start\n",
    "df.rename(columns={'Entity': 'Country'}, inplace=True)\n",
    "df = df.ffill().bfill()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df.columns if 'Literacy' in col]\n",
    "    \n",
    "sequence_length = 5\n",
    "predictions_by_country = {}\n",
    "selected_countries = ['United States', 'China', 'Japan', 'Germany', 'United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for Afghanistan\n",
      "Epoch [50/200], Loss: 0.0187\n",
      "Epoch [100/200], Loss: 0.0204\n",
      "Epoch [150/200], Loss: 0.0163\n",
      "Epoch [200/200], Loss: 0.0205\n",
      "\n",
      "Training model for Albania\n",
      "Epoch [50/200], Loss: 0.0741\n",
      "Epoch [100/200], Loss: 0.0438\n",
      "Epoch [150/200], Loss: 0.0401\n",
      "Epoch [200/200], Loss: 0.0412\n",
      "\n",
      "Training model for Algeria\n",
      "Epoch [50/200], Loss: 0.0179\n",
      "Epoch [100/200], Loss: 0.0143\n",
      "Epoch [150/200], Loss: 0.0118\n",
      "Epoch [200/200], Loss: 0.0090\n",
      "\n",
      "Training model for Andorra\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Angola\n",
      "Epoch [50/200], Loss: 0.0481\n",
      "Epoch [100/200], Loss: 0.0305\n",
      "Epoch [150/200], Loss: 0.0264\n",
      "Epoch [200/200], Loss: 0.0366\n",
      "\n",
      "Training model for Antigua and Barbuda\n",
      "Epoch [50/200], Loss: 0.0666\n",
      "Epoch [100/200], Loss: 0.0435\n",
      "Epoch [150/200], Loss: 0.0388\n",
      "Epoch [200/200], Loss: 0.0330\n",
      "\n",
      "Training model for Arab World\n",
      "Epoch [50/200], Loss: 0.0306\n",
      "Epoch [100/200], Loss: 0.0236\n",
      "Epoch [150/200], Loss: 0.0188\n",
      "Epoch [200/200], Loss: 0.0160\n",
      "\n",
      "Training model for Arab World (WB)\n",
      "Epoch [50/200], Loss: 0.0037\n",
      "Epoch [100/200], Loss: 0.0031\n",
      "Epoch [150/200], Loss: 0.0031\n",
      "Epoch [200/200], Loss: 0.0034\n",
      "\n",
      "Training model for Argentina\n",
      "Epoch [50/200], Loss: 0.0291\n",
      "Epoch [100/200], Loss: 0.0256\n",
      "Epoch [150/200], Loss: 0.0229\n",
      "Epoch [200/200], Loss: 0.0169\n",
      "\n",
      "Training model for Armenia\n",
      "Epoch [50/200], Loss: 0.0719\n",
      "Epoch [100/200], Loss: 0.0366\n",
      "Epoch [150/200], Loss: 0.0334\n",
      "Epoch [200/200], Loss: 0.0330\n",
      "\n",
      "Training model for Aruba\n",
      "Epoch [50/200], Loss: 0.0219\n",
      "Epoch [100/200], Loss: 0.0171\n",
      "Epoch [150/200], Loss: 0.0163\n",
      "Epoch [200/200], Loss: 0.0143\n",
      "\n",
      "Training model for Australia\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Austria\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Azerbaijan\n",
      "Epoch [50/200], Loss: 0.0590\n",
      "Epoch [100/200], Loss: 0.0326\n",
      "Epoch [150/200], Loss: 0.0301\n",
      "Epoch [200/200], Loss: 0.0453\n",
      "\n",
      "Training model for Bahamas\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Bahrain\n",
      "Epoch [50/200], Loss: 0.0166\n",
      "Epoch [100/200], Loss: 0.0137\n",
      "Epoch [150/200], Loss: 0.0139\n",
      "Epoch [200/200], Loss: 0.0128\n",
      "\n",
      "Training model for Bangladesh\n",
      "Epoch [50/200], Loss: 0.0133\n",
      "Epoch [100/200], Loss: 0.0117\n",
      "Epoch [150/200], Loss: 0.0103\n",
      "Epoch [200/200], Loss: 0.0092\n",
      "\n",
      "Training model for Barbados\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Belarus\n",
      "Epoch [50/200], Loss: 0.1178\n",
      "Epoch [100/200], Loss: 0.0675\n",
      "Epoch [150/200], Loss: 0.0470\n",
      "Epoch [200/200], Loss: 0.0428\n",
      "\n",
      "Training model for Belgium\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Belize\n",
      "Epoch [50/200], Loss: 0.0289\n",
      "Epoch [100/200], Loss: 0.0243\n",
      "Epoch [150/200], Loss: 0.0195\n",
      "Epoch [200/200], Loss: 0.0154\n",
      "\n",
      "Training model for Benin\n",
      "Epoch [50/200], Loss: 0.0285\n",
      "Epoch [100/200], Loss: 0.0244\n",
      "Epoch [150/200], Loss: 0.0186\n",
      "Epoch [200/200], Loss: 0.0161\n",
      "\n",
      "Training model for Bermuda\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Bhutan\n",
      "Epoch [50/200], Loss: 0.0224\n",
      "Epoch [100/200], Loss: 0.0082\n",
      "Epoch [150/200], Loss: 0.0065\n",
      "Epoch [200/200], Loss: 0.0054\n",
      "\n",
      "Training model for Bolivia\n",
      "Epoch [50/200], Loss: 0.0222\n",
      "Epoch [100/200], Loss: 0.0175\n",
      "Epoch [150/200], Loss: 0.0170\n",
      "Epoch [200/200], Loss: 0.0160\n",
      "\n",
      "Training model for Bosnia and Herzegovina\n",
      "Epoch [50/200], Loss: 0.0475\n",
      "Epoch [100/200], Loss: 0.0335\n",
      "Epoch [150/200], Loss: 0.0265\n",
      "Epoch [200/200], Loss: 0.0311\n",
      "\n",
      "Training model for Botswana\n",
      "Epoch [50/200], Loss: 0.0333\n",
      "Epoch [100/200], Loss: 0.0257\n",
      "Epoch [150/200], Loss: 0.0195\n",
      "Epoch [200/200], Loss: 0.0172\n",
      "\n",
      "Training model for Brazil\n",
      "Epoch [50/200], Loss: 0.0119\n",
      "Epoch [100/200], Loss: 0.0114\n",
      "Epoch [150/200], Loss: 0.0093\n",
      "Epoch [200/200], Loss: 0.0075\n",
      "\n",
      "Training model for British Virgin Islands\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Brunei\n",
      "Epoch [50/200], Loss: 0.0212\n",
      "Epoch [100/200], Loss: 0.0222\n",
      "Epoch [150/200], Loss: 0.0151\n",
      "Epoch [200/200], Loss: 0.0135\n",
      "\n",
      "Training model for Bulgaria\n",
      "Epoch [50/200], Loss: 0.0451\n",
      "Epoch [100/200], Loss: 0.0437\n",
      "Epoch [150/200], Loss: 0.0406\n",
      "Epoch [200/200], Loss: 0.0256\n",
      "\n",
      "Training model for Burkina Faso\n",
      "Epoch [50/200], Loss: 0.0221\n",
      "Epoch [100/200], Loss: 0.0205\n",
      "Epoch [150/200], Loss: 0.0167\n",
      "Epoch [200/200], Loss: 0.0148\n",
      "\n",
      "Training model for Burundi\n",
      "Epoch [50/200], Loss: 0.0365\n",
      "Epoch [100/200], Loss: 0.0304\n",
      "Epoch [150/200], Loss: 0.0255\n",
      "Epoch [200/200], Loss: 0.0235\n",
      "\n",
      "Training model for Cambodia\n",
      "Epoch [50/200], Loss: 0.0294\n",
      "Epoch [100/200], Loss: 0.0252\n",
      "Epoch [150/200], Loss: 0.0257\n",
      "Epoch [200/200], Loss: 0.0290\n",
      "\n",
      "Training model for Cameroon\n",
      "Epoch [50/200], Loss: 0.0209\n",
      "Epoch [100/200], Loss: 0.0208\n",
      "Epoch [150/200], Loss: 0.0186\n",
      "Epoch [200/200], Loss: 0.0173\n",
      "\n",
      "Training model for Canada\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Cape Verde\n",
      "Epoch [50/200], Loss: 0.0164\n",
      "Epoch [100/200], Loss: 0.0161\n",
      "Epoch [150/200], Loss: 0.0144\n",
      "Epoch [200/200], Loss: 0.0108\n",
      "\n",
      "Training model for Caribbean small states\n",
      "Epoch [50/200], Loss: 0.0558\n",
      "Epoch [100/200], Loss: 0.0327\n",
      "Epoch [150/200], Loss: 0.0301\n",
      "Epoch [200/200], Loss: 0.0303\n",
      "\n",
      "Training model for Cayman Islands\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Central African Republic\n",
      "Epoch [50/200], Loss: 0.0569\n",
      "Epoch [100/200], Loss: 0.0474\n",
      "Epoch [150/200], Loss: 0.0376\n",
      "Epoch [200/200], Loss: 0.0345\n",
      "\n",
      "Training model for Central Europe and the Baltics\n",
      "Epoch [50/200], Loss: 0.0310\n",
      "Epoch [100/200], Loss: 0.0256\n",
      "Epoch [150/200], Loss: 0.0236\n",
      "Epoch [200/200], Loss: 0.0184\n",
      "\n",
      "Training model for Central Europe and the Baltics (WB)\n",
      "Epoch [50/200], Loss: 0.0248\n",
      "Epoch [100/200], Loss: 0.0210\n",
      "Epoch [150/200], Loss: 0.0128\n",
      "Epoch [200/200], Loss: 0.0169\n",
      "\n",
      "Training model for Chad\n",
      "Epoch [50/200], Loss: 0.0310\n",
      "Epoch [100/200], Loss: 0.0310\n",
      "Epoch [150/200], Loss: 0.0253\n",
      "Epoch [200/200], Loss: 0.0207\n",
      "\n",
      "Training model for Chile\n",
      "Epoch [50/200], Loss: 0.0452\n",
      "Epoch [100/200], Loss: 0.0351\n",
      "Epoch [150/200], Loss: 0.0236\n",
      "Epoch [200/200], Loss: 0.0212\n",
      "\n",
      "Training model for China\n",
      "Epoch [50/200], Loss: 0.0289\n",
      "Epoch [100/200], Loss: 0.0269\n",
      "Epoch [150/200], Loss: 0.0201\n",
      "Epoch [200/200], Loss: 0.0177\n",
      "\n",
      "Training model for Colombia\n",
      "Epoch [50/200], Loss: 0.0119\n",
      "Epoch [100/200], Loss: 0.0103\n",
      "Epoch [150/200], Loss: 0.0135\n",
      "Epoch [200/200], Loss: 0.0114\n",
      "\n",
      "Training model for Comoros\n",
      "Epoch [50/200], Loss: 0.0614\n",
      "Epoch [100/200], Loss: 0.0585\n",
      "Epoch [150/200], Loss: 0.0610\n",
      "Epoch [200/200], Loss: 0.0421\n",
      "\n",
      "Training model for Congo\n",
      "Epoch [50/200], Loss: 0.0413\n",
      "Epoch [100/200], Loss: 0.0261\n",
      "Epoch [150/200], Loss: 0.0179\n",
      "Epoch [200/200], Loss: 0.0202\n",
      "\n",
      "Training model for Cook Islands\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Costa Rica\n",
      "Epoch [50/200], Loss: 0.0283\n",
      "Epoch [100/200], Loss: 0.0278\n",
      "Epoch [150/200], Loss: 0.0161\n",
      "Epoch [200/200], Loss: 0.0153\n",
      "\n",
      "Training model for Cote d'Ivoire\n",
      "Epoch [50/200], Loss: 0.0525\n",
      "Epoch [100/200], Loss: 0.0268\n",
      "Epoch [150/200], Loss: 0.0188\n",
      "Epoch [200/200], Loss: 0.0278\n",
      "\n",
      "Training model for Croatia\n",
      "Epoch [50/200], Loss: 0.0250\n",
      "Epoch [100/200], Loss: 0.0190\n",
      "Epoch [150/200], Loss: 0.0169\n",
      "Epoch [200/200], Loss: 0.0143\n",
      "\n",
      "Training model for Cuba\n",
      "Epoch [50/200], Loss: 0.0543\n",
      "Epoch [100/200], Loss: 0.0504\n",
      "Epoch [150/200], Loss: 0.0475\n",
      "Epoch [200/200], Loss: 0.0638\n",
      "\n",
      "Training model for Cyprus\n",
      "Epoch [50/200], Loss: 0.0256\n",
      "Epoch [100/200], Loss: 0.0219\n",
      "Epoch [150/200], Loss: 0.0195\n",
      "Epoch [200/200], Loss: 0.0192\n",
      "\n",
      "Training model for Czechia\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Democratic Republic of Congo\n",
      "Epoch [50/200], Loss: 0.0478\n",
      "Epoch [100/200], Loss: 0.0250\n",
      "Epoch [150/200], Loss: 0.0168\n",
      "Epoch [200/200], Loss: 0.0121\n",
      "\n",
      "Training model for Denmark\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Djibouti\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Dominica\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Dominican Republic\n",
      "Epoch [50/200], Loss: 0.0095\n",
      "Epoch [100/200], Loss: 0.0046\n",
      "Epoch [150/200], Loss: 0.0047\n",
      "Epoch [200/200], Loss: 0.0042\n",
      "\n",
      "Training model for Early-demographic dividend\n",
      "Epoch [50/200], Loss: 0.0296\n",
      "Epoch [100/200], Loss: 0.0237\n",
      "Epoch [150/200], Loss: 0.0194\n",
      "Epoch [200/200], Loss: 0.0151\n",
      "\n",
      "Training model for East Asia & Pacific\n",
      "Epoch [50/200], Loss: 0.0321\n",
      "Epoch [100/200], Loss: 0.0278\n",
      "Epoch [150/200], Loss: 0.0292\n",
      "Epoch [200/200], Loss: 0.0178\n",
      "\n",
      "Training model for East Asia & Pacific (IDA & IBRD)\n",
      "Epoch [50/200], Loss: 0.0343\n",
      "Epoch [100/200], Loss: 0.0330\n",
      "Epoch [150/200], Loss: 0.0296\n",
      "Epoch [200/200], Loss: 0.0216\n",
      "\n",
      "Training model for East Asia & Pacific (excluding high income)\n",
      "Epoch [50/200], Loss: 0.0325\n",
      "Epoch [100/200], Loss: 0.0311\n",
      "Epoch [150/200], Loss: 0.0192\n",
      "Epoch [200/200], Loss: 0.0168\n",
      "\n",
      "Training model for East Asia and the Pacific (WB)\n",
      "Epoch [50/200], Loss: 0.0052\n",
      "Epoch [100/200], Loss: 0.0043\n",
      "Epoch [150/200], Loss: 0.0046\n",
      "Epoch [200/200], Loss: 0.0047\n",
      "\n",
      "Training model for East Timor\n",
      "Epoch [50/200], Loss: 0.0185\n",
      "Epoch [100/200], Loss: 0.0114\n",
      "Epoch [150/200], Loss: 0.0091\n",
      "Epoch [200/200], Loss: 0.0081\n",
      "\n",
      "Training model for Ecuador\n",
      "Epoch [50/200], Loss: 0.0225\n",
      "Epoch [100/200], Loss: 0.0178\n",
      "Epoch [150/200], Loss: 0.0184\n",
      "Epoch [200/200], Loss: 0.0145\n",
      "\n",
      "Training model for Egypt\n",
      "Epoch [50/200], Loss: 0.0281\n",
      "Epoch [100/200], Loss: 0.0188\n",
      "Epoch [150/200], Loss: 0.0182\n",
      "Epoch [200/200], Loss: 0.0179\n",
      "\n",
      "Training model for El Salvador\n",
      "Epoch [50/200], Loss: 0.0191\n",
      "Epoch [100/200], Loss: 0.0165\n",
      "Epoch [150/200], Loss: 0.0139\n",
      "Epoch [200/200], Loss: 0.0095\n",
      "\n",
      "Training model for Equatorial Guinea\n",
      "Epoch [50/200], Loss: 0.0571\n",
      "Epoch [100/200], Loss: 0.0292\n",
      "Epoch [150/200], Loss: 0.0246\n",
      "Epoch [200/200], Loss: 0.0372\n",
      "\n",
      "Training model for Eritrea\n",
      "Epoch [50/200], Loss: 0.0270\n",
      "Epoch [100/200], Loss: 0.0173\n",
      "Epoch [150/200], Loss: 0.0199\n",
      "Epoch [200/200], Loss: 0.0143\n",
      "\n",
      "Training model for Estonia\n",
      "Epoch [50/200], Loss: 0.0753\n",
      "Epoch [100/200], Loss: 0.0476\n",
      "Epoch [150/200], Loss: 0.0364\n",
      "Epoch [200/200], Loss: 0.0371\n",
      "\n",
      "Training model for Eswatini\n",
      "Epoch [50/200], Loss: 0.0108\n",
      "Epoch [100/200], Loss: 0.0074\n",
      "Epoch [150/200], Loss: 0.0079\n",
      "Epoch [200/200], Loss: 0.0060\n",
      "\n",
      "Training model for Ethiopia\n",
      "Epoch [50/200], Loss: 0.0180\n",
      "Epoch [100/200], Loss: 0.0157\n",
      "Epoch [150/200], Loss: 0.0148\n",
      "Epoch [200/200], Loss: 0.0172\n",
      "\n",
      "Training model for Europe & Central Asia\n",
      "Epoch [50/200], Loss: 0.0289\n",
      "Epoch [100/200], Loss: 0.0254\n",
      "Epoch [150/200], Loss: 0.0221\n",
      "Epoch [200/200], Loss: 0.0213\n",
      "\n",
      "Training model for Europe & Central Asia (IDA & IBRD)\n",
      "Epoch [50/200], Loss: 0.0282\n",
      "Epoch [100/200], Loss: 0.0237\n",
      "Epoch [150/200], Loss: 0.0206\n",
      "Epoch [200/200], Loss: 0.0200\n",
      "\n",
      "Training model for Europe & Central Asia (excluding high income)\n",
      "Epoch [50/200], Loss: 0.0322\n",
      "Epoch [100/200], Loss: 0.0261\n",
      "Epoch [150/200], Loss: 0.0216\n",
      "Epoch [200/200], Loss: 0.0179\n",
      "\n",
      "Training model for Europe and Central Asia (WB)\n",
      "Epoch [50/200], Loss: 0.0029\n",
      "Epoch [100/200], Loss: 0.0009\n",
      "Epoch [150/200], Loss: 0.0010\n",
      "Epoch [200/200], Loss: 0.0009\n",
      "\n",
      "Training model for Fiji\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Finland\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Fragile and conflict affected situations\n",
      "Epoch [50/200], Loss: 0.0613\n",
      "Epoch [100/200], Loss: 0.0324\n",
      "Epoch [150/200], Loss: 0.0305\n",
      "Epoch [200/200], Loss: 0.0298\n",
      "\n",
      "Training model for France\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Gabon\n",
      "Epoch [50/200], Loss: 0.0275\n",
      "Epoch [100/200], Loss: 0.0248\n",
      "Epoch [150/200], Loss: 0.0186\n",
      "Epoch [200/200], Loss: 0.0209\n",
      "\n",
      "Training model for Gambia\n",
      "Epoch [50/200], Loss: 0.0395\n",
      "Epoch [100/200], Loss: 0.0316\n",
      "Epoch [150/200], Loss: 0.0181\n",
      "Epoch [200/200], Loss: 0.0148\n",
      "\n",
      "Training model for Georgia\n",
      "Epoch [50/200], Loss: 0.0385\n",
      "Epoch [100/200], Loss: 0.0371\n",
      "Epoch [150/200], Loss: 0.0329\n",
      "Epoch [200/200], Loss: 0.0313\n",
      "\n",
      "Training model for Germany\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Ghana\n",
      "Epoch [50/200], Loss: 0.0561\n",
      "Epoch [100/200], Loss: 0.0440\n",
      "Epoch [150/200], Loss: 0.0328\n",
      "Epoch [200/200], Loss: 0.0296\n",
      "\n",
      "Training model for Gibraltar\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Greece\n",
      "Epoch [50/200], Loss: 0.0642\n",
      "Epoch [100/200], Loss: 0.0415\n",
      "Epoch [150/200], Loss: 0.0418\n",
      "Epoch [200/200], Loss: 0.0508\n",
      "\n",
      "Training model for Greenland\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Grenada\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Guam\n",
      "Epoch [50/200], Loss: 0.0339\n",
      "Epoch [100/200], Loss: 0.0347\n",
      "Epoch [150/200], Loss: 0.0241\n",
      "Epoch [200/200], Loss: 0.0186\n",
      "\n",
      "Training model for Guatemala\n",
      "Epoch [50/200], Loss: 0.0180\n",
      "Epoch [100/200], Loss: 0.0152\n",
      "Epoch [150/200], Loss: 0.0131\n",
      "Epoch [200/200], Loss: 0.0115\n",
      "\n",
      "Training model for Guinea\n",
      "Epoch [50/200], Loss: 0.0254\n",
      "Epoch [100/200], Loss: 0.0195\n",
      "Epoch [150/200], Loss: 0.0153\n",
      "Epoch [200/200], Loss: 0.0151\n",
      "\n",
      "Training model for Guinea-Bissau\n",
      "Epoch [50/200], Loss: 0.0492\n",
      "Epoch [100/200], Loss: 0.0201\n",
      "Epoch [150/200], Loss: 0.0177\n",
      "Epoch [200/200], Loss: 0.0113\n",
      "\n",
      "Training model for Guyana\n",
      "Epoch [50/200], Loss: 0.0438\n",
      "Epoch [100/200], Loss: 0.0356\n",
      "Epoch [150/200], Loss: 0.0243\n",
      "Epoch [200/200], Loss: 0.0145\n",
      "\n",
      "Training model for Haiti\n",
      "Epoch [50/200], Loss: 0.0656\n",
      "Epoch [100/200], Loss: 0.0253\n",
      "Epoch [150/200], Loss: 0.0220\n",
      "Epoch [200/200], Loss: 0.0202\n",
      "\n",
      "Training model for Heavily indebted poor countries (HIPC)\n",
      "Epoch [50/200], Loss: 0.0274\n",
      "Epoch [100/200], Loss: 0.0251\n",
      "Epoch [150/200], Loss: 0.0210\n",
      "Epoch [200/200], Loss: 0.0167\n",
      "\n",
      "Training model for Honduras\n",
      "Epoch [50/200], Loss: 0.0225\n",
      "Epoch [100/200], Loss: 0.0166\n",
      "Epoch [150/200], Loss: 0.0162\n",
      "Epoch [200/200], Loss: 0.0130\n",
      "\n",
      "Training model for Hong Kong\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Hungary\n",
      "Epoch [50/200], Loss: 0.0612\n",
      "Epoch [100/200], Loss: 0.0500\n",
      "Epoch [150/200], Loss: 0.0326\n",
      "Epoch [200/200], Loss: 0.0317\n",
      "\n",
      "Training model for IBRD only\n",
      "Epoch [50/200], Loss: 0.0287\n",
      "Epoch [100/200], Loss: 0.0266\n",
      "Epoch [150/200], Loss: 0.0269\n",
      "Epoch [200/200], Loss: 0.0183\n",
      "\n",
      "Training model for IDA & IBRD total\n",
      "Epoch [50/200], Loss: 0.0305\n",
      "Epoch [100/200], Loss: 0.0259\n",
      "Epoch [150/200], Loss: 0.0205\n",
      "Epoch [200/200], Loss: 0.0191\n",
      "\n",
      "Training model for IDA blend\n",
      "Epoch [50/200], Loss: 0.0607\n",
      "Epoch [100/200], Loss: 0.0502\n",
      "Epoch [150/200], Loss: 0.0459\n",
      "Epoch [200/200], Loss: 0.0305\n",
      "\n",
      "Training model for IDA only\n",
      "Epoch [50/200], Loss: 0.0321\n",
      "Epoch [100/200], Loss: 0.0277\n",
      "Epoch [150/200], Loss: 0.0197\n",
      "Epoch [200/200], Loss: 0.0209\n",
      "\n",
      "Training model for IDA total\n",
      "Epoch [50/200], Loss: 0.0306\n",
      "Epoch [100/200], Loss: 0.0243\n",
      "Epoch [150/200], Loss: 0.0203\n",
      "Epoch [200/200], Loss: 0.0172\n",
      "\n",
      "Training model for Iceland\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for India\n",
      "Epoch [50/200], Loss: 0.0141\n",
      "Epoch [100/200], Loss: 0.0134\n",
      "Epoch [150/200], Loss: 0.0129\n",
      "Epoch [200/200], Loss: 0.0136\n",
      "\n",
      "Training model for Indonesia\n",
      "Epoch [50/200], Loss: 0.0296\n",
      "Epoch [100/200], Loss: 0.0217\n",
      "Epoch [150/200], Loss: 0.0134\n",
      "Epoch [200/200], Loss: 0.0111\n",
      "\n",
      "Training model for Iran\n",
      "Epoch [50/200], Loss: 0.0070\n",
      "Epoch [100/200], Loss: 0.0056\n",
      "Epoch [150/200], Loss: 0.0063\n",
      "Epoch [200/200], Loss: 0.0062\n",
      "\n",
      "Training model for Iraq\n",
      "Epoch [50/200], Loss: 0.0243\n",
      "Epoch [100/200], Loss: 0.0107\n",
      "Epoch [150/200], Loss: 0.0090\n",
      "Epoch [200/200], Loss: 0.0075\n",
      "\n",
      "Training model for Ireland\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Israel\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Italy\n",
      "Epoch [50/200], Loss: 0.0619\n",
      "Epoch [100/200], Loss: 0.0364\n",
      "Epoch [150/200], Loss: 0.0296\n",
      "Epoch [200/200], Loss: 0.0315\n",
      "\n",
      "Training model for Jamaica\n",
      "Epoch [50/200], Loss: 0.0729\n",
      "Epoch [100/200], Loss: 0.0317\n",
      "Epoch [150/200], Loss: 0.0277\n",
      "Epoch [200/200], Loss: 0.0440\n",
      "\n",
      "Training model for Japan\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Jordan\n",
      "Epoch [50/200], Loss: 0.0265\n",
      "Epoch [100/200], Loss: 0.0112\n",
      "Epoch [150/200], Loss: 0.0076\n",
      "Epoch [200/200], Loss: 0.0084\n",
      "\n",
      "Training model for Kazakhstan\n",
      "Epoch [50/200], Loss: 0.0694\n",
      "Epoch [100/200], Loss: 0.0461\n",
      "Epoch [150/200], Loss: 0.0365\n",
      "Epoch [200/200], Loss: 0.0308\n",
      "\n",
      "Training model for Kenya\n",
      "Epoch [50/200], Loss: 0.0953\n",
      "Epoch [100/200], Loss: 0.0511\n",
      "Epoch [150/200], Loss: 0.0584\n",
      "Epoch [200/200], Loss: 0.0433\n",
      "\n",
      "Training model for Kiribati\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Kosovo\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Kuwait\n",
      "Epoch [50/200], Loss: 0.0488\n",
      "Epoch [100/200], Loss: 0.0345\n",
      "Epoch [150/200], Loss: 0.0235\n",
      "Epoch [200/200], Loss: 0.0205\n",
      "\n",
      "Training model for Kyrgyzstan\n",
      "Epoch [50/200], Loss: 0.0388\n",
      "Epoch [100/200], Loss: 0.0245\n",
      "Epoch [150/200], Loss: 0.0351\n",
      "Epoch [200/200], Loss: 0.0225\n",
      "\n",
      "Training model for Laos\n",
      "Epoch [50/200], Loss: 0.0578\n",
      "Epoch [100/200], Loss: 0.0317\n",
      "Epoch [150/200], Loss: 0.0315\n",
      "Epoch [200/200], Loss: 0.0291\n",
      "\n",
      "Training model for Late-demographic dividend\n",
      "Epoch [50/200], Loss: 0.0320\n",
      "Epoch [100/200], Loss: 0.0288\n",
      "Epoch [150/200], Loss: 0.0237\n",
      "Epoch [200/200], Loss: 0.0190\n",
      "\n",
      "Training model for Latin America & Caribbean\n",
      "Epoch [50/200], Loss: 0.0286\n",
      "Epoch [100/200], Loss: 0.0235\n",
      "Epoch [150/200], Loss: 0.0241\n",
      "Epoch [200/200], Loss: 0.0152\n",
      "\n",
      "Training model for Latin America & Caribbean (IDA & IBRD)\n",
      "Epoch [50/200], Loss: 0.0373\n",
      "Epoch [100/200], Loss: 0.0269\n",
      "Epoch [150/200], Loss: 0.0217\n",
      "Epoch [200/200], Loss: 0.0209\n",
      "\n",
      "Training model for Latin America & Caribbean (excluding high income)\n",
      "Epoch [50/200], Loss: 0.0284\n",
      "Epoch [100/200], Loss: 0.0236\n",
      "Epoch [150/200], Loss: 0.0213\n",
      "Epoch [200/200], Loss: 0.0196\n",
      "\n",
      "Training model for Latin America and Caribbean (WB)\n",
      "Epoch [50/200], Loss: 0.0006\n",
      "Epoch [100/200], Loss: 0.0003\n",
      "Epoch [150/200], Loss: 0.0003\n",
      "Epoch [200/200], Loss: 0.0003\n",
      "\n",
      "Training model for Latvia\n",
      "Epoch [50/200], Loss: 0.0517\n",
      "Epoch [100/200], Loss: 0.0374\n",
      "Epoch [150/200], Loss: 0.0525\n",
      "Epoch [200/200], Loss: 0.0359\n",
      "\n",
      "Training model for Least developed countries: UN classification\n",
      "Epoch [50/200], Loss: 0.0272\n",
      "Epoch [100/200], Loss: 0.0246\n",
      "Epoch [150/200], Loss: 0.0206\n",
      "Epoch [200/200], Loss: 0.0188\n",
      "\n",
      "Training model for Lebanon\n",
      "Epoch [50/200], Loss: 0.0253\n",
      "Epoch [100/200], Loss: 0.0192\n",
      "Epoch [150/200], Loss: 0.0186\n",
      "Epoch [200/200], Loss: 0.0170\n",
      "\n",
      "Training model for Lesotho\n",
      "Epoch [50/200], Loss: 0.0984\n",
      "Epoch [100/200], Loss: 0.0498\n",
      "Epoch [150/200], Loss: 0.0478\n",
      "Epoch [200/200], Loss: 0.0435\n",
      "\n",
      "Training model for Liberia\n",
      "Epoch [50/200], Loss: 0.0470\n",
      "Epoch [100/200], Loss: 0.0240\n",
      "Epoch [150/200], Loss: 0.0208\n",
      "Epoch [200/200], Loss: 0.0200\n",
      "\n",
      "Training model for Libya\n",
      "Epoch [50/200], Loss: 0.0297\n",
      "Epoch [100/200], Loss: 0.0237\n",
      "Epoch [150/200], Loss: 0.0196\n",
      "Epoch [200/200], Loss: 0.0149\n",
      "\n",
      "Training model for Liechtenstein\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Lithuania\n",
      "Epoch [50/200], Loss: 0.0891\n",
      "Epoch [100/200], Loss: 0.0641\n",
      "Epoch [150/200], Loss: 0.0387\n",
      "Epoch [200/200], Loss: 0.0338\n",
      "\n",
      "Training model for Low income\n",
      "Epoch [50/200], Loss: 0.0301\n",
      "Epoch [100/200], Loss: 0.0259\n",
      "Epoch [150/200], Loss: 0.0276\n",
      "Epoch [200/200], Loss: 0.0192\n",
      "\n",
      "Training model for Low-income countries\n",
      "Epoch [50/200], Loss: 0.0048\n",
      "Epoch [100/200], Loss: 0.0028\n",
      "Epoch [150/200], Loss: 0.0025\n",
      "Epoch [200/200], Loss: 0.0023\n",
      "\n",
      "Training model for Lower middle income\n",
      "Epoch [50/200], Loss: 0.0320\n",
      "Epoch [100/200], Loss: 0.0260\n",
      "Epoch [150/200], Loss: 0.0211\n",
      "Epoch [200/200], Loss: 0.0179\n",
      "\n",
      "Training model for Lower-middle-income countries\n",
      "Epoch [50/200], Loss: 0.0012\n",
      "Epoch [100/200], Loss: 0.0012\n",
      "Epoch [150/200], Loss: 0.0012\n",
      "Epoch [200/200], Loss: 0.0011\n",
      "\n",
      "Training model for Luxembourg\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Macao\n",
      "Epoch [50/200], Loss: 0.0177\n",
      "Epoch [100/200], Loss: 0.0111\n",
      "Epoch [150/200], Loss: 0.0094\n",
      "Epoch [200/200], Loss: 0.0100\n",
      "\n",
      "Training model for Madagascar\n",
      "Epoch [50/200], Loss: 0.0764\n",
      "Epoch [100/200], Loss: 0.0457\n",
      "Epoch [150/200], Loss: 0.0436\n",
      "Epoch [200/200], Loss: 0.0370\n",
      "\n",
      "Training model for Malawi\n",
      "Epoch [50/200], Loss: 0.0403\n",
      "Epoch [100/200], Loss: 0.0335\n",
      "Epoch [150/200], Loss: 0.0334\n",
      "Epoch [200/200], Loss: 0.0321\n",
      "\n",
      "Training model for Malaysia\n",
      "Epoch [50/200], Loss: 0.0178\n",
      "Epoch [100/200], Loss: 0.0162\n",
      "Epoch [150/200], Loss: 0.0146\n",
      "Epoch [200/200], Loss: 0.0160\n",
      "\n",
      "Training model for Maldives\n",
      "Epoch [50/200], Loss: 0.0584\n",
      "Epoch [100/200], Loss: 0.0603\n",
      "Epoch [150/200], Loss: 0.0262\n",
      "Epoch [200/200], Loss: 0.0073\n",
      "\n",
      "Training model for Mali\n",
      "Epoch [50/200], Loss: 0.0151\n",
      "Epoch [100/200], Loss: 0.0121\n",
      "Epoch [150/200], Loss: 0.0108\n",
      "Epoch [200/200], Loss: 0.0105\n",
      "\n",
      "Training model for Malta\n",
      "Epoch [50/200], Loss: 0.0261\n",
      "Epoch [100/200], Loss: 0.0199\n",
      "Epoch [150/200], Loss: 0.0163\n",
      "Epoch [200/200], Loss: 0.0177\n",
      "\n",
      "Training model for Marshall Islands\n",
      "Epoch [50/200], Loss: 0.0611\n",
      "Epoch [100/200], Loss: 0.0315\n",
      "Epoch [150/200], Loss: 0.0302\n",
      "Epoch [200/200], Loss: 0.0303\n",
      "\n",
      "Training model for Mauritania\n",
      "Epoch [50/200], Loss: 0.0516\n",
      "Epoch [100/200], Loss: 0.0359\n",
      "Epoch [150/200], Loss: 0.0198\n",
      "Epoch [200/200], Loss: 0.0194\n",
      "\n",
      "Training model for Mauritius\n",
      "Epoch [50/200], Loss: 0.0271\n",
      "Epoch [100/200], Loss: 0.0206\n",
      "Epoch [150/200], Loss: 0.0153\n",
      "Epoch [200/200], Loss: 0.0149\n",
      "\n",
      "Training model for Mexico\n",
      "Epoch [50/200], Loss: 0.0116\n",
      "Epoch [100/200], Loss: 0.0110\n",
      "Epoch [150/200], Loss: 0.0110\n",
      "Epoch [200/200], Loss: 0.0104\n",
      "\n",
      "Training model for Middle East & North Africa\n",
      "Epoch [50/200], Loss: 0.0274\n",
      "Epoch [100/200], Loss: 0.0270\n",
      "Epoch [150/200], Loss: 0.0217\n",
      "Epoch [200/200], Loss: 0.0155\n",
      "\n",
      "Training model for Middle East & North Africa (IDA & IBRD)\n",
      "Epoch [50/200], Loss: 0.0287\n",
      "Epoch [100/200], Loss: 0.0235\n",
      "Epoch [150/200], Loss: 0.0234\n",
      "Epoch [200/200], Loss: 0.0158\n",
      "\n",
      "Training model for Middle East & North Africa (excluding high income)\n",
      "Epoch [50/200], Loss: 0.0320\n",
      "Epoch [100/200], Loss: 0.0245\n",
      "Epoch [150/200], Loss: 0.0209\n",
      "Epoch [200/200], Loss: 0.0170\n",
      "\n",
      "Training model for Middle East and North Africa (WB)\n",
      "Epoch [50/200], Loss: 0.0023\n",
      "Epoch [100/200], Loss: 0.0014\n",
      "Epoch [150/200], Loss: 0.0012\n",
      "Epoch [200/200], Loss: 0.0012\n",
      "\n",
      "Training model for Middle income\n",
      "Epoch [50/200], Loss: 0.0304\n",
      "Epoch [100/200], Loss: 0.0258\n",
      "Epoch [150/200], Loss: 0.0224\n",
      "Epoch [200/200], Loss: 0.0179\n",
      "\n",
      "Training model for Moldova\n",
      "Epoch [50/200], Loss: 0.0409\n",
      "Epoch [100/200], Loss: 0.0321\n",
      "Epoch [150/200], Loss: 0.0301\n",
      "Epoch [200/200], Loss: 0.0191\n",
      "\n",
      "Training model for Monaco\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Mongolia\n",
      "Epoch [50/200], Loss: 0.0590\n",
      "Epoch [100/200], Loss: 0.0473\n",
      "Epoch [150/200], Loss: 0.0219\n",
      "Epoch [200/200], Loss: 0.0161\n",
      "\n",
      "Training model for Montenegro\n",
      "Epoch [50/200], Loss: 0.0461\n",
      "Epoch [100/200], Loss: 0.0280\n",
      "Epoch [150/200], Loss: 0.0223\n",
      "Epoch [200/200], Loss: 0.0320\n",
      "\n",
      "Training model for Morocco\n",
      "Epoch [50/200], Loss: 0.0147\n",
      "Epoch [100/200], Loss: 0.0090\n",
      "Epoch [150/200], Loss: 0.0100\n",
      "Epoch [200/200], Loss: 0.0085\n",
      "\n",
      "Training model for Mozambique\n",
      "Epoch [50/200], Loss: 0.0194\n",
      "Epoch [100/200], Loss: 0.0168\n",
      "Epoch [150/200], Loss: 0.0145\n",
      "Epoch [200/200], Loss: 0.0128\n",
      "\n",
      "Training model for Myanmar\n",
      "Epoch [50/200], Loss: 0.0693\n",
      "Epoch [100/200], Loss: 0.0589\n",
      "Epoch [150/200], Loss: 0.0531\n",
      "Epoch [200/200], Loss: 0.0382\n",
      "\n",
      "Training model for Namibia\n",
      "Epoch [50/200], Loss: 0.0635\n",
      "Epoch [100/200], Loss: 0.0328\n",
      "Epoch [150/200], Loss: 0.0300\n",
      "Epoch [200/200], Loss: 0.0293\n",
      "\n",
      "Training model for Nepal\n",
      "Epoch [50/200], Loss: 0.0154\n",
      "Epoch [100/200], Loss: 0.0139\n",
      "Epoch [150/200], Loss: 0.0132\n",
      "Epoch [200/200], Loss: 0.0115\n",
      "\n",
      "Training model for Netherlands\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for New Caledonia\n",
      "Epoch [50/200], Loss: 0.0713\n",
      "Epoch [100/200], Loss: 0.0404\n",
      "Epoch [150/200], Loss: 0.0529\n",
      "Epoch [200/200], Loss: 0.0332\n",
      "\n",
      "Training model for New Zealand\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Nicaragua\n",
      "Epoch [50/200], Loss: 0.0205\n",
      "Epoch [100/200], Loss: 0.0200\n",
      "Epoch [150/200], Loss: 0.0175\n",
      "Epoch [200/200], Loss: 0.0158\n",
      "\n",
      "Training model for Niger\n",
      "Epoch [50/200], Loss: 0.0645\n",
      "Epoch [100/200], Loss: 0.0406\n",
      "Epoch [150/200], Loss: 0.0352\n",
      "Epoch [200/200], Loss: 0.0429\n",
      "\n",
      "Training model for Nigeria\n",
      "Epoch [50/200], Loss: 0.0702\n",
      "Epoch [100/200], Loss: 0.0609\n",
      "Epoch [150/200], Loss: 0.0421\n",
      "Epoch [200/200], Loss: 0.0319\n",
      "\n",
      "Training model for Niue\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for North America (WB)\n",
      "Epoch [50/200], Loss: 0.0159\n",
      "Epoch [100/200], Loss: 0.0156\n",
      "Epoch [150/200], Loss: 0.0122\n",
      "Epoch [200/200], Loss: 0.0084\n",
      "\n",
      "Training model for North Korea\n",
      "Epoch [50/200], Loss: 0.0221\n",
      "Epoch [100/200], Loss: 0.0126\n",
      "Epoch [150/200], Loss: 0.0152\n",
      "Epoch [200/200], Loss: 0.0097\n",
      "\n",
      "Training model for North Macedonia\n",
      "Epoch [50/200], Loss: 0.0280\n",
      "Epoch [100/200], Loss: 0.0260\n",
      "Epoch [150/200], Loss: 0.0227\n",
      "Epoch [200/200], Loss: 0.0188\n",
      "\n",
      "Training model for Norway\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Oman\n",
      "Epoch [50/200], Loss: 0.0154\n",
      "Epoch [100/200], Loss: 0.0143\n",
      "Epoch [150/200], Loss: 0.0121\n",
      "Epoch [200/200], Loss: 0.0096\n",
      "\n",
      "Training model for Other small states\n",
      "Epoch [50/200], Loss: 0.0300\n",
      "Epoch [100/200], Loss: 0.0253\n",
      "Epoch [150/200], Loss: 0.0222\n",
      "Epoch [200/200], Loss: 0.0208\n",
      "\n",
      "Training model for Pacific island small states\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Pakistan\n",
      "Epoch [50/200], Loss: 0.0278\n",
      "Epoch [100/200], Loss: 0.0202\n",
      "Epoch [150/200], Loss: 0.0144\n",
      "Epoch [200/200], Loss: 0.0127\n",
      "\n",
      "Training model for Palau\n",
      "Epoch [50/200], Loss: 0.0421\n",
      "Epoch [100/200], Loss: 0.0293\n",
      "Epoch [150/200], Loss: 0.0223\n",
      "Epoch [200/200], Loss: 0.0201\n",
      "\n",
      "Training model for Palestine\n",
      "Epoch [50/200], Loss: 0.0231\n",
      "Epoch [100/200], Loss: 0.0168\n",
      "Epoch [150/200], Loss: 0.0096\n",
      "Epoch [200/200], Loss: 0.0084\n",
      "\n",
      "Training model for Panama\n",
      "Epoch [50/200], Loss: 0.0146\n",
      "Epoch [100/200], Loss: 0.0138\n",
      "Epoch [150/200], Loss: 0.0129\n",
      "Epoch [200/200], Loss: 0.0112\n",
      "\n",
      "Training model for Papua New Guinea\n",
      "Epoch [50/200], Loss: 0.0169\n",
      "Epoch [100/200], Loss: 0.0135\n",
      "Epoch [150/200], Loss: 0.0141\n",
      "Epoch [200/200], Loss: 0.0112\n",
      "\n",
      "Training model for Paraguay\n",
      "Epoch [50/200], Loss: 0.0490\n",
      "Epoch [100/200], Loss: 0.0310\n",
      "Epoch [150/200], Loss: 0.0281\n",
      "Epoch [200/200], Loss: 0.0264\n",
      "\n",
      "Training model for Peru\n",
      "Epoch [50/200], Loss: 0.0158\n",
      "Epoch [100/200], Loss: 0.0139\n",
      "Epoch [150/200], Loss: 0.0116\n",
      "Epoch [200/200], Loss: 0.0125\n",
      "\n",
      "Training model for Philippines\n",
      "Epoch [50/200], Loss: 0.0372\n",
      "Epoch [100/200], Loss: 0.0283\n",
      "Epoch [150/200], Loss: 0.0236\n",
      "Epoch [200/200], Loss: 0.0161\n",
      "\n",
      "Training model for Poland\n",
      "Epoch [50/200], Loss: 0.0287\n",
      "Epoch [100/200], Loss: 0.0228\n",
      "Epoch [150/200], Loss: 0.0193\n",
      "Epoch [200/200], Loss: 0.0151\n",
      "\n",
      "Training model for Portugal\n",
      "Epoch [50/200], Loss: 0.0398\n",
      "Epoch [100/200], Loss: 0.0251\n",
      "Epoch [150/200], Loss: 0.0190\n",
      "Epoch [200/200], Loss: 0.0157\n",
      "\n",
      "Training model for Pre-demographic dividend\n",
      "Epoch [50/200], Loss: 0.0315\n",
      "Epoch [100/200], Loss: 0.0278\n",
      "Epoch [150/200], Loss: 0.0277\n",
      "Epoch [200/200], Loss: 0.0169\n",
      "\n",
      "Training model for Puerto Rico\n",
      "Epoch [50/200], Loss: 0.0220\n",
      "Epoch [100/200], Loss: 0.0148\n",
      "Epoch [150/200], Loss: 0.0133\n",
      "Epoch [200/200], Loss: 0.0129\n",
      "\n",
      "Training model for Qatar\n",
      "Epoch [50/200], Loss: 0.0193\n",
      "Epoch [100/200], Loss: 0.0083\n",
      "Epoch [150/200], Loss: 0.0066\n",
      "Epoch [200/200], Loss: 0.0058\n",
      "\n",
      "Training model for Romania\n",
      "Epoch [50/200], Loss: 0.0588\n",
      "Epoch [100/200], Loss: 0.0335\n",
      "Epoch [150/200], Loss: 0.0523\n",
      "Epoch [200/200], Loss: 0.0310\n",
      "\n",
      "Training model for Russia\n",
      "Epoch [50/200], Loss: 0.0725\n",
      "Epoch [100/200], Loss: 0.0399\n",
      "Epoch [150/200], Loss: 0.0366\n",
      "Epoch [200/200], Loss: 0.0347\n",
      "\n",
      "Training model for Rwanda\n",
      "Epoch [50/200], Loss: 0.0113\n",
      "Epoch [100/200], Loss: 0.0110\n",
      "Epoch [150/200], Loss: 0.0105\n",
      "Epoch [200/200], Loss: 0.0103\n",
      "\n",
      "Training model for Saint Kitts and Nevis\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Saint Lucia\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Samoa\n",
      "Epoch [50/200], Loss: 0.0786\n",
      "Epoch [100/200], Loss: 0.0738\n",
      "Epoch [150/200], Loss: 0.0665\n",
      "Epoch [200/200], Loss: 0.0567\n",
      "\n",
      "Training model for San Marino\n",
      "Epoch [50/200], Loss: 0.0656\n",
      "Epoch [100/200], Loss: 0.0305\n",
      "Epoch [150/200], Loss: 0.0308\n",
      "Epoch [200/200], Loss: 0.0306\n",
      "\n",
      "Training model for Sao Tome and Principe\n",
      "Epoch [50/200], Loss: 0.0838\n",
      "Epoch [100/200], Loss: 0.0507\n",
      "Epoch [150/200], Loss: 0.0387\n",
      "Epoch [200/200], Loss: 0.0384\n",
      "\n",
      "Training model for Saudi Arabia\n",
      "Epoch [50/200], Loss: 0.0168\n",
      "Epoch [100/200], Loss: 0.0133\n",
      "Epoch [150/200], Loss: 0.0130\n",
      "Epoch [200/200], Loss: 0.0111\n",
      "\n",
      "Training model for Senegal\n",
      "Epoch [50/200], Loss: 0.0467\n",
      "Epoch [100/200], Loss: 0.0359\n",
      "Epoch [150/200], Loss: 0.0251\n",
      "Epoch [200/200], Loss: 0.0181\n",
      "\n",
      "Training model for Serbia\n",
      "Epoch [50/200], Loss: 0.0333\n",
      "Epoch [100/200], Loss: 0.0228\n",
      "Epoch [150/200], Loss: 0.0201\n",
      "Epoch [200/200], Loss: 0.0170\n",
      "\n",
      "Training model for Seychelles\n",
      "Epoch [50/200], Loss: 0.0184\n",
      "Epoch [100/200], Loss: 0.0164\n",
      "Epoch [150/200], Loss: 0.0138\n",
      "Epoch [200/200], Loss: 0.0117\n",
      "\n",
      "Training model for Sierra Leone\n",
      "Epoch [50/200], Loss: 0.0609\n",
      "Epoch [100/200], Loss: 0.0556\n",
      "Epoch [150/200], Loss: 0.0474\n",
      "Epoch [200/200], Loss: 0.0287\n",
      "\n",
      "Training model for Singapore\n",
      "Epoch [50/200], Loss: 0.0185\n",
      "Epoch [100/200], Loss: 0.0164\n",
      "Epoch [150/200], Loss: 0.0149\n",
      "Epoch [200/200], Loss: 0.0120\n",
      "\n",
      "Training model for Slovakia\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Slovenia\n",
      "Epoch [50/200], Loss: 0.0497\n",
      "Epoch [100/200], Loss: 0.0508\n",
      "Epoch [150/200], Loss: 0.0302\n",
      "Epoch [200/200], Loss: 0.0301\n",
      "\n",
      "Training model for Small states\n",
      "Epoch [50/200], Loss: 0.0302\n",
      "Epoch [100/200], Loss: 0.0273\n",
      "Epoch [150/200], Loss: 0.0237\n",
      "Epoch [200/200], Loss: 0.0210\n",
      "\n",
      "Training model for Solomon Islands\n",
      "Epoch [50/200], Loss: 0.0602\n",
      "Epoch [100/200], Loss: 0.0345\n",
      "Epoch [150/200], Loss: 0.0303\n",
      "Epoch [200/200], Loss: 0.0324\n",
      "\n",
      "Training model for Somalia\n",
      "Epoch [50/200], Loss: 0.0551\n",
      "Epoch [100/200], Loss: 0.0308\n",
      "Epoch [150/200], Loss: 0.0309\n",
      "Epoch [200/200], Loss: 0.0304\n",
      "\n",
      "Training model for South Africa\n",
      "Epoch [50/200], Loss: 0.0537\n",
      "Epoch [100/200], Loss: 0.0337\n",
      "Epoch [150/200], Loss: 0.0268\n",
      "Epoch [200/200], Loss: 0.0293\n",
      "\n",
      "Training model for South Asia\n",
      "Epoch [50/200], Loss: 0.0286\n",
      "Epoch [100/200], Loss: 0.0278\n",
      "Epoch [150/200], Loss: 0.0213\n",
      "Epoch [200/200], Loss: 0.0206\n",
      "\n",
      "Training model for South Asia (IDA & IBRD)\n",
      "Epoch [50/200], Loss: 0.0290\n",
      "Epoch [100/200], Loss: 0.0253\n",
      "Epoch [150/200], Loss: 0.0212\n",
      "Epoch [200/200], Loss: 0.0183\n",
      "\n",
      "Training model for South Asia (WB)\n",
      "Epoch [50/200], Loss: 0.0020\n",
      "Epoch [100/200], Loss: 0.0019\n",
      "Epoch [150/200], Loss: 0.0017\n",
      "Epoch [200/200], Loss: 0.0018\n",
      "\n",
      "Training model for South Korea\n",
      "Epoch [50/200], Loss: 0.0573\n",
      "Epoch [100/200], Loss: 0.0321\n",
      "Epoch [150/200], Loss: 0.0295\n",
      "Epoch [200/200], Loss: 0.0306\n",
      "\n",
      "Training model for South Sudan\n",
      "Epoch [50/200], Loss: 0.0257\n",
      "Epoch [100/200], Loss: 0.0195\n",
      "Epoch [150/200], Loss: 0.0264\n",
      "Epoch [200/200], Loss: 0.0154\n",
      "\n",
      "Training model for Southern and Eastern Africa (WB)\n",
      "Epoch [50/200], Loss: 0.0093\n",
      "Epoch [100/200], Loss: 0.0094\n",
      "Epoch [150/200], Loss: 0.0066\n",
      "Epoch [200/200], Loss: 0.0062\n",
      "\n",
      "Training model for Spain\n",
      "Epoch [50/200], Loss: 0.0311\n",
      "Epoch [100/200], Loss: 0.0258\n",
      "Epoch [150/200], Loss: 0.0178\n",
      "Epoch [200/200], Loss: 0.0115\n",
      "\n",
      "Training model for Sri Lanka\n",
      "Epoch [50/200], Loss: 0.0426\n",
      "Epoch [100/200], Loss: 0.0325\n",
      "Epoch [150/200], Loss: 0.0484\n",
      "Epoch [200/200], Loss: 0.0302\n",
      "\n",
      "Training model for Sub-Saharan Africa\n",
      "Epoch [50/200], Loss: 0.0571\n",
      "Epoch [100/200], Loss: 0.0317\n",
      "Epoch [150/200], Loss: 0.0314\n",
      "Epoch [200/200], Loss: 0.0302\n",
      "\n",
      "Training model for Sub-Saharan Africa (IDA & IBRD)\n",
      "Epoch [50/200], Loss: 0.0294\n",
      "Epoch [100/200], Loss: 0.0235\n",
      "Epoch [150/200], Loss: 0.0199\n",
      "Epoch [200/200], Loss: 0.0158\n",
      "\n",
      "Training model for Sub-Saharan Africa (WB)\n",
      "Epoch [50/200], Loss: 0.0047\n",
      "Epoch [100/200], Loss: 0.0043\n",
      "Epoch [150/200], Loss: 0.0044\n",
      "Epoch [200/200], Loss: 0.0036\n",
      "\n",
      "Training model for Sub-Saharan Africa (excluding high income)\n",
      "Epoch [50/200], Loss: 0.0665\n",
      "Epoch [100/200], Loss: 0.0368\n",
      "Epoch [150/200], Loss: 0.0486\n",
      "Epoch [200/200], Loss: 0.0304\n",
      "\n",
      "Training model for Sudan\n",
      "Epoch [50/200], Loss: 0.0997\n",
      "Epoch [100/200], Loss: 0.0474\n",
      "Epoch [150/200], Loss: 0.0456\n",
      "Epoch [200/200], Loss: 0.0429\n",
      "\n",
      "Training model for Suriname\n",
      "Epoch [50/200], Loss: 0.0687\n",
      "Epoch [100/200], Loss: 0.0438\n",
      "Epoch [150/200], Loss: 0.0343\n",
      "Epoch [200/200], Loss: 0.0333\n",
      "\n",
      "Training model for Sweden\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Switzerland\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Syria\n",
      "Epoch [50/200], Loss: 0.0272\n",
      "Epoch [100/200], Loss: 0.0239\n",
      "Epoch [150/200], Loss: 0.0215\n",
      "Epoch [200/200], Loss: 0.0191\n",
      "\n",
      "Training model for Taiwan\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Tajikistan\n",
      "Epoch [50/200], Loss: 0.0630\n",
      "Epoch [100/200], Loss: 0.0436\n",
      "Epoch [150/200], Loss: 0.0247\n",
      "Epoch [200/200], Loss: 0.0254\n",
      "\n",
      "Training model for Tanzania\n",
      "Epoch [50/200], Loss: 0.0367\n",
      "Epoch [100/200], Loss: 0.0346\n",
      "Epoch [150/200], Loss: 0.0290\n",
      "Epoch [200/200], Loss: 0.0180\n",
      "\n",
      "Training model for Thailand\n",
      "Epoch [50/200], Loss: 0.0594\n",
      "Epoch [100/200], Loss: 0.0375\n",
      "Epoch [150/200], Loss: 0.0251\n",
      "Epoch [200/200], Loss: 0.0239\n",
      "\n",
      "Training model for Togo\n",
      "Epoch [50/200], Loss: 0.0086\n",
      "Epoch [100/200], Loss: 0.0065\n",
      "Epoch [150/200], Loss: 0.0064\n",
      "Epoch [200/200], Loss: 0.0060\n",
      "\n",
      "Training model for Tonga\n",
      "Epoch [50/200], Loss: 0.0556\n",
      "Epoch [100/200], Loss: 0.0710\n",
      "Epoch [150/200], Loss: 0.0708\n",
      "Epoch [200/200], Loss: 0.0535\n",
      "\n",
      "Training model for Trinidad and Tobago\n",
      "Epoch [50/200], Loss: 0.0213\n",
      "Epoch [100/200], Loss: 0.0180\n",
      "Epoch [150/200], Loss: 0.0185\n",
      "Epoch [200/200], Loss: 0.0145\n",
      "\n",
      "Training model for Tunisia\n",
      "Epoch [50/200], Loss: 0.0262\n",
      "Epoch [100/200], Loss: 0.0215\n",
      "Epoch [150/200], Loss: 0.0141\n",
      "Epoch [200/200], Loss: 0.0129\n",
      "\n",
      "Training model for Turkey\n",
      "Epoch [50/200], Loss: 0.0173\n",
      "Epoch [100/200], Loss: 0.0162\n",
      "Epoch [150/200], Loss: 0.0114\n",
      "Epoch [200/200], Loss: 0.0109\n",
      "\n",
      "Training model for Turkmenistan\n",
      "Epoch [50/200], Loss: 0.0304\n",
      "Epoch [100/200], Loss: 0.0252\n",
      "Epoch [150/200], Loss: 0.0254\n",
      "Epoch [200/200], Loss: 0.0147\n",
      "\n",
      "Training model for Uganda\n",
      "Epoch [50/200], Loss: 0.0307\n",
      "Epoch [100/200], Loss: 0.0248\n",
      "Epoch [150/200], Loss: 0.0215\n",
      "Epoch [200/200], Loss: 0.0164\n",
      "\n",
      "Training model for Ukraine\n",
      "Epoch [50/200], Loss: 0.0543\n",
      "Epoch [100/200], Loss: 0.0543\n",
      "Epoch [150/200], Loss: 0.0305\n",
      "Epoch [200/200], Loss: 0.0301\n",
      "\n",
      "Training model for United Arab Emirates\n",
      "Epoch [50/200], Loss: 0.0203\n",
      "Epoch [100/200], Loss: 0.0090\n",
      "Epoch [150/200], Loss: 0.0120\n",
      "Epoch [200/200], Loss: 0.0091\n",
      "\n",
      "Training model for United Kingdom\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for United States\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Upper middle income\n",
      "Epoch [50/200], Loss: 0.0341\n",
      "Epoch [100/200], Loss: 0.0264\n",
      "Epoch [150/200], Loss: 0.0219\n",
      "Epoch [200/200], Loss: 0.0182\n",
      "\n",
      "Training model for Upper-middle-income countries\n",
      "Epoch [50/200], Loss: 0.0031\n",
      "Epoch [100/200], Loss: 0.0031\n",
      "Epoch [150/200], Loss: 0.0038\n",
      "Epoch [200/200], Loss: 0.0030\n",
      "\n",
      "Training model for Uruguay\n",
      "Epoch [50/200], Loss: 0.0286\n",
      "Epoch [100/200], Loss: 0.0276\n",
      "Epoch [150/200], Loss: 0.0212\n",
      "Epoch [200/200], Loss: 0.0196\n",
      "\n",
      "Training model for Uzbekistan\n",
      "Epoch [50/200], Loss: 0.0645\n",
      "Epoch [100/200], Loss: 0.0492\n",
      "Epoch [150/200], Loss: 0.0307\n",
      "Epoch [200/200], Loss: 0.0306\n",
      "\n",
      "Training model for Vanuatu\n",
      "Epoch [50/200], Loss: 0.0121\n",
      "Epoch [100/200], Loss: 0.0123\n",
      "Epoch [150/200], Loss: 0.0124\n",
      "Epoch [200/200], Loss: 0.0100\n",
      "\n",
      "Training model for Vatican\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Venezuela\n",
      "Epoch [50/200], Loss: 0.0185\n",
      "Epoch [100/200], Loss: 0.0172\n",
      "Epoch [150/200], Loss: 0.0158\n",
      "Epoch [200/200], Loss: 0.0126\n",
      "\n",
      "Training model for Vietnam\n",
      "Epoch [50/200], Loss: 0.0298\n",
      "Epoch [100/200], Loss: 0.0209\n",
      "Epoch [150/200], Loss: 0.0172\n",
      "Epoch [200/200], Loss: 0.0160\n",
      "\n",
      "Training model for Virgin Islands\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Western and Central Africa (WB)\n",
      "Epoch [50/200], Loss: 0.0070\n",
      "Epoch [100/200], Loss: 0.0070\n",
      "Epoch [150/200], Loss: 0.0066\n",
      "Epoch [200/200], Loss: 0.0059\n",
      "\n",
      "Training model for World\n",
      "Epoch [50/200], Loss: 0.0018\n",
      "Epoch [100/200], Loss: 0.0020\n",
      "Epoch [150/200], Loss: 0.0017\n",
      "Epoch [200/200], Loss: 0.0021\n",
      "\n",
      "Training model for Yemen\n",
      "Epoch [50/200], Loss: 0.0303\n",
      "Epoch [100/200], Loss: 0.0290\n",
      "Epoch [150/200], Loss: 0.0181\n",
      "Epoch [200/200], Loss: 0.0190\n",
      "\n",
      "Training model for Zambia\n",
      "Epoch [50/200], Loss: 0.0728\n",
      "Epoch [100/200], Loss: 0.0684\n",
      "Epoch [150/200], Loss: 0.0466\n",
      "Epoch [200/200], Loss: 0.0356\n",
      "\n",
      "Training model for Zimbabwe\n",
      "Epoch [50/200], Loss: 0.0319\n",
      "Epoch [100/200], Loss: 0.0237\n",
      "Epoch [150/200], Loss: 0.0214\n",
      "Epoch [200/200], Loss: 0.0159\n"
     ]
    }
   ],
   "source": [
    "for country in df['Country']:\n",
    "        print(f\"\\nTraining model for {country}\")\n",
    "        \n",
    "        # Get country data\n",
    "        country_data = df[df['Country'] == country][cols].values.flatten()\n",
    "\n",
    "        country_data = country_data.astype(float)\n",
    "        \n",
    "        # Prepare data\n",
    "        X, y, scaler = prepare_country_data(country_data, sequence_length)\n",
    "        \n",
    "        if len(X) > 0:  # Check if we have enough data\n",
    "            # Train model\n",
    "            model = train_model(X, y)\n",
    "            \n",
    "            # Make predictions\n",
    "            last_sequence = scaler.transform(country_data[-sequence_length:].reshape(-1, 1))\n",
    "            predictions = predict_future(model, last_sequence, scaler)\n",
    "            predictions_by_country[country] = predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Internet (2024-2028):\n",
      "\n",
      "United States:\n",
      "2024: $99.00\n",
      "2025: $99.00\n",
      "2026: $99.00\n",
      "2027: $99.00\n",
      "2028: $99.00\n",
      "\n",
      "China:\n",
      "2024: $97.02\n",
      "2025: $97.01\n",
      "2026: $97.02\n",
      "2027: $97.02\n",
      "2028: $97.02\n",
      "\n",
      "Japan:\n",
      "2024: $99.00\n",
      "2025: $99.00\n",
      "2026: $99.00\n",
      "2027: $99.00\n",
      "2028: $99.00\n",
      "\n",
      "Germany:\n",
      "2024: $99.00\n",
      "2025: $99.00\n",
      "2026: $99.00\n",
      "2027: $99.00\n",
      "2028: $99.00\n",
      "\n",
      "United Kingdom:\n",
      "2024: $99.00\n",
      "2025: $99.00\n",
      "2026: $99.00\n",
      "2027: $99.00\n",
      "2028: $99.00\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for country in selected_countries:\n",
    "    if country in predictions_by_country:\n",
    "        plt.plot(range(2024, 2029), predictions_by_country[country], label=country)\n",
    "plt.title('Internet Predictions (2024-2028)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Internet')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "    \n",
    "    # Print predictions for selected countries\n",
    "print(\"\\nPredicted Internet (2024-2028):\")\n",
    "for country in selected_countries:\n",
    "    if country in predictions_by_country:\n",
    "        print(f\"\\n{country}:\")\n",
    "        for year, pred in zip(range(2024, 2029), predictions_by_country[country]):\n",
    "            print(f\"{year}: ${pred:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions exported to lstm_datasets/literacy_prediction.csv\n"
     ]
    }
   ],
   "source": [
    "# Export predictions to CSV\n",
    "predictions_df = pd.DataFrame()\n",
    "predictions_df['Country'] = list(predictions_by_country.keys())\n",
    "\n",
    "for year in range(2024, 2029):\n",
    "    year_predictions = []\n",
    "    for country in predictions_df['Country']:\n",
    "        if country in predictions_by_country:\n",
    "            year_predictions.append(predictions_by_country[country][year-2024])\n",
    "        else:\n",
    "            year_predictions.append(None)\n",
    "    predictions_df[f'{year} Literacy'] = year_predictions\n",
    "\n",
    "predictions_df.to_csv('../lstm_datasets/literacy_prediction.csv', index=False)\n",
    "print(\"\\nPredictions exported to lstm_datasets/literacy_prediction.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
