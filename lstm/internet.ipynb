{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from keras>=3.5.0->tensorflow) (13.7.0)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=32, num_layers=2):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_country_data(country_data, sequence_length=5):\n",
    "    # Scale the data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(country_data.reshape(-1, 1))\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y = [], []\n",
    "    for i in range(len(scaled_data) - sequence_length):\n",
    "        X.append(scaled_data[i:(i + sequence_length)])\n",
    "        y.append(scaled_data[i + sequence_length])\n",
    "    \n",
    "    return np.array(X), np.array(y), scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, epochs=200):\n",
    "    # Create dataset and dataloader\n",
    "    X_tensor = torch.FloatTensor(X)\n",
    "    y_tensor = torch.FloatTensor(y)\n",
    "    dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "    train_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = Predictor(input_size=1)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future(model, last_sequence, scaler, n_future=5):\n",
    "    model.eval()\n",
    "    current_sequence = last_sequence.copy()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_future):\n",
    "            sequence = torch.FloatTensor(current_sequence).unsqueeze(0)\n",
    "            pred = model(sequence)\n",
    "            predictions.append(pred.numpy())\n",
    "            current_sequence = np.vstack((current_sequence[1:], pred.numpy()))\n",
    "    \n",
    "    predictions = np.array(predictions).reshape(-1, 1)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    \n",
    "    return predictions.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>code</th>\n",
       "      <th>Internet Usage (% of Population) 1990</th>\n",
       "      <th>Internet Usage (% of Population) 1991</th>\n",
       "      <th>Internet Usage (% of Population) 1992</th>\n",
       "      <th>Internet Usage (% of Population) 1993</th>\n",
       "      <th>Internet Usage (% of Population) 1994</th>\n",
       "      <th>Internet Usage (% of Population) 1995</th>\n",
       "      <th>Internet Usage (% of Population) 1996</th>\n",
       "      <th>Internet Usage (% of Population) 1997</th>\n",
       "      <th>...</th>\n",
       "      <th>Internet Usage (% of Population) 2014</th>\n",
       "      <th>Internet Usage (% of Population) 2015</th>\n",
       "      <th>Internet Usage (% of Population) 2016</th>\n",
       "      <th>Internet Usage (% of Population) 2017</th>\n",
       "      <th>Internet Usage (% of Population) 2018</th>\n",
       "      <th>Internet Usage (% of Population) 2019</th>\n",
       "      <th>Internet Usage (% of Population) 2020</th>\n",
       "      <th>Internet Usage (% of Population) 2021</th>\n",
       "      <th>Internet Usage (% of Population) 2022</th>\n",
       "      <th>Internet Usage (% of Population) 2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032196828</td>\n",
       "      <td>0.048593919</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>8.26</td>\n",
       "      <td>11</td>\n",
       "      <td>13.5</td>\n",
       "      <td>16.8</td>\n",
       "      <td>17.6</td>\n",
       "      <td>18.4</td>\n",
       "      <td>79.3237</td>\n",
       "      <td>82.6137</td>\n",
       "      <td>83.1356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011168695</td>\n",
       "      <td>0.032196828</td>\n",
       "      <td>0.048593919</td>\n",
       "      <td>...</td>\n",
       "      <td>54.3</td>\n",
       "      <td>56.9</td>\n",
       "      <td>59.6</td>\n",
       "      <td>62.4</td>\n",
       "      <td>65.4</td>\n",
       "      <td>68.5504</td>\n",
       "      <td>72.2377</td>\n",
       "      <td>79.3237</td>\n",
       "      <td>82.6137</td>\n",
       "      <td>83.1356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000360674</td>\n",
       "      <td>0.001768954</td>\n",
       "      <td>0.001738533</td>\n",
       "      <td>0.010268463</td>\n",
       "      <td>...</td>\n",
       "      <td>29.5</td>\n",
       "      <td>38.2</td>\n",
       "      <td>42.9455</td>\n",
       "      <td>47.6911</td>\n",
       "      <td>49.0385</td>\n",
       "      <td>58.9776</td>\n",
       "      <td>60.6534</td>\n",
       "      <td>66.2356</td>\n",
       "      <td>71.2432</td>\n",
       "      <td>83.1356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>ASM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001738533</td>\n",
       "      <td>0.010268463</td>\n",
       "      <td>...</td>\n",
       "      <td>29.5</td>\n",
       "      <td>38.2</td>\n",
       "      <td>42.9455</td>\n",
       "      <td>47.6911</td>\n",
       "      <td>49.0385</td>\n",
       "      <td>58.9776</td>\n",
       "      <td>60.6534</td>\n",
       "      <td>66.2356</td>\n",
       "      <td>71.2432</td>\n",
       "      <td>83.1356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>AND</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.526601023</td>\n",
       "      <td>3.050175385</td>\n",
       "      <td>...</td>\n",
       "      <td>86.1</td>\n",
       "      <td>87.9</td>\n",
       "      <td>89.7</td>\n",
       "      <td>91.5675</td>\n",
       "      <td>49.0385</td>\n",
       "      <td>90.7187</td>\n",
       "      <td>93.2056</td>\n",
       "      <td>93.8975</td>\n",
       "      <td>94.4855</td>\n",
       "      <td>83.1356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Country code Internet Usage (% of Population) 1990  \\\n",
       "0     Afghanistan  AFG                                     0   \n",
       "1         Albania  ALB                                     0   \n",
       "2         Algeria  DZA                                     0   \n",
       "3  American Samoa  ASM                                     0   \n",
       "4         Andorra  AND                                     0   \n",
       "\n",
       "  Internet Usage (% of Population) 1991 Internet Usage (% of Population) 1992  \\\n",
       "0                                     0                                     0   \n",
       "1                                     0                                     0   \n",
       "2                                     0                                     0   \n",
       "3                                     0                                     0   \n",
       "4                                     0                                     0   \n",
       "\n",
       "  Internet Usage (% of Population) 1993 Internet Usage (% of Population) 1994  \\\n",
       "0                                     0                                     0   \n",
       "1                                     0                                     0   \n",
       "2                                     0                           0.000360674   \n",
       "3                                     0                                     0   \n",
       "4                                     0                                     0   \n",
       "\n",
       "  Internet Usage (% of Population) 1995 Internet Usage (% of Population) 1996  \\\n",
       "0                                     0                           0.032196828   \n",
       "1                           0.011168695                           0.032196828   \n",
       "2                           0.001768954                           0.001738533   \n",
       "3                                     0                           0.001738533   \n",
       "4                                     0                           1.526601023   \n",
       "\n",
       "  Internet Usage (% of Population) 1997  ...  \\\n",
       "0                           0.048593919  ...   \n",
       "1                           0.048593919  ...   \n",
       "2                           0.010268463  ...   \n",
       "3                           0.010268463  ...   \n",
       "4                           3.050175385  ...   \n",
       "\n",
       "  Internet Usage (% of Population) 2014 Internet Usage (% of Population) 2015  \\\n",
       "0                                     7                                  8.26   \n",
       "1                                  54.3                                  56.9   \n",
       "2                                  29.5                                  38.2   \n",
       "3                                  29.5                                  38.2   \n",
       "4                                  86.1                                  87.9   \n",
       "\n",
       "  Internet Usage (% of Population) 2016 Internet Usage (% of Population) 2017  \\\n",
       "0                                    11                                  13.5   \n",
       "1                                  59.6                                  62.4   \n",
       "2                               42.9455                               47.6911   \n",
       "3                               42.9455                               47.6911   \n",
       "4                                  89.7                               91.5675   \n",
       "\n",
       "  Internet Usage (% of Population) 2018 Internet Usage (% of Population) 2019  \\\n",
       "0                                  16.8                                  17.6   \n",
       "1                                  65.4                               68.5504   \n",
       "2                               49.0385                               58.9776   \n",
       "3                               49.0385                               58.9776   \n",
       "4                               49.0385                               90.7187   \n",
       "\n",
       "  Internet Usage (% of Population) 2020 Internet Usage (% of Population) 2021  \\\n",
       "0                                  18.4                               79.3237   \n",
       "1                               72.2377                               79.3237   \n",
       "2                               60.6534                               66.2356   \n",
       "3                               60.6534                               66.2356   \n",
       "4                               93.2056                               93.8975   \n",
       "\n",
       "  Internet Usage (% of Population) 2022 Internet Usage (% of Population) 2023  \n",
       "0                               82.6137                               83.1356  \n",
       "1                               82.6137                               83.1356  \n",
       "2                               71.2432                               83.1356  \n",
       "3                               71.2432                               83.1356  \n",
       "4                               94.4855                               83.1356  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/internet.csv')\n",
    "df.head()\n",
    "df.replace(\"..\", pd.NA, inplace=True)\n",
    "# Forward fill first, then backward fill to handle any remaining NAs at the start\n",
    "df.rename(columns={'entity': 'Country'}, inplace=True)\n",
    "df = df.ffill().bfill()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df.columns if 'Internet' in col]\n",
    "    \n",
    "sequence_length = 5\n",
    "predictions_by_country = {}\n",
    "selected_countries = ['United States', 'China', 'Japan', 'Germany', 'United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for Afghanistan\n",
      "Epoch [50/200], Loss: 0.0116\n",
      "Epoch [100/200], Loss: 0.0108\n",
      "Epoch [150/200], Loss: 0.0117\n",
      "Epoch [200/200], Loss: 0.0074\n",
      "\n",
      "Training model for Albania\n",
      "Epoch [50/200], Loss: 0.0112\n",
      "Epoch [100/200], Loss: 0.0089\n",
      "Epoch [150/200], Loss: 0.0053\n",
      "Epoch [200/200], Loss: 0.0028\n",
      "\n",
      "Training model for Algeria\n",
      "Epoch [50/200], Loss: 0.0035\n",
      "Epoch [100/200], Loss: 0.0012\n",
      "Epoch [150/200], Loss: 0.0012\n",
      "Epoch [200/200], Loss: 0.0012\n",
      "\n",
      "Training model for American Samoa\n",
      "Epoch [50/200], Loss: 0.0019\n",
      "Epoch [100/200], Loss: 0.0012\n",
      "Epoch [150/200], Loss: 0.0013\n",
      "Epoch [200/200], Loss: 0.0014\n",
      "\n",
      "Training model for Andorra\n",
      "Epoch [50/200], Loss: 0.0250\n",
      "Epoch [100/200], Loss: 0.0103\n",
      "Epoch [150/200], Loss: 0.0118\n",
      "Epoch [200/200], Loss: 0.0087\n",
      "\n",
      "Training model for Angola\n",
      "Epoch [50/200], Loss: 0.0086\n",
      "Epoch [100/200], Loss: 0.0066\n",
      "Epoch [150/200], Loss: 0.0066\n",
      "Epoch [200/200], Loss: 0.0077\n",
      "\n",
      "Training model for Antigua and Barbuda\n",
      "Epoch [50/200], Loss: 0.0021\n",
      "Epoch [100/200], Loss: 0.0009\n",
      "Epoch [150/200], Loss: 0.0009\n",
      "Epoch [200/200], Loss: 0.0008\n",
      "\n",
      "Training model for Argentina\n",
      "Epoch [50/200], Loss: 0.0033\n",
      "Epoch [100/200], Loss: 0.0010\n",
      "Epoch [150/200], Loss: 0.0011\n",
      "Epoch [200/200], Loss: 0.0009\n",
      "\n",
      "Training model for Armenia\n",
      "Epoch [50/200], Loss: 0.0048\n",
      "Epoch [100/200], Loss: 0.0023\n",
      "Epoch [150/200], Loss: 0.0020\n",
      "Epoch [200/200], Loss: 0.0023\n",
      "\n",
      "Training model for Aruba\n",
      "Epoch [50/200], Loss: 0.0146\n",
      "Epoch [100/200], Loss: 0.0079\n",
      "Epoch [150/200], Loss: 0.0066\n",
      "Epoch [200/200], Loss: 0.0060\n",
      "\n",
      "Training model for Australia\n",
      "Epoch [50/200], Loss: 0.0214\n",
      "Epoch [100/200], Loss: 0.0209\n",
      "Epoch [150/200], Loss: 0.0199\n",
      "Epoch [200/200], Loss: 0.0166\n",
      "\n",
      "Training model for Austria\n",
      "Epoch [50/200], Loss: 0.0056\n",
      "Epoch [100/200], Loss: 0.0031\n",
      "Epoch [150/200], Loss: 0.0018\n",
      "Epoch [200/200], Loss: 0.0024\n",
      "\n",
      "Training model for Azerbaijan\n",
      "Epoch [50/200], Loss: 0.0304\n",
      "Epoch [100/200], Loss: 0.0248\n",
      "Epoch [150/200], Loss: 0.0245\n",
      "Epoch [200/200], Loss: 0.0191\n",
      "\n",
      "Training model for Bahamas, The\n",
      "Epoch [50/200], Loss: 0.0080\n",
      "Epoch [100/200], Loss: 0.0041\n",
      "Epoch [150/200], Loss: 0.0044\n",
      "Epoch [200/200], Loss: 0.0042\n",
      "\n",
      "Training model for Bahrain\n",
      "Epoch [50/200], Loss: 0.0071\n",
      "Epoch [100/200], Loss: 0.0028\n",
      "Epoch [150/200], Loss: 0.0023\n",
      "Epoch [200/200], Loss: 0.0020\n",
      "\n",
      "Training model for Bangladesh\n",
      "Epoch [50/200], Loss: 0.0026\n",
      "Epoch [100/200], Loss: 0.0005\n",
      "Epoch [150/200], Loss: 0.0004\n",
      "Epoch [200/200], Loss: 0.0004\n",
      "\n",
      "Training model for Barbados\n",
      "Epoch [50/200], Loss: 0.0227\n",
      "Epoch [100/200], Loss: 0.0109\n",
      "Epoch [150/200], Loss: 0.0086\n",
      "Epoch [200/200], Loss: 0.0089\n",
      "\n",
      "Training model for Belarus\n",
      "Epoch [50/200], Loss: 0.0233\n",
      "Epoch [100/200], Loss: 0.0211\n",
      "Epoch [150/200], Loss: 0.0156\n",
      "Epoch [200/200], Loss: 0.0102\n",
      "\n",
      "Training model for Belgium\n",
      "Epoch [50/200], Loss: 0.0077\n",
      "Epoch [100/200], Loss: 0.0037\n",
      "Epoch [150/200], Loss: 0.0033\n",
      "Epoch [200/200], Loss: 0.0026\n",
      "\n",
      "Training model for Belize\n",
      "Epoch [50/200], Loss: 0.0098\n",
      "Epoch [100/200], Loss: 0.0094\n",
      "Epoch [150/200], Loss: 0.0086\n",
      "Epoch [200/200], Loss: 0.0087\n",
      "\n",
      "Training model for Benin\n",
      "Epoch [50/200], Loss: 0.0074\n",
      "Epoch [100/200], Loss: 0.0088\n",
      "Epoch [150/200], Loss: 0.0084\n",
      "Epoch [200/200], Loss: 0.0061\n",
      "\n",
      "Training model for Bermuda\n",
      "Epoch [50/200], Loss: 0.0614\n",
      "Epoch [100/200], Loss: 0.0421\n",
      "Epoch [150/200], Loss: 0.0326\n",
      "Epoch [200/200], Loss: 0.0238\n",
      "\n",
      "Training model for Bhutan\n",
      "Epoch [50/200], Loss: 0.0149\n",
      "Epoch [100/200], Loss: 0.0131\n",
      "Epoch [150/200], Loss: 0.0088\n",
      "Epoch [200/200], Loss: 0.0091\n",
      "\n",
      "Training model for Bolivia\n",
      "Epoch [50/200], Loss: 0.0042\n",
      "Epoch [100/200], Loss: 0.0038\n",
      "Epoch [150/200], Loss: 0.0031\n",
      "Epoch [200/200], Loss: 0.0030\n",
      "\n",
      "Training model for Bosnia and Herzegovina\n",
      "Epoch [50/200], Loss: 0.0065\n",
      "Epoch [100/200], Loss: 0.0043\n",
      "Epoch [150/200], Loss: 0.0036\n",
      "Epoch [200/200], Loss: 0.0027\n",
      "\n",
      "Training model for Botswana\n",
      "Epoch [50/200], Loss: 0.0047\n",
      "Epoch [100/200], Loss: 0.0038\n",
      "Epoch [150/200], Loss: 0.0031\n",
      "Epoch [200/200], Loss: 0.0041\n",
      "\n",
      "Training model for Brazil\n",
      "Epoch [50/200], Loss: 0.0029\n",
      "Epoch [100/200], Loss: 0.0021\n",
      "Epoch [150/200], Loss: 0.0017\n",
      "Epoch [200/200], Loss: 0.0015\n",
      "\n",
      "Training model for British Virgin Islands\n",
      "Epoch [50/200], Loss: 0.0068\n",
      "Epoch [100/200], Loss: 0.0051\n",
      "Epoch [150/200], Loss: 0.0048\n",
      "Epoch [200/200], Loss: 0.0052\n",
      "\n",
      "Training model for Brunei Darussalam\n",
      "Epoch [50/200], Loss: 0.0068\n",
      "Epoch [100/200], Loss: 0.0045\n",
      "Epoch [150/200], Loss: 0.0045\n",
      "Epoch [200/200], Loss: 0.0037\n",
      "\n",
      "Training model for Bulgaria\n",
      "Epoch [50/200], Loss: 0.0047\n",
      "Epoch [100/200], Loss: 0.0019\n",
      "Epoch [150/200], Loss: 0.0014\n",
      "Epoch [200/200], Loss: 0.0009\n",
      "\n",
      "Training model for Burkina Faso\n",
      "Epoch [50/200], Loss: 0.0140\n",
      "Epoch [100/200], Loss: 0.0110\n",
      "Epoch [150/200], Loss: 0.0068\n",
      "Epoch [200/200], Loss: 0.0023\n",
      "\n",
      "Training model for Burundi\n",
      "Epoch [50/200], Loss: 0.0196\n",
      "Epoch [100/200], Loss: 0.0096\n",
      "Epoch [150/200], Loss: 0.0055\n",
      "Epoch [200/200], Loss: 0.0040\n",
      "\n",
      "Training model for Cabo Verde\n",
      "Epoch [50/200], Loss: 0.0047\n",
      "Epoch [100/200], Loss: 0.0029\n",
      "Epoch [150/200], Loss: 0.0023\n",
      "Epoch [200/200], Loss: 0.0020\n",
      "\n",
      "Training model for Cambodia\n",
      "Epoch [50/200], Loss: 0.0065\n",
      "Epoch [100/200], Loss: 0.0041\n",
      "Epoch [150/200], Loss: 0.0041\n",
      "Epoch [200/200], Loss: 0.0038\n",
      "\n",
      "Training model for Cameroon\n",
      "Epoch [50/200], Loss: 0.0036\n",
      "Epoch [100/200], Loss: 0.0031\n",
      "Epoch [150/200], Loss: 0.0035\n",
      "Epoch [200/200], Loss: 0.0034\n",
      "\n",
      "Training model for Canada\n",
      "Epoch [50/200], Loss: 0.0088\n",
      "Epoch [100/200], Loss: 0.0061\n",
      "Epoch [150/200], Loss: 0.0046\n",
      "Epoch [200/200], Loss: 0.0032\n",
      "\n",
      "Training model for Cayman Islands\n",
      "Epoch [50/200], Loss: 0.0165\n",
      "Epoch [100/200], Loss: 0.0136\n",
      "Epoch [150/200], Loss: 0.0113\n",
      "Epoch [200/200], Loss: 0.0095\n",
      "\n",
      "Training model for Central African Republic\n",
      "Epoch [50/200], Loss: 0.0219\n",
      "Epoch [100/200], Loss: 0.0163\n",
      "Epoch [150/200], Loss: 0.0173\n",
      "Epoch [200/200], Loss: 0.0147\n",
      "\n",
      "Training model for Chad\n",
      "Epoch [50/200], Loss: 0.0278\n",
      "Epoch [100/200], Loss: 0.0218\n",
      "Epoch [150/200], Loss: 0.0119\n",
      "Epoch [200/200], Loss: 0.0181\n",
      "\n",
      "Training model for Channel Islands\n",
      "Epoch [50/200], Loss: 0.0197\n",
      "Epoch [100/200], Loss: 0.0144\n",
      "Epoch [150/200], Loss: 0.0139\n",
      "Epoch [200/200], Loss: 0.0100\n",
      "\n",
      "Training model for Chile\n",
      "Epoch [50/200], Loss: 0.0056\n",
      "Epoch [100/200], Loss: 0.0031\n",
      "Epoch [150/200], Loss: 0.0031\n",
      "Epoch [200/200], Loss: 0.0028\n",
      "\n",
      "Training model for China\n",
      "Epoch [50/200], Loss: 0.0056\n",
      "Epoch [100/200], Loss: 0.0031\n",
      "Epoch [150/200], Loss: 0.0023\n",
      "Epoch [200/200], Loss: 0.0016\n",
      "\n",
      "Training model for Colombia\n",
      "Epoch [50/200], Loss: 0.0047\n",
      "Epoch [100/200], Loss: 0.0010\n",
      "Epoch [150/200], Loss: 0.0008\n",
      "Epoch [200/200], Loss: 0.0006\n",
      "\n",
      "Training model for Comoros\n",
      "Epoch [50/200], Loss: 0.0179\n",
      "Epoch [100/200], Loss: 0.0168\n",
      "Epoch [150/200], Loss: 0.0162\n",
      "Epoch [200/200], Loss: 0.0164\n",
      "\n",
      "Training model for Congo, Dem. Rep.\n",
      "Epoch [50/200], Loss: 0.0127\n",
      "Epoch [100/200], Loss: 0.0031\n",
      "Epoch [150/200], Loss: 0.0024\n",
      "Epoch [200/200], Loss: 0.0027\n",
      "\n",
      "Training model for Congo, Rep.\n",
      "Epoch [50/200], Loss: 0.0035\n",
      "Epoch [100/200], Loss: 0.0012\n",
      "Epoch [150/200], Loss: 0.0013\n",
      "Epoch [200/200], Loss: 0.0014\n",
      "\n",
      "Training model for Costa Rica\n",
      "Epoch [50/200], Loss: 0.0023\n",
      "Epoch [100/200], Loss: 0.0020\n",
      "Epoch [150/200], Loss: 0.0019\n",
      "Epoch [200/200], Loss: 0.0019\n",
      "\n",
      "Training model for Cote d'Ivoire\n",
      "Epoch [50/200], Loss: 0.0191\n",
      "Epoch [100/200], Loss: 0.0149\n",
      "Epoch [150/200], Loss: 0.0119\n",
      "Epoch [200/200], Loss: 0.0113\n",
      "\n",
      "Training model for Croatia\n",
      "Epoch [50/200], Loss: 0.0036\n",
      "Epoch [100/200], Loss: 0.0020\n",
      "Epoch [150/200], Loss: 0.0019\n",
      "Epoch [200/200], Loss: 0.0013\n",
      "\n",
      "Training model for Cuba\n",
      "Epoch [50/200], Loss: 0.0027\n",
      "Epoch [100/200], Loss: 0.0024\n",
      "Epoch [150/200], Loss: 0.0022\n",
      "Epoch [200/200], Loss: 0.0020\n",
      "\n",
      "Training model for Curacao\n",
      "Epoch [50/200], Loss: 0.0097\n",
      "Epoch [100/200], Loss: 0.0055\n",
      "Epoch [150/200], Loss: 0.0038\n",
      "Epoch [200/200], Loss: 0.0027\n",
      "\n",
      "Training model for Cyprus\n",
      "Epoch [50/200], Loss: 0.0035\n",
      "Epoch [100/200], Loss: 0.0015\n",
      "Epoch [150/200], Loss: 0.0015\n",
      "Epoch [200/200], Loss: 0.0019\n",
      "\n",
      "Training model for Czechia\n",
      "Epoch [50/200], Loss: 0.0071\n",
      "Epoch [100/200], Loss: 0.0017\n",
      "Epoch [150/200], Loss: 0.0021\n",
      "Epoch [200/200], Loss: 0.0013\n",
      "\n",
      "Training model for Denmark\n",
      "Epoch [50/200], Loss: 0.0121\n",
      "Epoch [100/200], Loss: 0.0070\n",
      "Epoch [150/200], Loss: 0.0016\n",
      "Epoch [200/200], Loss: 0.0019\n",
      "\n",
      "Training model for Djibouti\n",
      "Epoch [50/200], Loss: 0.0082\n",
      "Epoch [100/200], Loss: 0.0034\n",
      "Epoch [150/200], Loss: 0.0034\n",
      "Epoch [200/200], Loss: 0.0035\n",
      "\n",
      "Training model for Dominica\n",
      "Epoch [50/200], Loss: 0.0054\n",
      "Epoch [100/200], Loss: 0.0050\n",
      "Epoch [150/200], Loss: 0.0047\n",
      "Epoch [200/200], Loss: 0.0039\n",
      "\n",
      "Training model for Dominican Republic\n",
      "Epoch [50/200], Loss: 0.0017\n",
      "Epoch [100/200], Loss: 0.0008\n",
      "Epoch [150/200], Loss: 0.0007\n",
      "Epoch [200/200], Loss: 0.0008\n",
      "\n",
      "Training model for Ecuador\n",
      "Epoch [50/200], Loss: 0.0063\n",
      "Epoch [100/200], Loss: 0.0021\n",
      "Epoch [150/200], Loss: 0.0019\n",
      "Epoch [200/200], Loss: 0.0014\n",
      "\n",
      "Training model for Egypt, Arab Rep.\n",
      "Epoch [50/200], Loss: 0.0032\n",
      "Epoch [100/200], Loss: 0.0029\n",
      "Epoch [150/200], Loss: 0.0033\n",
      "Epoch [200/200], Loss: 0.0026\n",
      "\n",
      "Training model for El Salvador\n",
      "Epoch [50/200], Loss: 0.0028\n",
      "Epoch [100/200], Loss: 0.0013\n",
      "Epoch [150/200], Loss: 0.0014\n",
      "Epoch [200/200], Loss: 0.0013\n",
      "\n",
      "Training model for Equatorial Guinea\n",
      "Epoch [50/200], Loss: 0.0024\n",
      "Epoch [100/200], Loss: 0.0024\n",
      "Epoch [150/200], Loss: 0.0024\n",
      "Epoch [200/200], Loss: 0.0022\n",
      "\n",
      "Training model for Eritrea\n",
      "Epoch [50/200], Loss: 0.0035\n",
      "Epoch [100/200], Loss: 0.0032\n",
      "Epoch [150/200], Loss: 0.0035\n",
      "Epoch [200/200], Loss: 0.0034\n",
      "\n",
      "Training model for Estonia\n",
      "Epoch [50/200], Loss: 0.0067\n",
      "Epoch [100/200], Loss: 0.0026\n",
      "Epoch [150/200], Loss: 0.0017\n",
      "Epoch [200/200], Loss: 0.0015\n",
      "\n",
      "Training model for Eswatini\n",
      "Epoch [50/200], Loss: 0.0028\n",
      "Epoch [100/200], Loss: 0.0045\n",
      "Epoch [150/200], Loss: 0.0024\n",
      "Epoch [200/200], Loss: 0.0031\n",
      "\n",
      "Training model for Ethiopia\n",
      "Epoch [50/200], Loss: 0.0170\n",
      "Epoch [100/200], Loss: 0.0248\n",
      "Epoch [150/200], Loss: 0.0166\n",
      "Epoch [200/200], Loss: 0.0164\n",
      "\n",
      "Training model for Faroe Islands\n",
      "Epoch [50/200], Loss: 0.0658\n",
      "Epoch [100/200], Loss: 0.0365\n",
      "Epoch [150/200], Loss: 0.0322\n",
      "Epoch [200/200], Loss: 0.0311\n",
      "\n",
      "Training model for Fiji\n",
      "Epoch [50/200], Loss: 0.0042\n",
      "Epoch [100/200], Loss: 0.0015\n",
      "Epoch [150/200], Loss: 0.0014\n",
      "Epoch [200/200], Loss: 0.0013\n",
      "\n",
      "Training model for Finland\n",
      "Epoch [50/200], Loss: 0.0066\n",
      "Epoch [100/200], Loss: 0.0012\n",
      "Epoch [150/200], Loss: 0.0011\n",
      "Epoch [200/200], Loss: 0.0011\n",
      "\n",
      "Training model for France\n",
      "Epoch [50/200], Loss: 0.0063\n",
      "Epoch [100/200], Loss: 0.0024\n",
      "Epoch [150/200], Loss: 0.0022\n",
      "Epoch [200/200], Loss: 0.0023\n",
      "\n",
      "Training model for French Polynesia\n",
      "Epoch [50/200], Loss: 0.0029\n",
      "Epoch [100/200], Loss: 0.0015\n",
      "Epoch [150/200], Loss: 0.0014\n",
      "Epoch [200/200], Loss: 0.0013\n",
      "\n",
      "Training model for Gabon\n",
      "Epoch [50/200], Loss: 0.0045\n",
      "Epoch [100/200], Loss: 0.0009\n",
      "Epoch [150/200], Loss: 0.0011\n",
      "Epoch [200/200], Loss: 0.0008\n",
      "\n",
      "Training model for Gambia, The\n",
      "Epoch [50/200], Loss: 0.0016\n",
      "Epoch [100/200], Loss: 0.0010\n",
      "Epoch [150/200], Loss: 0.0011\n",
      "Epoch [200/200], Loss: 0.0009\n",
      "\n",
      "Training model for Georgia\n",
      "Epoch [50/200], Loss: 0.0061\n",
      "Epoch [100/200], Loss: 0.0015\n",
      "Epoch [150/200], Loss: 0.0012\n",
      "Epoch [200/200], Loss: 0.0009\n",
      "\n",
      "Training model for Germany\n",
      "Epoch [50/200], Loss: 0.0094\n",
      "Epoch [100/200], Loss: 0.0034\n",
      "Epoch [150/200], Loss: 0.0016\n",
      "Epoch [200/200], Loss: 0.0012\n",
      "\n",
      "Training model for Ghana\n",
      "Epoch [50/200], Loss: 0.0067\n",
      "Epoch [100/200], Loss: 0.0057\n",
      "Epoch [150/200], Loss: 0.0038\n",
      "Epoch [200/200], Loss: 0.0054\n",
      "\n",
      "Training model for Gibraltar\n",
      "Epoch [50/200], Loss: 0.0453\n",
      "Epoch [100/200], Loss: 0.0413\n",
      "Epoch [150/200], Loss: 0.0368\n",
      "Epoch [200/200], Loss: 0.0362\n",
      "\n",
      "Training model for Greece\n",
      "Epoch [50/200], Loss: 0.0034\n",
      "Epoch [100/200], Loss: 0.0009\n",
      "Epoch [150/200], Loss: 0.0008\n",
      "Epoch [200/200], Loss: 0.0007\n",
      "\n",
      "Training model for Greenland\n",
      "Epoch [50/200], Loss: 0.0099\n",
      "Epoch [100/200], Loss: 0.0058\n",
      "Epoch [150/200], Loss: 0.0043\n",
      "Epoch [200/200], Loss: 0.0034\n",
      "\n",
      "Training model for Grenada\n",
      "Epoch [50/200], Loss: 0.0034\n",
      "Epoch [100/200], Loss: 0.0029\n",
      "Epoch [150/200], Loss: 0.0031\n",
      "Epoch [200/200], Loss: 0.0030\n",
      "\n",
      "Training model for Guam\n",
      "Epoch [50/200], Loss: 0.0072\n",
      "Epoch [100/200], Loss: 0.0057\n",
      "Epoch [150/200], Loss: 0.0055\n",
      "Epoch [200/200], Loss: 0.0051\n",
      "\n",
      "Training model for Guatemala\n",
      "Epoch [50/200], Loss: 0.0040\n",
      "Epoch [100/200], Loss: 0.0037\n",
      "Epoch [150/200], Loss: 0.0030\n",
      "Epoch [200/200], Loss: 0.0032\n",
      "\n",
      "Training model for Guinea\n",
      "Epoch [50/200], Loss: 0.0086\n",
      "Epoch [100/200], Loss: 0.0052\n",
      "Epoch [150/200], Loss: 0.0053\n",
      "Epoch [200/200], Loss: 0.0054\n",
      "\n",
      "Training model for Guinea-Bissau\n",
      "Epoch [50/200], Loss: 0.0080\n",
      "Epoch [100/200], Loss: 0.0047\n",
      "Epoch [150/200], Loss: 0.0046\n",
      "Epoch [200/200], Loss: 0.0043\n",
      "\n",
      "Training model for Guyana\n",
      "Epoch [50/200], Loss: 0.0064\n",
      "Epoch [100/200], Loss: 0.0059\n",
      "Epoch [150/200], Loss: 0.0055\n",
      "Epoch [200/200], Loss: 0.0047\n",
      "\n",
      "Training model for Haiti\n",
      "Epoch [50/200], Loss: 0.0055\n",
      "Epoch [100/200], Loss: 0.0050\n",
      "Epoch [150/200], Loss: 0.0046\n",
      "Epoch [200/200], Loss: 0.0063\n",
      "\n",
      "Training model for Honduras\n",
      "Epoch [50/200], Loss: 0.0016\n",
      "Epoch [100/200], Loss: 0.0017\n",
      "Epoch [150/200], Loss: 0.0014\n",
      "Epoch [200/200], Loss: 0.0015\n",
      "\n",
      "Training model for Hong Kong SAR, China\n",
      "Epoch [50/200], Loss: 0.0058\n",
      "Epoch [100/200], Loss: 0.0045\n",
      "Epoch [150/200], Loss: 0.0028\n",
      "Epoch [200/200], Loss: 0.0029\n",
      "\n",
      "Training model for Hungary\n",
      "Epoch [50/200], Loss: 0.0069\n",
      "Epoch [100/200], Loss: 0.0017\n",
      "Epoch [150/200], Loss: 0.0015\n",
      "Epoch [200/200], Loss: 0.0013\n",
      "\n",
      "Training model for Iceland\n",
      "Epoch [50/200], Loss: 0.0079\n",
      "Epoch [100/200], Loss: 0.0027\n",
      "Epoch [150/200], Loss: 0.0018\n",
      "Epoch [200/200], Loss: 0.0020\n",
      "\n",
      "Training model for India\n",
      "Epoch [50/200], Loss: 0.0115\n",
      "Epoch [100/200], Loss: 0.0154\n",
      "Epoch [150/200], Loss: 0.0112\n",
      "Epoch [200/200], Loss: 0.0122\n",
      "\n",
      "Training model for Indonesia\n",
      "Epoch [50/200], Loss: 0.0018\n",
      "Epoch [100/200], Loss: 0.0008\n",
      "Epoch [150/200], Loss: 0.0006\n",
      "Epoch [200/200], Loss: 0.0005\n",
      "\n",
      "Training model for Iran, Islamic Rep.\n",
      "Epoch [50/200], Loss: 0.0076\n",
      "Epoch [100/200], Loss: 0.0018\n",
      "Epoch [150/200], Loss: 0.0014\n",
      "Epoch [200/200], Loss: 0.0011\n",
      "\n",
      "Training model for Iraq\n",
      "Epoch [50/200], Loss: 0.0095\n",
      "Epoch [100/200], Loss: 0.0032\n",
      "Epoch [150/200], Loss: 0.0029\n",
      "Epoch [200/200], Loss: 0.0041\n",
      "\n",
      "Training model for Ireland\n",
      "Epoch [50/200], Loss: 0.0077\n",
      "Epoch [100/200], Loss: 0.0029\n",
      "Epoch [150/200], Loss: 0.0026\n",
      "Epoch [200/200], Loss: 0.0026\n",
      "\n",
      "Training model for Isle of Man\n",
      "Epoch [50/200], Loss: 0.0083\n",
      "Epoch [100/200], Loss: 0.0038\n",
      "Epoch [150/200], Loss: 0.0031\n",
      "Epoch [200/200], Loss: 0.0028\n",
      "\n",
      "Training model for Israel\n",
      "Epoch [50/200], Loss: 0.0112\n",
      "Epoch [100/200], Loss: 0.0068\n",
      "Epoch [150/200], Loss: 0.0067\n",
      "Epoch [200/200], Loss: 0.0057\n",
      "\n",
      "Training model for Italy\n",
      "Epoch [50/200], Loss: 0.0047\n",
      "Epoch [100/200], Loss: 0.0041\n",
      "Epoch [150/200], Loss: 0.0040\n",
      "Epoch [200/200], Loss: 0.0034\n",
      "\n",
      "Training model for Jamaica\n",
      "Epoch [50/200], Loss: 0.0039\n",
      "Epoch [100/200], Loss: 0.0026\n",
      "Epoch [150/200], Loss: 0.0029\n",
      "Epoch [200/200], Loss: 0.0024\n",
      "\n",
      "Training model for Japan\n",
      "Epoch [50/200], Loss: 0.0090\n",
      "Epoch [100/200], Loss: 0.0037\n",
      "Epoch [150/200], Loss: 0.0020\n",
      "Epoch [200/200], Loss: 0.0018\n",
      "\n",
      "Training model for Jordan\n",
      "Epoch [50/200], Loss: 0.0015\n",
      "Epoch [100/200], Loss: 0.0006\n",
      "Epoch [150/200], Loss: 0.0006\n",
      "Epoch [200/200], Loss: 0.0007\n",
      "\n",
      "Training model for Kazakhstan\n",
      "Epoch [50/200], Loss: 0.0171\n",
      "Epoch [100/200], Loss: 0.0041\n",
      "Epoch [150/200], Loss: 0.0023\n",
      "Epoch [200/200], Loss: 0.0013\n",
      "\n",
      "Training model for Kenya\n",
      "Epoch [50/200], Loss: 0.0061\n",
      "Epoch [100/200], Loss: 0.0039\n",
      "Epoch [150/200], Loss: 0.0030\n",
      "Epoch [200/200], Loss: 0.0015\n",
      "\n",
      "Training model for Kiribati\n",
      "Epoch [50/200], Loss: 0.0024\n",
      "Epoch [100/200], Loss: 0.0028\n",
      "Epoch [150/200], Loss: 0.0030\n",
      "Epoch [200/200], Loss: 0.0028\n",
      "\n",
      "Training model for Korea, Dem. People's Rep.\n",
      "Epoch [50/200], Loss: 0.0065\n",
      "Epoch [100/200], Loss: 0.0044\n",
      "Epoch [150/200], Loss: 0.0041\n",
      "Epoch [200/200], Loss: 0.0037\n",
      "\n",
      "Training model for Korea, Rep.\n",
      "Epoch [50/200], Loss: 0.0137\n",
      "Epoch [100/200], Loss: 0.0123\n",
      "Epoch [150/200], Loss: 0.0072\n",
      "Epoch [200/200], Loss: 0.0053\n",
      "\n",
      "Training model for Kosovo\n",
      "Epoch [50/200], Loss: 0.0146\n",
      "Epoch [100/200], Loss: 0.0081\n",
      "Epoch [150/200], Loss: 0.0052\n",
      "Epoch [200/200], Loss: 0.0033\n",
      "\n",
      "Training model for Kuwait\n",
      "Epoch [50/200], Loss: 0.0047\n",
      "Epoch [100/200], Loss: 0.0014\n",
      "Epoch [150/200], Loss: 0.0014\n",
      "Epoch [200/200], Loss: 0.0013\n",
      "\n",
      "Training model for Kyrgyz Republic\n",
      "Epoch [50/200], Loss: 0.0023\n",
      "Epoch [100/200], Loss: 0.0023\n",
      "Epoch [150/200], Loss: 0.0024\n",
      "Epoch [200/200], Loss: 0.0022\n",
      "\n",
      "Training model for Lao PDR\n",
      "Epoch [50/200], Loss: 0.0016\n",
      "Epoch [100/200], Loss: 0.0014\n",
      "Epoch [150/200], Loss: 0.0013\n",
      "Epoch [200/200], Loss: 0.0012\n",
      "\n",
      "Training model for Latvia\n",
      "Epoch [50/200], Loss: 0.0107\n",
      "Epoch [100/200], Loss: 0.0056\n",
      "Epoch [150/200], Loss: 0.0022\n",
      "Epoch [200/200], Loss: 0.0014\n",
      "\n",
      "Training model for Lebanon\n",
      "Epoch [50/200], Loss: 0.0079\n",
      "Epoch [100/200], Loss: 0.0022\n",
      "Epoch [150/200], Loss: 0.0024\n",
      "Epoch [200/200], Loss: 0.0017\n",
      "\n",
      "Training model for Lesotho\n",
      "Epoch [50/200], Loss: 0.0084\n",
      "Epoch [100/200], Loss: 0.0097\n",
      "Epoch [150/200], Loss: 0.0077\n",
      "Epoch [200/200], Loss: 0.0073\n",
      "\n",
      "Training model for Liberia\n",
      "Epoch [50/200], Loss: 0.0082\n",
      "Epoch [100/200], Loss: 0.0091\n",
      "Epoch [150/200], Loss: 0.0093\n",
      "Epoch [200/200], Loss: 0.0062\n",
      "\n",
      "Training model for Libya\n",
      "Epoch [50/200], Loss: 0.0305\n",
      "Epoch [100/200], Loss: 0.0183\n",
      "Epoch [150/200], Loss: 0.0154\n",
      "Epoch [200/200], Loss: 0.0214\n",
      "\n",
      "Training model for Liechtenstein\n",
      "Epoch [50/200], Loss: 0.0389\n",
      "Epoch [100/200], Loss: 0.0384\n",
      "Epoch [150/200], Loss: 0.0325\n",
      "Epoch [200/200], Loss: 0.0319\n",
      "\n",
      "Training model for Lithuania\n",
      "Epoch [50/200], Loss: 0.0077\n",
      "Epoch [100/200], Loss: 0.0033\n",
      "Epoch [150/200], Loss: 0.0029\n",
      "Epoch [200/200], Loss: 0.0020\n",
      "\n",
      "Training model for Luxembourg\n",
      "Epoch [50/200], Loss: 0.0066\n",
      "Epoch [100/200], Loss: 0.0007\n",
      "Epoch [150/200], Loss: 0.0005\n",
      "Epoch [200/200], Loss: 0.0004\n",
      "\n",
      "Training model for Macao SAR, China\n",
      "Epoch [50/200], Loss: 0.0037\n",
      "Epoch [100/200], Loss: 0.0020\n",
      "Epoch [150/200], Loss: 0.0019\n",
      "Epoch [200/200], Loss: 0.0019\n",
      "\n",
      "Training model for Madagascar\n",
      "Epoch [50/200], Loss: 0.0253\n",
      "Epoch [100/200], Loss: 0.0088\n",
      "Epoch [150/200], Loss: 0.0052\n",
      "Epoch [200/200], Loss: 0.0065\n",
      "\n",
      "Training model for Malawi\n",
      "Epoch [50/200], Loss: 0.0139\n",
      "Epoch [100/200], Loss: 0.0136\n",
      "Epoch [150/200], Loss: 0.0138\n",
      "Epoch [200/200], Loss: 0.0094\n",
      "\n",
      "Training model for Malaysia\n",
      "Epoch [50/200], Loss: 0.0053\n",
      "Epoch [100/200], Loss: 0.0049\n",
      "Epoch [150/200], Loss: 0.0045\n",
      "Epoch [200/200], Loss: 0.0038\n",
      "\n",
      "Training model for Maldives\n",
      "Epoch [50/200], Loss: 0.0012\n",
      "Epoch [100/200], Loss: 0.0007\n",
      "Epoch [150/200], Loss: 0.0008\n",
      "Epoch [200/200], Loss: 0.0008\n",
      "\n",
      "Training model for Mali\n",
      "Epoch [50/200], Loss: 0.0095\n",
      "Epoch [100/200], Loss: 0.0074\n",
      "Epoch [150/200], Loss: 0.0070\n",
      "Epoch [200/200], Loss: 0.0064\n",
      "\n",
      "Training model for Malta\n",
      "Epoch [50/200], Loss: 0.0038\n",
      "Epoch [100/200], Loss: 0.0019\n",
      "Epoch [150/200], Loss: 0.0016\n",
      "Epoch [200/200], Loss: 0.0015\n",
      "\n",
      "Training model for Marshall Islands\n",
      "Epoch [50/200], Loss: 0.0184\n",
      "Epoch [100/200], Loss: 0.0079\n",
      "Epoch [150/200], Loss: 0.0066\n",
      "Epoch [200/200], Loss: 0.0043\n",
      "\n",
      "Training model for Mauritania\n",
      "Epoch [50/200], Loss: 0.0061\n",
      "Epoch [100/200], Loss: 0.0052\n",
      "Epoch [150/200], Loss: 0.0049\n",
      "Epoch [200/200], Loss: 0.0064\n",
      "\n",
      "Training model for Mauritius\n",
      "Epoch [50/200], Loss: 0.0024\n",
      "Epoch [100/200], Loss: 0.0012\n",
      "Epoch [150/200], Loss: 0.0011\n",
      "Epoch [200/200], Loss: 0.0010\n",
      "\n",
      "Training model for Mexico\n",
      "Epoch [50/200], Loss: 0.0030\n",
      "Epoch [100/200], Loss: 0.0021\n",
      "Epoch [150/200], Loss: 0.0018\n",
      "Epoch [200/200], Loss: 0.0017\n",
      "\n",
      "Training model for Micronesia, Fed. Sts.\n",
      "Epoch [50/200], Loss: 0.0066\n",
      "Epoch [100/200], Loss: 0.0072\n",
      "Epoch [150/200], Loss: 0.0069\n",
      "Epoch [200/200], Loss: 0.0061\n",
      "\n",
      "Training model for Moldova\n",
      "Epoch [50/200], Loss: 0.0121\n",
      "Epoch [100/200], Loss: 0.0104\n",
      "Epoch [150/200], Loss: 0.0101\n",
      "Epoch [200/200], Loss: 0.0089\n",
      "\n",
      "Training model for Monaco\n",
      "Epoch [50/200], Loss: 0.0224\n",
      "Epoch [100/200], Loss: 0.0189\n",
      "Epoch [150/200], Loss: 0.0190\n",
      "Epoch [200/200], Loss: 0.0225\n",
      "\n",
      "Training model for Mongolia\n",
      "Epoch [50/200], Loss: 0.0394\n",
      "Epoch [100/200], Loss: 0.0313\n",
      "Epoch [150/200], Loss: 0.0242\n",
      "Epoch [200/200], Loss: 0.0340\n",
      "\n",
      "Training model for Montenegro\n",
      "Epoch [50/200], Loss: 0.0140\n",
      "Epoch [100/200], Loss: 0.0132\n",
      "Epoch [150/200], Loss: 0.0119\n",
      "Epoch [200/200], Loss: 0.0124\n",
      "\n",
      "Training model for Morocco\n",
      "Epoch [50/200], Loss: 0.0103\n",
      "Epoch [100/200], Loss: 0.0058\n",
      "Epoch [150/200], Loss: 0.0048\n",
      "Epoch [200/200], Loss: 0.0048\n",
      "\n",
      "Training model for Mozambique\n",
      "Epoch [50/200], Loss: 0.0099\n",
      "Epoch [100/200], Loss: 0.0057\n",
      "Epoch [150/200], Loss: 0.0025\n",
      "Epoch [200/200], Loss: 0.0019\n",
      "\n",
      "Training model for Myanmar\n",
      "Epoch [50/200], Loss: 0.0193\n",
      "Epoch [100/200], Loss: 0.0127\n",
      "Epoch [150/200], Loss: 0.0121\n",
      "Epoch [200/200], Loss: 0.0090\n",
      "\n",
      "Training model for Namibia\n",
      "Epoch [50/200], Loss: 0.0023\n",
      "Epoch [100/200], Loss: 0.0012\n",
      "Epoch [150/200], Loss: 0.0012\n",
      "Epoch [200/200], Loss: 0.0012\n",
      "\n",
      "Training model for Nauru\n",
      "Epoch [50/200], Loss: 0.0297\n",
      "Epoch [100/200], Loss: 0.0234\n",
      "Epoch [150/200], Loss: 0.0229\n",
      "Epoch [200/200], Loss: 0.0200\n",
      "\n",
      "Training model for Nepal\n",
      "Epoch [50/200], Loss: 0.0025\n",
      "Epoch [100/200], Loss: 0.0021\n",
      "Epoch [150/200], Loss: 0.0026\n",
      "Epoch [200/200], Loss: 0.0022\n",
      "\n",
      "Training model for Netherlands\n",
      "Epoch [50/200], Loss: 0.0086\n",
      "Epoch [100/200], Loss: 0.0027\n",
      "Epoch [150/200], Loss: 0.0013\n",
      "Epoch [200/200], Loss: 0.0016\n",
      "\n",
      "Training model for New Caledonia\n",
      "Epoch [50/200], Loss: 0.0075\n",
      "Epoch [100/200], Loss: 0.0049\n",
      "Epoch [150/200], Loss: 0.0045\n",
      "Epoch [200/200], Loss: 0.0042\n",
      "\n",
      "Training model for New Zealand\n",
      "Epoch [50/200], Loss: 0.0052\n",
      "Epoch [100/200], Loss: 0.0048\n",
      "Epoch [150/200], Loss: 0.0044\n",
      "Epoch [200/200], Loss: 0.0038\n",
      "\n",
      "Training model for Nicaragua\n",
      "Epoch [50/200], Loss: 0.0019\n",
      "Epoch [100/200], Loss: 0.0022\n",
      "Epoch [150/200], Loss: 0.0019\n",
      "Epoch [200/200], Loss: 0.0020\n",
      "\n",
      "Training model for Niger\n",
      "Epoch [50/200], Loss: 0.0145\n",
      "Epoch [100/200], Loss: 0.0109\n",
      "Epoch [150/200], Loss: 0.0096\n",
      "Epoch [200/200], Loss: 0.0058\n",
      "\n",
      "Training model for Nigeria\n",
      "Epoch [50/200], Loss: 0.0157\n",
      "Epoch [100/200], Loss: 0.0089\n",
      "Epoch [150/200], Loss: 0.0095\n",
      "Epoch [200/200], Loss: 0.0079\n",
      "\n",
      "Training model for North Macedonia\n",
      "Epoch [50/200], Loss: 0.0044\n",
      "Epoch [100/200], Loss: 0.0027\n",
      "Epoch [150/200], Loss: 0.0027\n",
      "Epoch [200/200], Loss: 0.0021\n",
      "\n",
      "Training model for Northern Mariana Islands\n",
      "Epoch [50/200], Loss: 0.0054\n",
      "Epoch [100/200], Loss: 0.0031\n",
      "Epoch [150/200], Loss: 0.0025\n",
      "Epoch [200/200], Loss: 0.0024\n",
      "\n",
      "Training model for Norway\n",
      "Epoch [50/200], Loss: 0.0087\n",
      "Epoch [100/200], Loss: 0.0043\n",
      "Epoch [150/200], Loss: 0.0015\n",
      "Epoch [200/200], Loss: 0.0011\n",
      "\n",
      "Training model for Oman\n",
      "Epoch [50/200], Loss: 0.0053\n",
      "Epoch [100/200], Loss: 0.0020\n",
      "Epoch [150/200], Loss: 0.0020\n",
      "Epoch [200/200], Loss: 0.0018\n",
      "\n",
      "Training model for Pakistan\n",
      "Epoch [50/200], Loss: 0.0127\n",
      "Epoch [100/200], Loss: 0.0076\n",
      "Epoch [150/200], Loss: 0.0036\n",
      "Epoch [200/200], Loss: 0.0020\n",
      "\n",
      "Training model for Palau\n",
      "Epoch [50/200], Loss: 0.0333\n",
      "Epoch [100/200], Loss: 0.0271\n",
      "Epoch [150/200], Loss: 0.0135\n",
      "Epoch [200/200], Loss: 0.0120\n",
      "\n",
      "Training model for Panama\n",
      "Epoch [50/200], Loss: 0.0044\n",
      "Epoch [100/200], Loss: 0.0038\n",
      "Epoch [150/200], Loss: 0.0040\n",
      "Epoch [200/200], Loss: 0.0040\n",
      "\n",
      "Training model for Papua New Guinea\n",
      "Epoch [50/200], Loss: 0.0205\n",
      "Epoch [100/200], Loss: 0.0147\n",
      "Epoch [150/200], Loss: 0.0141\n",
      "Epoch [200/200], Loss: 0.0131\n",
      "\n",
      "Training model for Paraguay\n",
      "Epoch [50/200], Loss: 0.0030\n",
      "Epoch [100/200], Loss: 0.0006\n",
      "Epoch [150/200], Loss: 0.0004\n",
      "Epoch [200/200], Loss: 0.0005\n",
      "\n",
      "Training model for Peru\n",
      "Epoch [50/200], Loss: 0.0028\n",
      "Epoch [100/200], Loss: 0.0028\n",
      "Epoch [150/200], Loss: 0.0021\n",
      "Epoch [200/200], Loss: 0.0020\n",
      "\n",
      "Training model for Philippines\n",
      "Epoch [50/200], Loss: 0.0073\n",
      "Epoch [100/200], Loss: 0.0069\n",
      "Epoch [150/200], Loss: 0.0069\n",
      "Epoch [200/200], Loss: 0.0044\n",
      "\n",
      "Training model for Poland\n",
      "Epoch [50/200], Loss: 0.0058\n",
      "Epoch [100/200], Loss: 0.0030\n",
      "Epoch [150/200], Loss: 0.0032\n",
      "Epoch [200/200], Loss: 0.0019\n",
      "\n",
      "Training model for Portugal\n",
      "Epoch [50/200], Loss: 0.0025\n",
      "Epoch [100/200], Loss: 0.0011\n",
      "Epoch [150/200], Loss: 0.0009\n",
      "Epoch [200/200], Loss: 0.0009\n",
      "\n",
      "Training model for Puerto Rico\n",
      "Epoch [50/200], Loss: 0.0058\n",
      "Epoch [100/200], Loss: 0.0042\n",
      "Epoch [150/200], Loss: 0.0042\n",
      "Epoch [200/200], Loss: 0.0044\n",
      "\n",
      "Training model for Qatar\n",
      "Epoch [50/200], Loss: 0.0053\n",
      "Epoch [100/200], Loss: 0.0019\n",
      "Epoch [150/200], Loss: 0.0016\n",
      "Epoch [200/200], Loss: 0.0015\n",
      "\n",
      "Training model for Romania\n",
      "Epoch [50/200], Loss: 0.0033\n",
      "Epoch [100/200], Loss: 0.0020\n",
      "Epoch [150/200], Loss: 0.0016\n",
      "Epoch [200/200], Loss: 0.0014\n",
      "\n",
      "Training model for Russian Federation\n",
      "Epoch [50/200], Loss: 0.0089\n",
      "Epoch [100/200], Loss: 0.0012\n",
      "Epoch [150/200], Loss: 0.0011\n",
      "Epoch [200/200], Loss: 0.0011\n",
      "\n",
      "Training model for Rwanda\n",
      "Epoch [50/200], Loss: 0.0102\n",
      "Epoch [100/200], Loss: 0.0060\n",
      "Epoch [150/200], Loss: 0.0047\n",
      "Epoch [200/200], Loss: 0.0045\n",
      "\n",
      "Training model for Samoa\n",
      "Epoch [50/200], Loss: 0.0007\n",
      "Epoch [100/200], Loss: 0.0006\n",
      "Epoch [150/200], Loss: 0.0005\n",
      "Epoch [200/200], Loss: 0.0006\n",
      "\n",
      "Training model for San Marino\n",
      "Epoch [50/200], Loss: 0.0451\n",
      "Epoch [100/200], Loss: 0.0287\n",
      "Epoch [150/200], Loss: 0.0265\n",
      "Epoch [200/200], Loss: 0.0239\n",
      "\n",
      "Training model for Sao Tome and Principe\n",
      "Epoch [50/200], Loss: 0.0020\n",
      "Epoch [100/200], Loss: 0.0016\n",
      "Epoch [150/200], Loss: 0.0019\n",
      "Epoch [200/200], Loss: 0.0018\n",
      "\n",
      "Training model for Saudi Arabia\n",
      "Epoch [50/200], Loss: 0.0044\n",
      "Epoch [100/200], Loss: 0.0023\n",
      "Epoch [150/200], Loss: 0.0022\n",
      "Epoch [200/200], Loss: 0.0020\n",
      "\n",
      "Training model for Senegal\n",
      "Epoch [50/200], Loss: 0.0019\n",
      "Epoch [100/200], Loss: 0.0021\n",
      "Epoch [150/200], Loss: 0.0017\n",
      "Epoch [200/200], Loss: 0.0017\n",
      "\n",
      "Training model for Serbia\n",
      "Epoch [50/200], Loss: 0.0061\n",
      "Epoch [100/200], Loss: 0.0056\n",
      "Epoch [150/200], Loss: 0.0053\n",
      "Epoch [200/200], Loss: 0.0038\n",
      "\n",
      "Training model for Seychelles\n",
      "Epoch [50/200], Loss: 0.0048\n",
      "Epoch [100/200], Loss: 0.0037\n",
      "Epoch [150/200], Loss: 0.0036\n",
      "Epoch [200/200], Loss: 0.0036\n",
      "\n",
      "Training model for Sierra Leone\n",
      "Epoch [50/200], Loss: 0.0051\n",
      "Epoch [100/200], Loss: 0.0059\n",
      "Epoch [150/200], Loss: 0.0045\n",
      "Epoch [200/200], Loss: 0.0039\n",
      "\n",
      "Training model for Singapore\n",
      "Epoch [50/200], Loss: 0.0045\n",
      "Epoch [100/200], Loss: 0.0031\n",
      "Epoch [150/200], Loss: 0.0027\n",
      "Epoch [200/200], Loss: 0.0022\n",
      "\n",
      "Training model for Sint Maarten (Dutch part)\n",
      "Epoch [50/200], Loss: 0.0058\n",
      "Epoch [100/200], Loss: 0.0035\n",
      "Epoch [150/200], Loss: 0.0036\n",
      "Epoch [200/200], Loss: 0.0025\n",
      "\n",
      "Training model for Slovak Republic\n",
      "Epoch [50/200], Loss: 0.0121\n",
      "Epoch [100/200], Loss: 0.0086\n",
      "Epoch [150/200], Loss: 0.0060\n",
      "Epoch [200/200], Loss: 0.0053\n",
      "\n",
      "Training model for Slovenia\n",
      "Epoch [50/200], Loss: 0.0046\n",
      "Epoch [100/200], Loss: 0.0018\n",
      "Epoch [150/200], Loss: 0.0016\n",
      "Epoch [200/200], Loss: 0.0014\n",
      "\n",
      "Training model for Solomon Islands\n",
      "Epoch [50/200], Loss: 0.0022\n",
      "Epoch [100/200], Loss: 0.0022\n",
      "Epoch [150/200], Loss: 0.0024\n",
      "Epoch [200/200], Loss: 0.0028\n",
      "\n",
      "Training model for Somalia\n",
      "Epoch [50/200], Loss: 0.0161\n",
      "Epoch [100/200], Loss: 0.0068\n",
      "Epoch [150/200], Loss: 0.0055\n",
      "Epoch [200/200], Loss: 0.0042\n",
      "\n",
      "Training model for South Africa\n",
      "Epoch [50/200], Loss: 0.0084\n",
      "Epoch [100/200], Loss: 0.0050\n",
      "Epoch [150/200], Loss: 0.0042\n",
      "Epoch [200/200], Loss: 0.0035\n",
      "\n",
      "Training model for South Sudan\n",
      "Epoch [50/200], Loss: 0.0340\n",
      "Epoch [100/200], Loss: 0.0333\n",
      "Epoch [150/200], Loss: 0.0300\n",
      "Epoch [200/200], Loss: 0.0243\n",
      "\n",
      "Training model for Spain\n",
      "Epoch [50/200], Loss: 0.0076\n",
      "Epoch [100/200], Loss: 0.0036\n",
      "Epoch [150/200], Loss: 0.0028\n",
      "Epoch [200/200], Loss: 0.0016\n",
      "\n",
      "Training model for Sri Lanka\n",
      "Epoch [50/200], Loss: 0.0548\n",
      "Epoch [100/200], Loss: 0.0261\n",
      "Epoch [150/200], Loss: 0.0280\n",
      "Epoch [200/200], Loss: 0.0237\n",
      "\n",
      "Training model for St. Kitts and Nevis\n",
      "Epoch [50/200], Loss: 0.0075\n",
      "Epoch [100/200], Loss: 0.0046\n",
      "Epoch [150/200], Loss: 0.0030\n",
      "Epoch [200/200], Loss: 0.0039\n",
      "\n",
      "Training model for St. Lucia\n",
      "Epoch [50/200], Loss: 0.0029\n",
      "Epoch [100/200], Loss: 0.0028\n",
      "Epoch [150/200], Loss: 0.0025\n",
      "Epoch [200/200], Loss: 0.0025\n",
      "\n",
      "Training model for St. Martin (French part)\n",
      "Epoch [50/200], Loss: 0.0037\n",
      "Epoch [100/200], Loss: 0.0029\n",
      "Epoch [150/200], Loss: 0.0025\n",
      "Epoch [200/200], Loss: 0.0026\n",
      "\n",
      "Training model for St. Vincent and the Grenadines\n",
      "Epoch [50/200], Loss: 0.0039\n",
      "Epoch [100/200], Loss: 0.0028\n",
      "Epoch [150/200], Loss: 0.0027\n",
      "Epoch [200/200], Loss: 0.0027\n",
      "\n",
      "Training model for Sudan\n",
      "Epoch [50/200], Loss: 0.0264\n",
      "Epoch [100/200], Loss: 0.0182\n",
      "Epoch [150/200], Loss: 0.0178\n",
      "Epoch [200/200], Loss: 0.0165\n",
      "\n",
      "Training model for Suriname\n",
      "Epoch [50/200], Loss: 0.0030\n",
      "Epoch [100/200], Loss: 0.0026\n",
      "Epoch [150/200], Loss: 0.0024\n",
      "Epoch [200/200], Loss: 0.0022\n",
      "\n",
      "Training model for Sweden\n",
      "Epoch [50/200], Loss: 0.0103\n",
      "Epoch [100/200], Loss: 0.0081\n",
      "Epoch [150/200], Loss: 0.0036\n",
      "Epoch [200/200], Loss: 0.0020\n",
      "\n",
      "Training model for Switzerland\n",
      "Epoch [50/200], Loss: 0.0080\n",
      "Epoch [100/200], Loss: 0.0042\n",
      "Epoch [150/200], Loss: 0.0029\n",
      "Epoch [200/200], Loss: 0.0023\n",
      "\n",
      "Training model for Syrian Arab Republic\n",
      "Epoch [50/200], Loss: 0.0115\n",
      "Epoch [100/200], Loss: 0.0117\n",
      "Epoch [150/200], Loss: 0.0121\n",
      "Epoch [200/200], Loss: 0.0125\n",
      "\n",
      "Training model for Tajikistan\n",
      "Epoch [50/200], Loss: 0.0110\n",
      "Epoch [100/200], Loss: 0.0072\n",
      "Epoch [150/200], Loss: 0.0065\n",
      "Epoch [200/200], Loss: 0.0059\n",
      "\n",
      "Training model for Tanzania\n",
      "Epoch [50/200], Loss: 0.0128\n",
      "Epoch [100/200], Loss: 0.0053\n",
      "Epoch [150/200], Loss: 0.0050\n",
      "Epoch [200/200], Loss: 0.0058\n",
      "\n",
      "Training model for Thailand\n",
      "Epoch [50/200], Loss: 0.0025\n",
      "Epoch [100/200], Loss: 0.0014\n",
      "Epoch [150/200], Loss: 0.0012\n",
      "Epoch [200/200], Loss: 0.0011\n",
      "\n",
      "Training model for Timor-Leste\n",
      "Epoch [50/200], Loss: 0.0069\n",
      "Epoch [100/200], Loss: 0.0094\n",
      "Epoch [150/200], Loss: 0.0064\n",
      "Epoch [200/200], Loss: 0.0063\n",
      "\n",
      "Training model for Togo\n",
      "Epoch [50/200], Loss: 0.0028\n",
      "Epoch [100/200], Loss: 0.0024\n",
      "Epoch [150/200], Loss: 0.0017\n",
      "Epoch [200/200], Loss: 0.0022\n",
      "\n",
      "Training model for Tonga\n",
      "Epoch [50/200], Loss: 0.0098\n",
      "Epoch [100/200], Loss: 0.0094\n",
      "Epoch [150/200], Loss: 0.0089\n",
      "Epoch [200/200], Loss: 0.0067\n",
      "\n",
      "Training model for Trinidad and Tobago\n",
      "Epoch [50/200], Loss: 0.0030\n",
      "Epoch [100/200], Loss: 0.0027\n",
      "Epoch [150/200], Loss: 0.0022\n",
      "Epoch [200/200], Loss: 0.0023\n",
      "\n",
      "Training model for Tunisia\n",
      "Epoch [50/200], Loss: 0.0041\n",
      "Epoch [100/200], Loss: 0.0035\n",
      "Epoch [150/200], Loss: 0.0031\n",
      "Epoch [200/200], Loss: 0.0025\n",
      "\n",
      "Training model for Turkiye\n",
      "Epoch [50/200], Loss: 0.0031\n",
      "Epoch [100/200], Loss: 0.0024\n",
      "Epoch [150/200], Loss: 0.0017\n",
      "Epoch [200/200], Loss: 0.0017\n",
      "\n",
      "Training model for Turkmenistan\n",
      "Epoch [50/200], Loss: 0.0185\n",
      "Epoch [100/200], Loss: 0.0064\n",
      "Epoch [150/200], Loss: 0.0044\n",
      "Epoch [200/200], Loss: 0.0047\n",
      "\n",
      "Training model for Turks and Caicos Islands\n",
      "Epoch [50/200], Loss: 0.0182\n",
      "Epoch [100/200], Loss: 0.0061\n",
      "Epoch [150/200], Loss: 0.0061\n",
      "Epoch [200/200], Loss: 0.0055\n",
      "\n",
      "Training model for Tuvalu\n",
      "Epoch [50/200], Loss: 0.0089\n",
      "Epoch [100/200], Loss: 0.0050\n",
      "Epoch [150/200], Loss: 0.0039\n",
      "Epoch [200/200], Loss: 0.0038\n",
      "\n",
      "Training model for Uganda\n",
      "Epoch [50/200], Loss: 0.0450\n",
      "Epoch [100/200], Loss: 0.0300\n",
      "Epoch [150/200], Loss: 0.0198\n",
      "Epoch [200/200], Loss: 0.0197\n",
      "\n",
      "Training model for Ukraine\n",
      "Epoch [50/200], Loss: 0.0044\n",
      "Epoch [100/200], Loss: 0.0017\n",
      "Epoch [150/200], Loss: 0.0012\n",
      "Epoch [200/200], Loss: 0.0008\n",
      "\n",
      "Training model for United Arab Emirates\n",
      "Epoch [50/200], Loss: 0.0063\n",
      "Epoch [100/200], Loss: 0.0026\n",
      "Epoch [150/200], Loss: 0.0026\n",
      "Epoch [200/200], Loss: 0.0027\n",
      "\n",
      "Training model for United Kingdom\n",
      "Epoch [50/200], Loss: 0.0099\n",
      "Epoch [100/200], Loss: 0.0025\n",
      "Epoch [150/200], Loss: 0.0016\n",
      "Epoch [200/200], Loss: 0.0015\n",
      "\n",
      "Training model for United States\n",
      "Epoch [50/200], Loss: 0.0055\n",
      "Epoch [100/200], Loss: 0.0044\n",
      "Epoch [150/200], Loss: 0.0041\n",
      "Epoch [200/200], Loss: 0.0037\n",
      "\n",
      "Training model for Uruguay\n",
      "Epoch [50/200], Loss: 0.0031\n",
      "Epoch [100/200], Loss: 0.0015\n",
      "Epoch [150/200], Loss: 0.0012\n",
      "Epoch [200/200], Loss: 0.0011\n",
      "\n",
      "Training model for Uzbekistan\n",
      "Epoch [50/200], Loss: 0.0027\n",
      "Epoch [100/200], Loss: 0.0008\n",
      "Epoch [150/200], Loss: 0.0006\n",
      "Epoch [200/200], Loss: 0.0006\n",
      "\n",
      "Training model for Vanuatu\n",
      "Epoch [50/200], Loss: 0.0034\n",
      "Epoch [100/200], Loss: 0.0011\n",
      "Epoch [150/200], Loss: 0.0012\n",
      "Epoch [200/200], Loss: 0.0010\n",
      "\n",
      "Training model for Venezuela, RB\n",
      "Epoch [50/200], Loss: 0.0119\n",
      "Epoch [100/200], Loss: 0.0066\n",
      "Epoch [150/200], Loss: 0.0066\n",
      "Epoch [200/200], Loss: 0.0065\n",
      "\n",
      "Training model for Viet Nam\n",
      "Epoch [50/200], Loss: 0.0058\n",
      "Epoch [100/200], Loss: 0.0034\n",
      "Epoch [150/200], Loss: 0.0033\n",
      "Epoch [200/200], Loss: 0.0033\n",
      "\n",
      "Training model for Virgin Islands (U.S.)\n",
      "Epoch [50/200], Loss: 0.0047\n",
      "Epoch [100/200], Loss: 0.0041\n",
      "Epoch [150/200], Loss: 0.0038\n",
      "Epoch [200/200], Loss: 0.0036\n",
      "\n",
      "Training model for West Bank and Gaza\n",
      "Epoch [50/200], Loss: 0.0054\n",
      "Epoch [100/200], Loss: 0.0047\n",
      "Epoch [150/200], Loss: 0.0038\n",
      "Epoch [200/200], Loss: 0.0034\n",
      "\n",
      "Training model for Yemen, Rep.\n",
      "Epoch [50/200], Loss: 0.0274\n",
      "Epoch [100/200], Loss: 0.0288\n",
      "Epoch [150/200], Loss: 0.0266\n",
      "Epoch [200/200], Loss: 0.0251\n",
      "\n",
      "Training model for Zambia\n",
      "Epoch [50/200], Loss: 0.0044\n",
      "Epoch [100/200], Loss: 0.0035\n",
      "Epoch [150/200], Loss: 0.0039\n",
      "Epoch [200/200], Loss: 0.0032\n",
      "\n",
      "Training model for Zimbabwe\n",
      "Epoch [50/200], Loss: 0.0092\n",
      "Epoch [100/200], Loss: 0.0132\n",
      "Epoch [150/200], Loss: 0.0093\n",
      "Epoch [200/200], Loss: 0.0087\n",
      "\n",
      "Training model for Africa Eastern and Southern\n",
      "Epoch [50/200], Loss: 0.0011\n",
      "Epoch [100/200], Loss: 0.0006\n",
      "Epoch [150/200], Loss: 0.0006\n",
      "Epoch [200/200], Loss: 0.0005\n",
      "\n",
      "Training model for Africa Western and Central\n",
      "Epoch [50/200], Loss: 0.0024\n",
      "Epoch [100/200], Loss: 0.0003\n",
      "Epoch [150/200], Loss: 0.0003\n",
      "Epoch [200/200], Loss: 0.0002\n",
      "\n",
      "Training model for Arab World\n",
      "Epoch [50/200], Loss: 0.0061\n",
      "Epoch [100/200], Loss: 0.0064\n",
      "Epoch [150/200], Loss: 0.0055\n",
      "Epoch [200/200], Loss: 0.0059\n",
      "\n",
      "Training model for Caribbean small states\n",
      "Epoch [50/200], Loss: 0.0086\n",
      "Epoch [100/200], Loss: 0.0075\n",
      "Epoch [150/200], Loss: 0.0078\n",
      "Epoch [200/200], Loss: 0.0077\n",
      "\n",
      "Training model for Central Europe and the Baltics\n",
      "Epoch [50/200], Loss: 0.0068\n",
      "Epoch [100/200], Loss: 0.0028\n",
      "Epoch [150/200], Loss: 0.0018\n",
      "Epoch [200/200], Loss: 0.0011\n",
      "\n",
      "Training model for Early-demographic dividend\n",
      "Epoch [50/200], Loss: 0.0023\n",
      "Epoch [100/200], Loss: 0.0019\n",
      "Epoch [150/200], Loss: 0.0017\n",
      "Epoch [200/200], Loss: 0.0032\n",
      "\n",
      "Training model for East Asia & Pacific\n",
      "Epoch [50/200], Loss: 0.0018\n",
      "Epoch [100/200], Loss: 0.0012\n",
      "Epoch [150/200], Loss: 0.0010\n",
      "Epoch [200/200], Loss: 0.0009\n",
      "\n",
      "Training model for East Asia & Pacific (excluding high income)\n",
      "Epoch [50/200], Loss: 0.0023\n",
      "Epoch [100/200], Loss: 0.0015\n",
      "Epoch [150/200], Loss: 0.0012\n",
      "Epoch [200/200], Loss: 0.0011\n",
      "\n",
      "Training model for East Asia & Pacific (IDA & IBRD countries)\n",
      "Epoch [50/200], Loss: 0.0027\n",
      "Epoch [100/200], Loss: 0.0017\n",
      "Epoch [150/200], Loss: 0.0016\n",
      "Epoch [200/200], Loss: 0.0014\n",
      "\n",
      "Training model for Euro area\n",
      "Epoch [50/200], Loss: 0.0056\n",
      "Epoch [100/200], Loss: 0.0029\n",
      "Epoch [150/200], Loss: 0.0022\n",
      "Epoch [200/200], Loss: 0.0017\n",
      "\n",
      "Training model for Europe & Central Asia\n",
      "Epoch [50/200], Loss: 0.0041\n",
      "Epoch [100/200], Loss: 0.0019\n",
      "Epoch [150/200], Loss: 0.0013\n",
      "Epoch [200/200], Loss: 0.0010\n",
      "\n",
      "Training model for Europe & Central Asia (excluding high income)\n",
      "Epoch [50/200], Loss: 0.0009\n",
      "Epoch [100/200], Loss: 0.0008\n",
      "Epoch [150/200], Loss: 0.0007\n",
      "Epoch [200/200], Loss: 0.0005\n",
      "\n",
      "Training model for Europe & Central Asia (IDA & IBRD countries)\n",
      "Epoch [50/200], Loss: 0.0034\n",
      "Epoch [100/200], Loss: 0.0010\n",
      "Epoch [150/200], Loss: 0.0009\n",
      "Epoch [200/200], Loss: 0.0006\n",
      "\n",
      "Training model for European Union\n",
      "Epoch [50/200], Loss: 0.0051\n",
      "Epoch [100/200], Loss: 0.0024\n",
      "Epoch [150/200], Loss: 0.0019\n",
      "Epoch [200/200], Loss: 0.0016\n",
      "\n",
      "Training model for Fragile and conflict affected situations\n",
      "Epoch [50/200], Loss: 0.0013\n",
      "Epoch [100/200], Loss: 0.0004\n",
      "Epoch [150/200], Loss: 0.0004\n",
      "Epoch [200/200], Loss: 0.0003\n",
      "\n",
      "Training model for Heavily indebted poor countries (HIPC)\n",
      "Epoch [50/200], Loss: 0.0020\n",
      "Epoch [100/200], Loss: 0.0008\n",
      "Epoch [150/200], Loss: 0.0011\n",
      "Epoch [200/200], Loss: 0.0010\n",
      "\n",
      "Training model for High income\n",
      "Epoch [50/200], Loss: 0.0037\n",
      "Epoch [100/200], Loss: 0.0017\n",
      "Epoch [150/200], Loss: 0.0011\n",
      "Epoch [200/200], Loss: 0.0009\n",
      "\n",
      "Training model for IBRD only\n",
      "Epoch [50/200], Loss: 0.0035\n",
      "Epoch [100/200], Loss: 0.0019\n",
      "Epoch [150/200], Loss: 0.0016\n",
      "Epoch [200/200], Loss: 0.0015\n",
      "\n",
      "Training model for IDA & IBRD total\n",
      "Epoch [50/200], Loss: 0.0019\n",
      "Epoch [100/200], Loss: 0.0014\n",
      "Epoch [150/200], Loss: 0.0012\n",
      "Epoch [200/200], Loss: 0.0011\n",
      "\n",
      "Training model for IDA blend\n",
      "Epoch [50/200], Loss: 0.0011\n",
      "Epoch [100/200], Loss: 0.0008\n",
      "Epoch [150/200], Loss: 0.0009\n",
      "Epoch [200/200], Loss: 0.0009\n",
      "\n",
      "Training model for IDA only\n",
      "Epoch [50/200], Loss: 0.0003\n",
      "Epoch [100/200], Loss: 0.0003\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0003\n",
      "\n",
      "Training model for IDA total\n",
      "Epoch [50/200], Loss: 0.0004\n",
      "Epoch [100/200], Loss: 0.0001\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0001\n",
      "\n",
      "Training model for Late-demographic dividend\n",
      "Epoch [50/200], Loss: 0.0036\n",
      "Epoch [100/200], Loss: 0.0016\n",
      "Epoch [150/200], Loss: 0.0014\n",
      "Epoch [200/200], Loss: 0.0011\n",
      "\n",
      "Training model for Latin America & Caribbean\n",
      "Epoch [50/200], Loss: 0.0007\n",
      "Epoch [100/200], Loss: 0.0006\n",
      "Epoch [150/200], Loss: 0.0005\n",
      "Epoch [200/200], Loss: 0.0006\n",
      "\n",
      "Training model for Latin America & Caribbean (excluding high income)\n",
      "Epoch [50/200], Loss: 0.0012\n",
      "Epoch [100/200], Loss: 0.0007\n",
      "Epoch [150/200], Loss: 0.0006\n",
      "Epoch [200/200], Loss: 0.0006\n",
      "\n",
      "Training model for Latin America & the Caribbean (IDA & IBRD countries)\n",
      "Epoch [50/200], Loss: 0.0023\n",
      "Epoch [100/200], Loss: 0.0008\n",
      "Epoch [150/200], Loss: 0.0008\n",
      "Epoch [200/200], Loss: 0.0006\n",
      "\n",
      "Training model for Least developed countries: UN classification\n",
      "Epoch [50/200], Loss: 0.0063\n",
      "Epoch [100/200], Loss: 0.0057\n",
      "Epoch [150/200], Loss: 0.0063\n",
      "Epoch [200/200], Loss: 0.0061\n",
      "\n",
      "Training model for Low & middle income\n",
      "Epoch [50/200], Loss: 0.0015\n",
      "Epoch [100/200], Loss: 0.0015\n",
      "Epoch [150/200], Loss: 0.0012\n",
      "Epoch [200/200], Loss: 0.0012\n",
      "\n",
      "Training model for Low income\n",
      "Epoch [50/200], Loss: 0.0017\n",
      "Epoch [100/200], Loss: 0.0003\n",
      "Epoch [150/200], Loss: 0.0003\n",
      "Epoch [200/200], Loss: 0.0003\n",
      "\n",
      "Training model for Lower middle income\n",
      "Epoch [50/200], Loss: 0.0012\n",
      "Epoch [100/200], Loss: 0.0012\n",
      "Epoch [150/200], Loss: 0.0010\n",
      "Epoch [200/200], Loss: 0.0014\n",
      "\n",
      "Training model for Middle East & North Africa\n",
      "Epoch [50/200], Loss: 0.0020\n",
      "Epoch [100/200], Loss: 0.0005\n",
      "Epoch [150/200], Loss: 0.0005\n",
      "Epoch [200/200], Loss: 0.0005\n",
      "\n",
      "Training model for Middle East & North Africa (excluding high income)\n",
      "Epoch [50/200], Loss: 0.0024\n",
      "Epoch [100/200], Loss: 0.0005\n",
      "Epoch [150/200], Loss: 0.0006\n",
      "Epoch [200/200], Loss: 0.0004\n",
      "\n",
      "Training model for Middle East & North Africa (IDA & IBRD countries)\n",
      "Epoch [50/200], Loss: 0.0004\n",
      "Epoch [100/200], Loss: 0.0004\n",
      "Epoch [150/200], Loss: 0.0004\n",
      "Epoch [200/200], Loss: 0.0003\n",
      "\n",
      "Training model for Middle income\n",
      "Epoch [50/200], Loss: 0.0018\n",
      "Epoch [100/200], Loss: 0.0014\n",
      "Epoch [150/200], Loss: 0.0014\n",
      "Epoch [200/200], Loss: 0.0010\n",
      "\n",
      "Training model for North America\n",
      "Epoch [50/200], Loss: 0.0051\n",
      "Epoch [100/200], Loss: 0.0043\n",
      "Epoch [150/200], Loss: 0.0036\n",
      "Epoch [200/200], Loss: 0.0027\n",
      "\n",
      "Training model for Not classified\n",
      "Epoch [50/200], Loss: 0.0048\n",
      "Epoch [100/200], Loss: 0.0043\n",
      "Epoch [150/200], Loss: 0.0036\n",
      "Epoch [200/200], Loss: 0.0034\n",
      "\n",
      "Training model for OECD members\n",
      "Epoch [50/200], Loss: 0.0041\n",
      "Epoch [100/200], Loss: 0.0027\n",
      "Epoch [150/200], Loss: 0.0019\n",
      "Epoch [200/200], Loss: 0.0019\n",
      "\n",
      "Training model for Other small states\n",
      "Epoch [50/200], Loss: 0.0017\n",
      "Epoch [100/200], Loss: 0.0014\n",
      "Epoch [150/200], Loss: 0.0010\n",
      "Epoch [200/200], Loss: 0.0013\n",
      "\n",
      "Training model for Pacific island small states\n",
      "Epoch [50/200], Loss: 0.0025\n",
      "Epoch [100/200], Loss: 0.0013\n",
      "Epoch [150/200], Loss: 0.0016\n",
      "Epoch [200/200], Loss: 0.0016\n",
      "\n",
      "Training model for Post-demographic dividend\n",
      "Epoch [50/200], Loss: 0.0040\n",
      "Epoch [100/200], Loss: 0.0024\n",
      "Epoch [150/200], Loss: 0.0017\n",
      "Epoch [200/200], Loss: 0.0014\n",
      "\n",
      "Training model for Pre-demographic dividend\n",
      "Epoch [50/200], Loss: 0.0077\n",
      "Epoch [100/200], Loss: 0.0064\n",
      "Epoch [150/200], Loss: 0.0047\n",
      "Epoch [200/200], Loss: 0.0041\n",
      "\n",
      "Training model for Small states\n",
      "Epoch [50/200], Loss: 0.0021\n",
      "Epoch [100/200], Loss: 0.0005\n",
      "Epoch [150/200], Loss: 0.0005\n",
      "Epoch [200/200], Loss: 0.0004\n",
      "\n",
      "Training model for South Asia\n",
      "Epoch [50/200], Loss: 0.0037\n",
      "Epoch [100/200], Loss: 0.0022\n",
      "Epoch [150/200], Loss: 0.0023\n",
      "Epoch [200/200], Loss: 0.0019\n",
      "\n",
      "Training model for South Asia (IDA & IBRD)\n",
      "Epoch [50/200], Loss: 0.0023\n",
      "Epoch [100/200], Loss: 0.0020\n",
      "Epoch [150/200], Loss: 0.0033\n",
      "Epoch [200/200], Loss: 0.0026\n",
      "\n",
      "Training model for Sub-Saharan Africa\n",
      "Epoch [50/200], Loss: 0.0017\n",
      "Epoch [100/200], Loss: 0.0002\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0002\n",
      "\n",
      "Training model for Sub-Saharan Africa (excluding high income)\n",
      "Epoch [50/200], Loss: 0.0012\n",
      "Epoch [100/200], Loss: 0.0005\n",
      "Epoch [150/200], Loss: 0.0004\n",
      "Epoch [200/200], Loss: 0.0004\n",
      "\n",
      "Training model for Sub-Saharan Africa (IDA & IBRD countries)\n",
      "Epoch [50/200], Loss: 0.0004\n",
      "Epoch [100/200], Loss: 0.0003\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0002\n",
      "\n",
      "Training model for Upper middle income\n",
      "Epoch [50/200], Loss: 0.0029\n",
      "Epoch [100/200], Loss: 0.0015\n",
      "Epoch [150/200], Loss: 0.0014\n",
      "Epoch [200/200], Loss: 0.0012\n",
      "\n",
      "Training model for World\n",
      "Epoch [50/200], Loss: 0.0076\n",
      "Epoch [100/200], Loss: 0.0003\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0001\n",
      "\n",
      "Training model for World\n",
      "Epoch [50/200], Loss: 0.0091\n",
      "Epoch [100/200], Loss: 0.0006\n",
      "Epoch [150/200], Loss: 0.0004\n",
      "Epoch [200/200], Loss: 0.0002\n",
      "\n",
      "Training model for World\n",
      "Epoch [50/200], Loss: 0.0082\n",
      "Epoch [100/200], Loss: 0.0003\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0001\n",
      "\n",
      "Training model for World\n",
      "Epoch [50/200], Loss: 0.0095\n",
      "Epoch [100/200], Loss: 0.0004\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0002\n",
      "\n",
      "Training model for World\n",
      "Epoch [50/200], Loss: 0.0104\n",
      "Epoch [100/200], Loss: 0.0004\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0001\n",
      "\n",
      "Training model for World\n",
      "Epoch [50/200], Loss: 0.0187\n",
      "Epoch [100/200], Loss: 0.0008\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0002\n"
     ]
    }
   ],
   "source": [
    "for country in df['Country']:\n",
    "        print(f\"\\nTraining model for {country}\")\n",
    "        \n",
    "        # Get country data\n",
    "        country_data = df[df['Country'] == country][cols].values.flatten()\n",
    "\n",
    "        country_data = country_data.astype(float)\n",
    "        \n",
    "        # Prepare data\n",
    "        X, y, scaler = prepare_country_data(country_data, sequence_length)\n",
    "        \n",
    "        if len(X) > 0:  # Check if we have enough data\n",
    "            # Train model\n",
    "            model = train_model(X, y)\n",
    "            \n",
    "            # Make predictions\n",
    "            last_sequence = scaler.transform(country_data[-sequence_length:].reshape(-1, 1))\n",
    "            predictions = predict_future(model, last_sequence, scaler)\n",
    "            predictions_by_country[country] = predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Internet (2024-2028):\n",
      "\n",
      "United States:\n",
      "2024: $96.44\n",
      "2025: $97.42\n",
      "2026: $97.53\n",
      "2027: $97.59\n",
      "2028: $97.59\n",
      "\n",
      "China:\n",
      "2024: $75.61\n",
      "2025: $77.14\n",
      "2026: $77.98\n",
      "2027: $78.51\n",
      "2028: $78.81\n",
      "\n",
      "Japan:\n",
      "2024: $87.27\n",
      "2025: $86.79\n",
      "2026: $86.46\n",
      "2027: $86.75\n",
      "2028: $86.90\n",
      "\n",
      "Germany:\n",
      "2024: $87.58\n",
      "2025: $87.68\n",
      "2026: $87.64\n",
      "2027: $87.48\n",
      "2028: $87.27\n",
      "\n",
      "United Kingdom:\n",
      "2024: $93.49\n",
      "2025: $93.73\n",
      "2026: $93.70\n",
      "2027: $93.60\n",
      "2028: $93.44\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for country in selected_countries:\n",
    "    if country in predictions_by_country:\n",
    "        plt.plot(range(2024, 2029), predictions_by_country[country], label=country)\n",
    "plt.title('Internet Predictions (2024-2028)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Internet')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "    \n",
    "    # Print predictions for selected countries\n",
    "print(\"\\nPredicted Internet (2024-2028):\")\n",
    "for country in selected_countries:\n",
    "    if country in predictions_by_country:\n",
    "        print(f\"\\n{country}:\")\n",
    "        for year, pred in zip(range(2024, 2029), predictions_by_country[country]):\n",
    "            print(f\"{year}: ${pred:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions exported to lstm_datasets/internet_prediction.csv\n"
     ]
    }
   ],
   "source": [
    "# Export predictions to CSV\n",
    "predictions_df = pd.DataFrame()\n",
    "predictions_df['Country'] = list(predictions_by_country.keys())\n",
    "\n",
    "for year in range(2024, 2029):\n",
    "    year_predictions = []\n",
    "    for country in predictions_df['Country']:\n",
    "        if country in predictions_by_country:\n",
    "            year_predictions.append(predictions_by_country[country][year-2024])\n",
    "        else:\n",
    "            year_predictions.append(None)\n",
    "    predictions_df[f'{year} Internet'] = year_predictions\n",
    "\n",
    "predictions_df.to_csv('../lstm_datasets/internet_prediction.csv', index=False)\n",
    "print(\"\\nPredictions exported to lstm_datasets/internet_prediction.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
