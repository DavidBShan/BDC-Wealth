{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from keras>=3.5.0->tensorflow) (13.7.0)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/davidshan/Library/Python/3.12/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=32, num_layers=2):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_country_data(country_data, sequence_length=5):\n",
    "    # Scale the data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(country_data.reshape(-1, 1))\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y = [], []\n",
    "    for i in range(len(scaled_data) - sequence_length):\n",
    "        X.append(scaled_data[i:(i + sequence_length)])\n",
    "        y.append(scaled_data[i + sequence_length])\n",
    "    \n",
    "    return np.array(X), np.array(y), scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, epochs=200):\n",
    "    # Create dataset and dataloader\n",
    "    X_tensor = torch.FloatTensor(X)\n",
    "    y_tensor = torch.FloatTensor(y)\n",
    "    dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "    train_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = Predictor(input_size=1)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future(model, last_sequence, scaler, n_future=7):  # Changed to 7 years\n",
    "    model.eval()\n",
    "    current_sequence = last_sequence.copy()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_future):  # Will now predict 7 years\n",
    "            sequence = torch.FloatTensor(current_sequence).unsqueeze(0)\n",
    "            pred = model(sequence)\n",
    "            predictions.append(pred.numpy())\n",
    "            current_sequence = np.vstack((current_sequence[1:], pred.numpy()))\n",
    "    \n",
    "    predictions = np.array(predictions).reshape(-1, 1)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    \n",
    "    return predictions.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>YR2014</th>\n",
       "      <th>YR2015</th>\n",
       "      <th>YR2016</th>\n",
       "      <th>YR2017</th>\n",
       "      <th>YR2018</th>\n",
       "      <th>YR2019</th>\n",
       "      <th>YR2020</th>\n",
       "      <th>YR2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>2.21103916447582</td>\n",
       "      <td>0.78997913166528</td>\n",
       "      <td>0.568187363007616</td>\n",
       "      <td>0.676135028048864</td>\n",
       "      <td>1.43730115442118</td>\n",
       "      <td>1.53656088925892</td>\n",
       "      <td>0.805650721774117</td>\n",
       "      <td>1.59471633197215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>0.755451088942237</td>\n",
       "      <td>0.567565619466884</td>\n",
       "      <td>0.591410295226177</td>\n",
       "      <td>0.760358992143208</td>\n",
       "      <td>1.14049132500834</td>\n",
       "      <td>1.31732811944483</td>\n",
       "      <td>1.1162720977283</td>\n",
       "      <td>1.6313907314568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>1.39876331607307</td>\n",
       "      <td>0.857685698468755</td>\n",
       "      <td>0.686699294180488</td>\n",
       "      <td>0.934976537711634</td>\n",
       "      <td>1.5802963493344</td>\n",
       "      <td>1.44608781006584</td>\n",
       "      <td>0.949585951805012</td>\n",
       "      <td>2.26355193351451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China</td>\n",
       "      <td>1.17449560810056</td>\n",
       "      <td>0.55146891809536</td>\n",
       "      <td>0.468471119066501</td>\n",
       "      <td>0.582954445963903</td>\n",
       "      <td>0.704281724834458</td>\n",
       "      <td>0.554702096120324</td>\n",
       "      <td>0.361833602387154</td>\n",
       "      <td>0.689430074246557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>0.00701751945317788</td>\n",
       "      <td>0.00394674875841994</td>\n",
       "      <td>0.00301090345845521</td>\n",
       "      <td>0.00404255730613459</td>\n",
       "      <td>0.00676725037994716</td>\n",
       "      <td>0.00543453180331309</td>\n",
       "      <td>0.00264417156034399</td>\n",
       "      <td>0.00550683481013504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country               YR2014               YR2015               YR2016  \\\n",
       "0  Argentina     2.21103916447582     0.78997913166528    0.568187363007616   \n",
       "1  Australia    0.755451088942237    0.567565619466884    0.591410295226177   \n",
       "2     Brazil     1.39876331607307    0.857685698468755    0.686699294180488   \n",
       "3      China     1.17449560810056     0.55146891809536    0.468471119066501   \n",
       "4     France  0.00701751945317788  0.00394674875841994  0.00301090345845521   \n",
       "\n",
       "                YR2017               YR2018               YR2019  \\\n",
       "0    0.676135028048864     1.43730115442118     1.53656088925892   \n",
       "1    0.760358992143208     1.14049132500834     1.31732811944483   \n",
       "2    0.934976537711634      1.5802963493344     1.44608781006584   \n",
       "3    0.582954445963903    0.704281724834458    0.554702096120324   \n",
       "4  0.00404255730613459  0.00676725037994716  0.00543453180331309   \n",
       "\n",
       "                YR2020               YR2021  \n",
       "0    0.805650721774117     1.59471633197215  \n",
       "1      1.1162720977283      1.6313907314568  \n",
       "2    0.949585951805012     2.26355193351451  \n",
       "3    0.361833602387154    0.689430074246557  \n",
       "4  0.00264417156034399  0.00550683481013504  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/energy.csv')\n",
    "df.head()\n",
    "df.replace(\"..\", pd.NA, inplace=True)\n",
    "# Forward fill first, then backward fill to handle any remaining NAs at the start\n",
    "df.rename(columns={'Country Name': 'Country'}, inplace=True)\n",
    "df.drop(columns=['YR2022', 'YR2023'], inplace=True)\n",
    "df = df.ffill().bfill()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['YR2014', 'YR2015', 'YR2016', 'YR2017', 'YR2018', 'YR2019', 'YR2020', 'YR2021']\n"
     ]
    }
   ],
   "source": [
    "cols = [col for col in df.columns if 'YR' in col]\n",
    "print(cols)\n",
    "    \n",
    "sequence_length = 7\n",
    "predictions_by_country = {}\n",
    "selected_countries = ['United States', 'China', 'Japan', 'Germany', 'United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for Argentina\n",
      "Epoch [50/200], Loss: 0.0008\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Australia\n",
      "Epoch [50/200], Loss: 0.0063\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Brazil\n",
      "Epoch [50/200], Loss: 0.0065\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for China\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for France\n",
      "Epoch [50/200], Loss: 0.0049\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Germany\n",
      "Epoch [50/200], Loss: 0.0056\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for India\n",
      "Epoch [50/200], Loss: 0.0007\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Indonesia\n",
      "Epoch [50/200], Loss: 0.0041\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Italy\n",
      "Epoch [50/200], Loss: 0.0037\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Japan\n",
      "Epoch [50/200], Loss: 0.0007\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Korea, Rep.\n",
      "Epoch [50/200], Loss: 0.0037\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Mexico\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Netherlands\n",
      "Epoch [50/200], Loss: 0.0003\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Russian Federation\n",
      "Epoch [50/200], Loss: 0.0051\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Saudi Arabia\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Spain\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Switzerland\n",
      "Epoch [50/200], Loss: 0.0084\n",
      "Epoch [100/200], Loss: 0.0001\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Turkiye\n",
      "Epoch [50/200], Loss: 0.0118\n",
      "Epoch [100/200], Loss: 0.0001\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for United Kingdom\n",
      "Epoch [50/200], Loss: 0.0001\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for United States\n",
      "Epoch [50/200], Loss: 0.0029\n",
      "Epoch [100/200], Loss: 0.0001\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Afghanistan\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Albania\n",
      "Epoch [50/200], Loss: 0.0001\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Algeria\n",
      "Epoch [50/200], Loss: 0.0008\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for American Samoa\n",
      "Epoch [50/200], Loss: 0.0030\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Andorra\n",
      "Epoch [50/200], Loss: 0.0037\n",
      "Epoch [100/200], Loss: 0.0001\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Angola\n",
      "Epoch [50/200], Loss: 0.0035\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Antigua and Barbuda\n",
      "Epoch [50/200], Loss: 0.0001\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Armenia\n",
      "Epoch [50/200], Loss: 0.0055\n",
      "Epoch [100/200], Loss: 0.0001\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Aruba\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Austria\n",
      "Epoch [50/200], Loss: 0.0022\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Azerbaijan\n",
      "Epoch [50/200], Loss: 0.0040\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Bahamas, The\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Bahrain\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Bangladesh\n",
      "Epoch [50/200], Loss: 0.0006\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Barbados\n",
      "Epoch [50/200], Loss: 0.0082\n",
      "Epoch [100/200], Loss: 0.0001\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Belarus\n",
      "Epoch [50/200], Loss: 0.0008\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Belgium\n",
      "Epoch [50/200], Loss: 0.0031\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Belize\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Benin\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Bermuda\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Bhutan\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Bolivia\n",
      "Epoch [50/200], Loss: 0.0001\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Bosnia and Herzegovina\n",
      "Epoch [50/200], Loss: 0.0029\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Botswana\n",
      "Epoch [50/200], Loss: 0.0043\n",
      "Epoch [100/200], Loss: 0.0001\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for British Virgin Islands\n",
      "Epoch [50/200], Loss: 0.0053\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Brunei Darussalam\n",
      "Epoch [50/200], Loss: 0.0081\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Bulgaria\n",
      "Epoch [50/200], Loss: 0.0002\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Burkina Faso\n",
      "Epoch [50/200], Loss: 0.0001\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Burundi\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Cabo Verde\n",
      "Epoch [50/200], Loss: 0.0002\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Cambodia\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Cameroon\n",
      "Epoch [50/200], Loss: 0.0048\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Canada\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Cayman Islands\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Central African Republic\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Chad\n",
      "Epoch [50/200], Loss: 0.0045\n",
      "Epoch [100/200], Loss: 0.0001\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Channel Islands\n",
      "Epoch [50/200], Loss: 0.0060\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Chile\n",
      "Epoch [50/200], Loss: 0.0021\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Colombia\n",
      "Epoch [50/200], Loss: 0.0029\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Comoros\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Congo, Dem. Rep.\n",
      "Epoch [50/200], Loss: 0.0012\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Congo, Rep.\n",
      "Epoch [50/200], Loss: 0.0040\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Costa Rica\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Cote d'Ivoire\n",
      "Epoch [50/200], Loss: 0.0034\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Croatia\n",
      "Epoch [50/200], Loss: 0.0008\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Cuba\n",
      "Epoch [50/200], Loss: 0.0002\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Curacao\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Cyprus\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Czechia\n",
      "Epoch [50/200], Loss: 0.0008\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Denmark\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Djibouti\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Dominica\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Dominican Republic\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Ecuador\n",
      "Epoch [50/200], Loss: 0.0015\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Egypt, Arab Rep.\n",
      "Epoch [50/200], Loss: 0.0009\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for El Salvador\n",
      "Epoch [50/200], Loss: 0.0024\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Equatorial Guinea\n",
      "Epoch [50/200], Loss: 0.0001\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Eritrea\n",
      "Epoch [50/200], Loss: 0.0001\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Estonia\n",
      "Epoch [50/200], Loss: 0.0064\n",
      "Epoch [100/200], Loss: 0.0001\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Eswatini\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Ethiopia\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Faroe Islands\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Fiji\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Finland\n",
      "Epoch [50/200], Loss: 0.0034\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for French Polynesia\n",
      "Epoch [50/200], Loss: 0.0005\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Gabon\n",
      "Epoch [50/200], Loss: 0.0022\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Gambia, The\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Georgia\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Ghana\n",
      "Epoch [50/200], Loss: 0.0079\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Gibraltar\n",
      "Epoch [50/200], Loss: 0.0011\n",
      "Epoch [100/200], Loss: 0.0001\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Greece\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Greenland\n",
      "Epoch [50/200], Loss: 0.0003\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Grenada\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Guam\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Guatemala\n",
      "Epoch [50/200], Loss: 0.0003\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Guinea\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Guinea-Bissau\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Guyana\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Haiti\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Honduras\n",
      "Epoch [50/200], Loss: 0.0024\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Hong Kong SAR, China\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Hungary\n",
      "Epoch [50/200], Loss: 0.0061\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Iceland\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Iran, Islamic Rep.\n",
      "Epoch [50/200], Loss: 0.0010\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Iraq\n",
      "Epoch [50/200], Loss: 0.0009\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Ireland\n",
      "Epoch [50/200], Loss: 0.0057\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Isle of Man\n",
      "Epoch [50/200], Loss: 0.0028\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Israel\n",
      "Epoch [50/200], Loss: 0.0006\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Jamaica\n",
      "Epoch [50/200], Loss: 0.0012\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Jordan\n",
      "Epoch [50/200], Loss: 0.0015\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Kazakhstan\n",
      "Epoch [50/200], Loss: 0.0023\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Kenya\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Kiribati\n",
      "Epoch [50/200], Loss: 0.0001\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Korea, Dem. People's Rep.\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Kosovo\n",
      "Epoch [50/200], Loss: 0.0058\n",
      "Epoch [100/200], Loss: 0.0001\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Kuwait\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Kyrgyz Republic\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Lao PDR\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Latvia\n",
      "Epoch [50/200], Loss: 0.0016\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Lebanon\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Lesotho\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Liberia\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Libya\n",
      "Epoch [50/200], Loss: 0.0015\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Liechtenstein\n",
      "Epoch [50/200], Loss: 0.0002\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Lithuania\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Luxembourg\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Macao SAR, China\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Madagascar\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Malawi\n",
      "Epoch [50/200], Loss: 0.0002\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Malaysia\n",
      "Epoch [50/200], Loss: 0.0020\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Maldives\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Mali\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Malta\n",
      "Epoch [50/200], Loss: 0.0001\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Marshall Islands\n",
      "Epoch [50/200], Loss: 0.0001\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Mauritania\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Mauritius\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Micronesia, Fed. Sts.\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Moldova\n",
      "Epoch [50/200], Loss: 0.0007\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Monaco\n",
      "Epoch [50/200], Loss: 0.0001\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Mongolia\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Montenegro\n",
      "Epoch [50/200], Loss: 0.0041\n",
      "Epoch [100/200], Loss: 0.0001\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Morocco\n",
      "Epoch [50/200], Loss: 0.0004\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Mozambique\n",
      "Epoch [50/200], Loss: 0.0036\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Myanmar\n",
      "Epoch [50/200], Loss: 0.0074\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Namibia\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Nauru\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Nepal\n",
      "Epoch [50/200], Loss: 0.0002\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for New Caledonia\n",
      "Epoch [50/200], Loss: 0.0058\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for New Zealand\n",
      "Epoch [50/200], Loss: 0.0004\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Nicaragua\n",
      "Epoch [50/200], Loss: 0.0007\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Niger\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Nigeria\n",
      "Epoch [50/200], Loss: 0.0015\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for North Macedonia\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Northern Mariana Islands\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Norway\n",
      "Epoch [50/200], Loss: 0.0025\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Oman\n",
      "Epoch [50/200], Loss: 0.0039\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Pakistan\n",
      "Epoch [50/200], Loss: 0.0008\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Palau\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Panama\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Papua New Guinea\n",
      "Epoch [50/200], Loss: 0.0030\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Paraguay\n",
      "Epoch [50/200], Loss: 0.0001\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Peru\n",
      "Epoch [50/200], Loss: 0.0025\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Philippines\n",
      "Epoch [50/200], Loss: 0.0001\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Poland\n",
      "Epoch [50/200], Loss: 0.0003\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Portugal\n",
      "Epoch [50/200], Loss: 0.0034\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Puerto Rico\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Qatar\n",
      "Epoch [50/200], Loss: 0.0004\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Romania\n",
      "Epoch [50/200], Loss: 0.0026\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Rwanda\n",
      "Epoch [50/200], Loss: 0.0412\n",
      "Epoch [100/200], Loss: 0.0002\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Samoa\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for San Marino\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Sao Tome and Principe\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Senegal\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Serbia\n",
      "Epoch [50/200], Loss: 0.0001\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Seychelles\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Sierra Leone\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Singapore\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Sint Maarten (Dutch part)\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Slovak Republic\n",
      "Epoch [50/200], Loss: 0.0003\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Slovenia\n",
      "Epoch [50/200], Loss: 0.0001\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Solomon Islands\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Somalia\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for South Africa\n",
      "Epoch [50/200], Loss: 0.0036\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for South Sudan\n",
      "Epoch [50/200], Loss: 0.0003\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Sri Lanka\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for St. Kitts and Nevis\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for St. Lucia\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for St. Martin (French part)\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for St. Vincent and the Grenadines\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Sudan\n",
      "Epoch [50/200], Loss: 0.0016\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Suriname\n",
      "Epoch [50/200], Loss: 0.0027\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Sweden\n",
      "Epoch [50/200], Loss: 0.0019\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Syrian Arab Republic\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Tajikistan\n",
      "Epoch [50/200], Loss: 0.0043\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Tanzania\n",
      "Epoch [50/200], Loss: 0.0076\n",
      "Epoch [100/200], Loss: 0.0001\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Thailand\n",
      "Epoch [50/200], Loss: 0.0008\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Timor-Leste\n",
      "Epoch [50/200], Loss: 0.0070\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Togo\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Tonga\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Trinidad and Tobago\n",
      "Epoch [50/200], Loss: 0.0008\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Tunisia\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Turkmenistan\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Turks and Caicos Islands\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Tuvalu\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Uganda\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Ukraine\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for United Arab Emirates\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Uruguay\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Uzbekistan\n",
      "Epoch [50/200], Loss: 0.0072\n",
      "Epoch [100/200], Loss: 0.0001\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Vanuatu\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Venezuela, RB\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Viet Nam\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Virgin Islands (U.S.)\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for West Bank and Gaza\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Yemen, Rep.\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Zambia\n",
      "Epoch [50/200], Loss: 0.0040\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Zimbabwe\n",
      "Epoch [50/200], Loss: 0.0800\n",
      "Epoch [100/200], Loss: 0.0321\n",
      "Epoch [150/200], Loss: 0.0041\n",
      "Epoch [200/200], Loss: 0.0003\n",
      "\n",
      "Training model for Zimbabwe\n",
      "Epoch [50/200], Loss: 0.1618\n",
      "Epoch [100/200], Loss: 0.0235\n",
      "Epoch [150/200], Loss: 0.0004\n",
      "Epoch [200/200], Loss: 0.0001\n",
      "\n",
      "Training model for Zimbabwe\n",
      "Epoch [50/200], Loss: 0.1630\n",
      "Epoch [100/200], Loss: 0.0048\n",
      "Epoch [150/200], Loss: 0.0003\n",
      "Epoch [200/200], Loss: 0.0002\n",
      "\n",
      "Training model for Zimbabwe\n",
      "Epoch [50/200], Loss: 0.0434\n",
      "Epoch [100/200], Loss: 0.0009\n",
      "Epoch [150/200], Loss: 0.0005\n",
      "Epoch [200/200], Loss: 0.0003\n",
      "\n",
      "Training model for Data from database: World Development Indicators\n",
      "Epoch [50/200], Loss: 0.0003\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n",
      "\n",
      "Training model for Last Updated: 12/16/2024\n",
      "Epoch [50/200], Loss: 0.0000\n",
      "Epoch [100/200], Loss: 0.0000\n",
      "Epoch [150/200], Loss: 0.0000\n",
      "Epoch [200/200], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "for country in df['Country']:\n",
    "        print(f\"\\nTraining model for {country}\")\n",
    "        \n",
    "        # Get country data\n",
    "        country_data = df[df['Country'] == country][cols].values.flatten()\n",
    "\n",
    "        country_data = country_data.astype(float)\n",
    "        \n",
    "        # Prepare data\n",
    "        X, y, scaler = prepare_country_data(country_data, sequence_length)\n",
    "        \n",
    "        if len(X) > 0:  # Check if we have enough data\n",
    "            # Train model\n",
    "            model = train_model(X, y)\n",
    "            \n",
    "            # Make predictions\n",
    "            last_sequence = scaler.transform(country_data[-sequence_length:].reshape(-1, 1))\n",
    "            predictions = predict_future(model, last_sequence, scaler)\n",
    "            predictions_by_country[country] = predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Internet (2024-2028):\n",
      "\n",
      "United States:\n",
      "2022: $0.76\n",
      "2023: $0.78\n",
      "2024: $0.81\n",
      "2025: $0.83\n",
      "2026: $0.84\n",
      "2027: $0.86\n",
      "2028: $0.87\n",
      "\n",
      "China:\n",
      "2022: $0.69\n",
      "2023: $0.69\n",
      "2024: $0.69\n",
      "2025: $0.69\n",
      "2026: $0.69\n",
      "2027: $0.69\n",
      "2028: $0.69\n",
      "\n",
      "Japan:\n",
      "2022: $0.01\n",
      "2023: $0.01\n",
      "2024: $0.01\n",
      "2025: $0.01\n",
      "2026: $0.01\n",
      "2027: $0.01\n",
      "2028: $0.01\n",
      "\n",
      "Germany:\n",
      "2022: $0.03\n",
      "2023: $0.03\n",
      "2024: $0.03\n",
      "2025: $0.03\n",
      "2026: $0.03\n",
      "2027: $0.03\n",
      "2028: $0.03\n",
      "\n",
      "United Kingdom:\n",
      "2022: $0.52\n",
      "2023: $0.52\n",
      "2024: $0.53\n",
      "2025: $0.53\n",
      "2026: $0.53\n",
      "2027: $0.53\n",
      "2028: $0.53\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for country in selected_countries:\n",
    "    if country in predictions_by_country:\n",
    "        plt.plot(range(2022, 2029), predictions_by_country[country], label=country)\n",
    "plt.title('Internet Predictions (2024-2028)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Internet')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "    \n",
    "    # Print predictions for selected countries\n",
    "print(\"\\nPredicted Internet (2024-2028):\")\n",
    "for country in selected_countries:\n",
    "    if country in predictions_by_country:\n",
    "        print(f\"\\n{country}:\")\n",
    "        for year, pred in zip(range(2022, 2029), predictions_by_country[country]):\n",
    "            print(f\"{year}: ${pred:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions exported to lstm_datasets/energy_prediction.csv\n"
     ]
    }
   ],
   "source": [
    "# Export predictions to CSV\n",
    "predictions_df = pd.DataFrame()\n",
    "predictions_df['Country'] = list(predictions_by_country.keys())\n",
    "\n",
    "for year in range(2022, 2029):\n",
    "    year_predictions = []\n",
    "    for country in predictions_df['Country']:\n",
    "        if country in predictions_by_country:\n",
    "            year_predictions.append(predictions_by_country[country][year-2022])\n",
    "        else:\n",
    "            year_predictions.append(None)\n",
    "    predictions_df[f'{year} Energy'] = year_predictions\n",
    "\n",
    "predictions_df.to_csv('../lstm_datasets/energy_prediction.csv', index=False)\n",
    "print(\"\\nPredictions exported to lstm_datasets/energy_prediction.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
